{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be2be71",
   "metadata": {},
   "source": [
    "# Recreating Roelof's PPA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1a6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import nengo\n",
    "\n",
    "seed = 18945\n",
    "np.random.seed(seed)\n",
    "\n",
    "STEP_SIZE = 1   # duration time step in ms\n",
    "N_STEPs = 2000     # 2000 ms in total\n",
    "N_CONCEPTs = 5   \n",
    "N_LEMMAs = 5     \n",
    "N_MORPHEMEs = 5  \n",
    "N_PHONEMEs = 10   \n",
    "N_SYLLABLEs = 5  \n",
    "\n",
    "N_lesion_values = 100 # for 100 for weight lesion, 66 (!) for decay lesion\n",
    "\n",
    "N_GROUPs = 4 # Normal, Nonfluent_agrammatic, Semantic_dementia, Logopenic\n",
    "NORMAL = 0\n",
    "NONFLUENT_AGRAMMATIC = 1\n",
    "SEMANTIC_DEMENTIA = 2\n",
    "LOGOPENIC = 3\n",
    "\n",
    "N_TASKs = 3 # Naming, Comprehension, Repetition\n",
    "NAMING = 0\n",
    "COMPREHENSION = 1\n",
    "REPETITION = 2\n",
    "\n",
    "N_ASSESSMENTs = 6\n",
    "ENGLISH = 0\n",
    "DUTCH = 1\n",
    "BRAMBATI_T1 = 2 # baseline \n",
    "BRAMBATI_T2 = 3 # follow up \n",
    "ROHRERMANDELLI_T1 = 4 # baseline \n",
    "ROHRERMANDELLI_T2 = 5 # follow up \n",
    "\n",
    "Y = 1.0     # connection present \n",
    "N = 0.0     # connection absent\n",
    "\n",
    "# labeling network nodes\n",
    "CAT = 0\n",
    "DOG = 1\n",
    "MAT = 2\n",
    "FOG = 3\n",
    "FISH = 4\n",
    "\n",
    "pK = 0 # phonemes\n",
    "pE = 1\n",
    "pT = 2\n",
    "pD = 3\n",
    "pO = 4\n",
    "pG = 5\n",
    "pM = 6\n",
    "pF = 7\n",
    "pI = 8\n",
    "pS = 9\n",
    "\n",
    "Cat = 0\n",
    "Dog = 1\n",
    "Mat = 2\n",
    "Fog = 3\n",
    "Fish = 4\n",
    "\n",
    "# connections conceptual network [N_CONCEPTs][N_CONCEPTs]\n",
    "CC_con =  np.array([\n",
    "    # CAT   DOG  MAT  FOG  FISH  \n",
    "    [   N,    Y,   N,   N,    Y ], # CAT\n",
    "    [   Y,    N,   N,   N,    Y ], # DOG\n",
    "    [   N,    N,   N,   N,    N ], # MAT\n",
    "    [   N,    N,   N,   N,    N ], # FOG\n",
    "    [   Y,    Y,   N,   N,    N ]  # FISH\n",
    "])\n",
    "\n",
    "# connections between concept and lemma nodes [N_CONCEPTs][N_LEMMAs]\n",
    "CL_con = np.array([\n",
    "    [ Y,  N,  N,  N,  N ],\n",
    "    [ N,  Y,  N,  N,  N ],\n",
    "    [ N,  N,  Y,  N,  N ],\n",
    "    [ N,  N,  N,  Y,  N ],\n",
    "    [ N,  N,  N,  N,  Y ]\n",
    "])\n",
    "\n",
    "# connections between lemma nodes and morpheme nodes [N_LEMMAs][N_MORPHEMEs]\n",
    "LM_con = np.array([\n",
    "    [ Y,  N,  N,  N,  N ],\n",
    "    [ N,  Y,  N,  N,  N ],\n",
    "    [ N,  N,  Y,  N,  N ],\n",
    "    [ N,  N,  N,  Y,  N ],\n",
    "    [ N,  N,  N,  N,  Y ]\n",
    "])\n",
    "\n",
    "# connections between morpheme nodes and output phoneme nodes [N_MORPHEMEs][N_PHONEMEs]\n",
    "MP_con = np.array([\n",
    "     #  K  E  T  D  O  G  M  F  I  S  \n",
    "    [   Y, Y, Y, N, N, N, N, N, N, N ], # <cat>\n",
    "    [   N, N, N, Y, Y, Y, N, N, N, N ], # <dog>\n",
    "    [   N, Y, Y, N, N, N, Y, N, N, N ], # <mat>\n",
    "    [   N, N, N, N, Y, Y, N, Y, N, N ], # <fog>\n",
    "    [   N, N, N, N, N, N, N, Y, Y, Y ]  # <fish>\n",
    "])\n",
    "\n",
    "# connections between output phoneme nodes and syllable program nodes [N_PHONEMEs][N_SYLLABLEs]\n",
    "PS_con = np.array([\n",
    "    # Cat Dog  Mat Fog  Fish\n",
    "    [ Y,   N,   N,  N,   N ], # K\n",
    "    [ Y,   N,   Y,  N,   N ], # E\n",
    "    [ Y,   N,   Y,  N,   N ], # T\n",
    "    [ N,   Y,   N,  N,   N ], # D\n",
    "    [ N,   Y,   N,  Y,   N ], # O\n",
    "    [ N,   Y,   N,  Y,   N ], # G\n",
    "    [ N,   N,   Y,  N,   N ], # M\n",
    "    [ N,   N,   N,  Y,   Y ], # F\n",
    "    [ N,   N,   N,  N,   Y ], # I\n",
    "    [ N,   N,   N,  N,   Y ]  # S\n",
    "])\n",
    "\n",
    "# connections between input and output phoneme nodes [N_PHONEMEs][N_PHONEMEs]\n",
    "PP_con = np.array([\n",
    "    # K    E    T   D    O    G   M   F   I  S \n",
    "    [ Y,   N,   N,  N,   N,   N,  N,  N,  N, N  ], # K\n",
    "    [ N,   Y,   N,  N,   N,   N,  N,  N,  N, N  ], # E\n",
    "    [ N,   N,   Y,  N,   N,   N,  N,  N,  N, N  ], # T\n",
    "    [ N,   N,   N,  Y,   N,   N,  N,  N,  N, N  ], # D\n",
    "    [ N,   N,   N,  N,   Y,   N,  N,  N,  N, N  ], # O\n",
    "    [ N,   N,   N,  N,   N,   Y,  N,  N,  N, N  ], # G\n",
    "    [ N,   N,   N,  N,   N,   N,  Y,  N,  N, N  ], # M\n",
    "    [ N,   N,   N,  N,   N,   N,  N,  Y,  N, N  ], # F\n",
    "    [ N,   N,   N,  N,   N,   N,  N,  N,  Y, N  ], # I\n",
    "    [ N,   N,   N,  N,   N,   N,  N,  N,  N, Y  ]  # S\n",
    "])\n",
    "\n",
    "# connections between input phoneme nodes and input morpheme nodes [N_PHONEMEs][N_MORPHEMEs]\n",
    "PiM_con = np.array([\n",
    "    # Cat Dog  Mat Fog  Fish \n",
    "    [ Y,   N,   N,  N,   N ], # K\n",
    "    [ Y,   N,   Y,  N,   N ], # E\n",
    "    [ Y,   N,   Y,  N,   N ], # T\n",
    "    [ N,   Y,   N,  N,   N ], # D\n",
    "    [ N,   Y,   N,  Y,   N ], # O\n",
    "    [ N,   Y,   N,  Y,   N ], # G\n",
    "    [ N,   N,   Y,  N,   N ], # M\n",
    "    [ N,   N,   N,  Y,   Y ], # F\n",
    "    [ N,   N,   N,  N,   Y ], # I\n",
    "    [ N,   N,   N,  N,   Y ]  # S\n",
    "])\n",
    "\n",
    "# connections between input morpheme and output morpheme nodes [N_MORPHEMEs][N_MORPHEMEs]\n",
    "iMM_con = np.array([\n",
    "    [ Y,  N,  N,  N,  N ],\n",
    "    [ N,  Y,  N,  N,  N ],\n",
    "    [ N,  N,  Y,  N,  N ],\n",
    "    [ N,  N,  N,  Y,  N ],\n",
    "    [ N,  N,  N,  N,  Y ]\n",
    "])\n",
    "\n",
    "# connections between input morpheme and lemma nodes [N_MORPHEMEs][N_LEMMAs]\n",
    "iML_con = np.array([\n",
    "    [ Y,  N,  N,  N,  N ],\n",
    "    [ N,  Y,  N,  N,  N ],\n",
    "    [ N,  N,  Y,  N,  N ],\n",
    "    [ N,  N,  N,  Y,  N ],\n",
    "    [ N,  N,  N,  N,  Y ]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf84543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English data on PPA for single word tasks: Savage et al. (2013) [N_GROUPs][N_TASKs]\n",
    "REAL_DATA_ENGLISH = np.array([\n",
    "    # Naming  Comprehension Repetition\n",
    "    [ 88.7,      97.0,      99.7 ], # Control\n",
    "    [ 78.3,      94.3,      79.7 ], # nfvPPA\n",
    "    [ 22.7,      63.3,      95.3 ], # svPPA\n",
    "    [ 41.3,      84.7,      84.7 ]  # lvPPA\n",
    "])\n",
    "\n",
    "# Dutch data on PPA for single word tasks: Janssen et al. (2021) [N_GROUPs][N_TASKs]\n",
    "REAL_DATA_DUTCH = np.array([\n",
    "    # Naming  Comprehension Repetition */\n",
    "    [ 90.3,      96.3,      96.7 ], # Control\n",
    "    [ 77.3,      97.7,      89.3 ], # nfvPPA\n",
    "    [ 29.0,      78.0,      96.3 ], # svPPA\n",
    "    [ 66.3,      93.7,      91.3 ]  # lvPPA\n",
    "])\n",
    "\n",
    "# Brambati T1 data on PPA for single word tasks: Brambati et al. (2015) [N_GROUPs][N_TASKs]\n",
    "REAL_DATA_BRAMBATI_T1 = np.array([\n",
    "    # Naming  Comprehension Repetition \n",
    "    [ 90.3,      96.3,      96.7 ], # Control (dummy, from Savage)\n",
    "    [ 85.3,      99.7,      83.7 ], # nfvPPA\n",
    "    [ 26.7,      88.0,      90.6 ], # svPPA\n",
    "    [ 69.3,      95.0,      69.0 ]  # lvPPA\n",
    "])\n",
    "\n",
    "# Brambati T2 data on PPA for single word tasks: Brambati et al. (2015) [N_GROUPs][N_TASKs]\n",
    "REAL_DATA_BRAMBATI_T2 = np.array([\n",
    "    # Naming  Comprehension Repetition\n",
    "    [ 90.3,      96.3,      96.7 ], # Control (dummy, from Savage)\n",
    "    [ 83.3,      94.8,      68.0 ], # nfvPPA\n",
    "    [ 19.3,      66.7,      82.3 ], # svPPA\n",
    "    [ 52.7,      95.0,      58.8 ]  # lvPPA\n",
    "])\n",
    "\n",
    "# Rohrer et al. (2013), logopenic patients (N=21), T1 baseline and T2 one year later\n",
    "# Mandelli et al. (2016), nonfluent/agrammatic patients (N=34), T1 baseline and T2 one year later\n",
    "\n",
    "# RohrerMandelli T1 data on PPA: Rohrer et al. (2013), Mandelli et al. (2016) [N_GROUPs][N_TASKs]\n",
    "REAL_DATA_ROHRERMANDELLI_T1 = np.array([\n",
    "    # Naming  Comprehension Repetition \n",
    "    [ 90.3,      96.3,      96.7 ], # Control (dummy, from Savage)\n",
    "    [ 76.7,      99.0,      81.5 ], # nfvPPA\n",
    "    [ 26.7,      88.0,      90.6 ], # svPPA (dummy, from Brambati)\n",
    "    [ 61.0,      94.0,      94.0 ]  # lvPPA\n",
    "])\n",
    "\n",
    "# RohrerMandelli T2 data on PPA: Rohrer et al. (2013), Mandelli et al. (2016) [N_GROUPs][N_TASKs]\n",
    "REAL_DATA_ROHRERMANDELLI_T2 = np.array([\n",
    "    # Naming  Comprehension Repetition \n",
    "    [ 90.3,      96.3,      96.7 ], # Control (dummy, from Savage)\n",
    "    [ 66.0,      90.0,      65.5 ], # nfvPPA\n",
    "    [ 26.7,      88.0,      90.6 ], # svPPA (dummy, from Brambati)\n",
    "    [ 43.0,      85.0,      77.0 ]  # lvPPA\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532b5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unscaled rate constants\n",
    "SEM = 0.0101\n",
    "LEM = 0.0074\n",
    "LEX = 0.0120\n",
    "DECAY = 0.0240\n",
    "EXT = 0.1965\n",
    "\n",
    "# parameter values\n",
    "CYCLE_TIME = 25                 # ms per link \n",
    "SEM_rate = SEM * STEP_SIZE   # prop per step_size ms \n",
    "LEM_rate = LEM * STEP_SIZE   # prop per step_size ms \n",
    "LEX_rate = LEX * STEP_SIZE   # prop per step_size ms \n",
    "DECAY_rate = DECAY * STEP_SIZE # prop per step_size ms \n",
    "EXTIN = EXT * STEP_SIZE      # act_units per step_size ms \n",
    "LEMLEXFRAC = 0.3 \n",
    "# fraction of LEX_rate spread between lemmas and output morphemes \n",
    "# implementing weak cascading of activation, see Roelofs (2008, JEP:LMC) \n",
    "\n",
    "FR = 0.10  # fraction of connection weight for input phoneme to input morpheme, cf. Roelofs (1997, Cognition)\n",
    "SEGMENT_DURATION = 125  # ms\n",
    "PICTURE_DURATION = 125  # ms\n",
    "\n",
    "# set here to simulate weight or decay lesion and what to print \n",
    "WEIGHT_LESION = 1\n",
    "DECAY_LESION = 0\n",
    "\n",
    "SHOW_RESULTS_ALL_VALUES = 0 # set here whether to print all values \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4a2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nengo settings\n",
    "\n",
    "N_NEURONS = 100 # num neurons in a pop\n",
    "DIM = 1 # dimensions\n",
    "T = 2\n",
    "CYCLE_TIME_NENGO = 0.025 \n",
    "PICTURE_DURATION_NENGO = 0.125\n",
    "SEGMENT_DURATION_NENGO = 0.125\n",
    "tau = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f0f4db",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f7e408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        CC_con = CC_con,\n",
    "        CL_con = CL_con,\n",
    "        LM_con = LM_con,\n",
    "        MP_con = MP_con,\n",
    "        PS_con = PS_con,\n",
    "        PP_con = PP_con,\n",
    "        PiM_con = PiM_con,\n",
    "        iMM_con = iMM_con,\n",
    "        iML_con = iML_con,\n",
    "    ):\n",
    "        \n",
    "        self.CC_con = CC_con\n",
    "        self.CL_con = CL_con\n",
    "        self.LM_con = LM_con\n",
    "        self.MP_con = MP_con\n",
    "        self.PS_con = PS_con\n",
    "        self.PP_con = PP_con\n",
    "        self.PiM_con = PiM_con\n",
    "        self.iMM_con = iMM_con\n",
    "        self.iML_con = iML_con\n",
    "        \n",
    "        self.REAL_DATA = np.zeros(shape=(N_GROUPs, N_TASKs))\n",
    "        self.SIM_DATA = np.zeros(shape=(N_GROUPs, N_TASKs))\n",
    "        self.GOODNESS_OF_FIT = np.zeros(N_lesion_values)\n",
    "        \n",
    "        self.WEIGHT_value = np.zeros(N_lesion_values)\n",
    "        self.DECAY_value = np.zeros(N_lesion_values)\n",
    "        \n",
    "        # concept and lemma\n",
    "        self.C_node_act = np.zeros(N_CONCEPTs)\n",
    "        self.L_node_act = np.zeros(N_LEMMAs)\n",
    "        # output form \n",
    "        self.M_node_act = np.zeros(N_MORPHEMEs)\n",
    "        self.oP_node_act = np.zeros(N_PHONEMEs)\n",
    "        self.S_node_act = np.zeros(N_SYLLABLEs)\n",
    "        # input form \n",
    "        self.iM_node_act = np.zeros(N_MORPHEMEs)\n",
    "        self.iP_node_act = np.zeros(N_PHONEMEs)\n",
    "\n",
    "        # input buffer for nodes \n",
    "        self.input_C = np.zeros(N_CONCEPTs)\n",
    "        self.input_L = np.zeros(N_LEMMAs)\n",
    "        self.input_M = np.zeros(N_MORPHEMEs)\n",
    "        self.input_iM = np.zeros(N_MORPHEMEs)\n",
    "        self.input_iP = np.zeros(N_PHONEMEs)\n",
    "        self.input_oP = np.zeros(N_PHONEMEs)\n",
    "        self.input_S = np.zeros(N_SYLLABLEs)\n",
    "        \n",
    "        # Aphasia parameters\n",
    "\n",
    "        # weight lesion \n",
    "        self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC = 0.0 # connections to/from output phonemes \n",
    "        self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA = 0.0 # connections to/within/from conceptual network\n",
    "        self.CONNECTION_DECREASE_LOGOPENIC = 0.0 # connections to/from lexical output forms, and b/w input/output phonemes\n",
    "        \n",
    "        # decay lesion\n",
    "        self.DECAY_INCREASE_NONFLUENT_AGRAMMATIC = 0.0 # output phonemes \n",
    "        self.DECAY_INCREASE_SEMANTIC_DEMENTIA = 0.0 # concepts\n",
    "        self.DECAY_INCREASE_LOGOPENIC = 0.0 # lexical output forms\n",
    "        \n",
    "        self.ACT_C = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_S = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "\n",
    "        # Activation of target concept, cat\n",
    "        self.ACT_CT = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        # Activation of conceptual relative, dog\n",
    "        self.ACT_CR= np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "\n",
    "        # Activation of target lemma, cat\n",
    "        self.ACT_LT = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        # Activation of lemma relative, i.e., semantically related, dog\n",
    "        self.ACT_LR = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "\n",
    "        # Activation of target syllable, cat\n",
    "        self.ACT_ST = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        # Activation of syllabic relative, mat\n",
    "        self.ACT_SR = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        \n",
    "        self.TOTAL_ACT_C = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_C = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_S = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_S = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        \n",
    "        # T = target, R = relative\n",
    "        self.TOTAL_ACT_CT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_CT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_CR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_CR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "\n",
    "        self.TOTAL_ACT_LT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_LT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_LR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_LR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "\n",
    "        self.TOTAL_ACT_ST = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_ST = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_SR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_SR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        \n",
    "        \n",
    "    def test(self):\n",
    "        print('hi')\n",
    "        \n",
    "    \n",
    "    def get_input_C(self):\n",
    "        ext_input_C = lambda t: self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA*EXT if t <= CYCLE_TIME_NENGO else (EXT*(self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA + 1) if t <= PICTURE_DURATION_NENGO else (EXT if t <= (CYCLE_TIME_NENGO + PICTURE_DURATION_NENGO) else 0.0))\n",
    "        return ext_input_C\n",
    "    \n",
    "\n",
    "    def get_input_iP(self):\n",
    "        # phonetic inputs for comprehension and repetition tasks  \n",
    "        ext_input_iP_pK = lambda t: EXT if t <= SEGMENT_DURATION_NENGO else 0.0\n",
    "        ext_input_iP_pE = lambda t: 0.0 if t <= SEGMENT_DURATION_NENGO else (EXT if t <= 2*SEGMENT_DURATION_NENGO else 0.0)\n",
    "        ext_input_iP_pT = lambda t: 0.0 if t <= 2*SEGMENT_DURATION_NENGO else (EXT if t <= 3*SEGMENT_DURATION_NENGO else 0.0) \n",
    "        \n",
    "        return ext_input_iP_pK, ext_input_iP_pE, ext_input_iP_pT\n",
    "        \n",
    "        \n",
    "    def nengo_model(self, lesion_value, group, task):\n",
    "        model = nengo.Network(seed = seed)\n",
    "        \n",
    "        with model:\n",
    "            \n",
    "            ### CONCEPTS\n",
    "            \n",
    "            # create concept ensembles\n",
    "            C_cat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            C_dog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            C_mat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            C_fog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            C_fish_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            \n",
    "            # connection from input\n",
    "            Bp = 1\n",
    "            \n",
    "            # input for naming task\n",
    "            if task == NAMING:\n",
    "                input_func_cat = self.get_input_C()\n",
    "                cat_input = nengo.Node(input_func_cat)\n",
    "                nengo.Connection(cat_input, C_cat_ens, synapse=tau, transform=Bp)\n",
    "            \n",
    "            # connections b/w concepts\n",
    "            \n",
    "            # recurrent connections\n",
    "            # self.C_node_act = self.C_node_act * (1.0 - (DECAY_rate * self.DECAY_INCREASE_SEMANTIC_DEMENTIA)) + self.input_C\n",
    "            Ap_C = 1.0 - (DECAY * self.DECAY_INCREASE_SEMANTIC_DEMENTIA)\n",
    "            nengo.Connection(C_cat_ens, C_cat_ens, synapse=tau, transform=Ap_C)\n",
    "            nengo.Connection(C_dog_ens, C_dog_ens, synapse=tau, transform=Ap_C)\n",
    "            nengo.Connection(C_mat_ens, C_mat_ens, synapse=tau, transform=Ap_C)\n",
    "            nengo.Connection(C_fog_ens, C_fog_ens, synapse=tau, transform=Ap_C)\n",
    "            nengo.Connection(C_fish_ens, C_fish_ens, synapse=tau, transform=Ap_C)\n",
    "            \n",
    "            # relation connections\n",
    "            # self.input_C[i] += (self.C_node_act[j] * (self.CC_con[j][i] * self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA))\n",
    "            CC_con_val = SEM * self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA\n",
    "            nengo.Connection(C_cat_ens, C_dog_ens, synapse=tau, transform=CC_con_val)\n",
    "            nengo.Connection(C_dog_ens, C_cat_ens, synapse=tau, transform=CC_con_val)\n",
    "            nengo.Connection(C_cat_ens, C_fish_ens, synapse=tau, transform=CC_con_val)\n",
    "            nengo.Connection(C_fish_ens, C_cat_ens, synapse=tau, transform=CC_con_val)\n",
    "            nengo.Connection(C_dog_ens, C_fish_ens, synapse=tau, transform=CC_con_val)\n",
    "            nengo.Connection(C_fish_ens, C_dog_ens, synapse=tau, transform=CC_con_val)\n",
    "            \n",
    "            ###  LEMMAS\n",
    "            \n",
    "            # create lemma ensembles\n",
    "            L_cat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            L_dog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            L_mat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            L_fog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            L_fish_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            \n",
    "            # connections between lemmas\n",
    "            \n",
    "            # recurrent connections\n",
    "            # self.L_node_act = self.L_node_act * (1.0 - DECAY_rate) + self.input_L\n",
    "            Ap_L = 1.0 - DECAY\n",
    "            nengo.Connection(L_cat_ens, L_cat_ens, synapse=tau, transform=Ap_L)\n",
    "            nengo.Connection(L_dog_ens, L_dog_ens, synapse=tau, transform=Ap_L)\n",
    "            nengo.Connection(L_mat_ens, L_mat_ens, synapse=tau, transform=Ap_L)\n",
    "            nengo.Connection(L_fog_ens, L_fog_ens, synapse=tau, transform=Ap_L)\n",
    "            nengo.Connection(L_fish_ens, L_fish_ens, synapse=tau, transform=Ap_L)\n",
    "            \n",
    "            # relation connections\n",
    "            # self.input_C[i] += (self.L_node_act[j] * self.CL_con[j][i] * self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA)\n",
    "            CL_con_val = LEM * self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA\n",
    "            nengo.Connection(L_cat_ens, C_cat_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(L_dog_ens, C_dog_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(L_mat_ens, C_mat_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(L_fog_ens, C_fog_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(L_fish_ens, C_fish_ens, synapse=tau, transform=CL_con_val)\n",
    "            # self.input_L[i] += (self.C_node_act[j] * self.CL_con[j][i] *  self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA)\n",
    "            nengo.Connection(C_cat_ens, L_cat_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(C_dog_ens, L_dog_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(C_mat_ens, L_mat_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(C_fog_ens, L_fog_ens, synapse=tau, transform=CL_con_val)\n",
    "            nengo.Connection(C_fish_ens, L_fish_ens, synapse=tau, transform=CL_con_val)\n",
    "            \n",
    "            ### MORPHEMES\n",
    "            \n",
    "            # create input morpheme ensembles\n",
    "            iM_cat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iM_dog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iM_mat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iM_fog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iM_fish_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            # create output morpheme ensembles\n",
    "            M_cat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            M_dog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            M_mat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            M_fog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            M_fish_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            \n",
    "            # connections b/w morphemes\n",
    "            \n",
    "            # recurrent connections\n",
    "            # self.iM_node_act = self.iM_node_act * (1.0 - DECAY_rate) + self.input_iM\n",
    "            Ap_iM = 1.0 - DECAY\n",
    "            nengo.Connection(iM_cat_ens, iM_cat_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(iM_dog_ens, iM_dog_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(iM_mat_ens, iM_mat_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(iM_fog_ens, iM_fog_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(iM_fish_ens, iM_fish_ens, synapse=tau, transform=Ap_iM)\n",
    "            # self.M_node_act = self.M_node_act * (1.0 - (DECAY_rate * self.DECAY_INCREASE_LOGOPENIC)) + self.input_M\n",
    "            Ap_M = 1.0 - (DECAY * self.DECAY_INCREASE_LOGOPENIC)\n",
    "            nengo.Connection(M_cat_ens, M_cat_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(M_dog_ens, M_dog_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(M_mat_ens, M_mat_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(M_fog_ens, M_fog_ens, synapse=tau, transform=Ap_iM)\n",
    "            nengo.Connection(M_fish_ens, M_fish_ens, synapse=tau, transform=Ap_iM)\n",
    "            \n",
    "            # relation connections\n",
    "            # self.input_L[i] += (self.iM_node_act[j] * self.iML_con[j][i])\n",
    "            iML_con_val = LEX\n",
    "            nengo.Connection(iM_cat_ens, L_cat_ens, synapse=tau, transform=iML_con_val)\n",
    "            nengo.Connection(iM_dog_ens, L_dog_ens, synapse=tau, transform=iML_con_val)\n",
    "            nengo.Connection(iM_mat_ens, L_mat_ens, synapse=tau, transform=iML_con_val)\n",
    "            nengo.Connection(iM_fog_ens, L_fog_ens, synapse=tau, transform=iML_con_val)\n",
    "            nengo.Connection(iM_fish_ens, L_fish_ens, synapse=tau, transform=iML_con_val)\n",
    "            # self.input_M[i] += (self.L_node_act[j] * LEMLEXFRAC * self.LM_con[j][i] * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "            LM_con_val = LEMLEXFRAC * LEX * self.CONNECTION_DECREASE_LOGOPENIC\n",
    "            nengo.Connection(L_cat_ens, M_cat_ens, synapse=tau, transform=LM_con_val)\n",
    "            nengo.Connection(L_dog_ens, M_dog_ens, synapse=tau, transform=LM_con_val)\n",
    "            nengo.Connection(L_mat_ens, M_mat_ens, synapse=tau, transform=LM_con_val)\n",
    "            nengo.Connection(L_fog_ens, M_fog_ens, synapse=tau, transform=LM_con_val)\n",
    "            nengo.Connection(L_fish_ens, M_fish_ens, synapse=tau, transform=LM_con_val)\n",
    "            # self.input_M[i] += (self.iM_node_act[j] * self.iMM_con[j][i] * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "            iMM_con_val = LEX * self.CONNECTION_DECREASE_LOGOPENIC\n",
    "            nengo.Connection(iM_cat_ens, M_cat_ens, synapse=tau, transform=iMM_con_val)\n",
    "            nengo.Connection(iM_dog_ens, M_dog_ens, synapse=tau, transform=iMM_con_val)\n",
    "            nengo.Connection(iM_mat_ens, M_mat_ens, synapse=tau, transform=iMM_con_val)\n",
    "            nengo.Connection(iM_fog_ens, M_fog_ens, synapse=tau, transform=iMM_con_val)\n",
    "            nengo.Connection(iM_fish_ens, M_fish_ens, synapse=tau, transform=iMM_con_val)\n",
    "            \n",
    "            ### PHONEMES\n",
    "            \n",
    "            # create input phoneme ensembles\n",
    "            #  K  E  T  D  O  G  M  F  I  S \n",
    "            iP_K_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_E_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_T_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_D_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_O_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_G_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_M_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_F_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_I_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            iP_S_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            # create output phoneme ensembles\n",
    "            oP_K_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_E_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_T_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_D_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_O_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_G_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_M_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_F_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_I_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            oP_S_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            \n",
    "            # input for naming task\n",
    "            if task == COMPREHENSION or task == REPETITION:\n",
    "                input_func_pK, input_func_pE, input_func_pT = self.get_input_iP()\n",
    "                pK_input = nengo.Node(input_func_pK)\n",
    "                pE_input = nengo.Node(input_func_pE)\n",
    "                pT_input = nengo.Node(input_func_pT)\n",
    "                nengo.Connection(pK_input, iP_K_ens, synapse=tau, transform=Bp)\n",
    "                nengo.Connection(pE_input, iP_E_ens, synapse=tau, transform=Bp)\n",
    "                nengo.Connection(pT_input, iP_T_ens, synapse=tau, transform=Bp)\n",
    "            \n",
    "            # connections b/w phonemes\n",
    "            \n",
    "            # recurrent connections\n",
    "            # self.oP_node_act = self.oP_node_act * (1.0 - (DECAY_rate * self.DECAY_INCREASE_NONFLUENT_AGRAMMATIC)) + self.input_oP\n",
    "            Ap_oP = 1.0 - (DECAY * self.DECAY_INCREASE_NONFLUENT_AGRAMMATIC)\n",
    "            nengo.Connection(oP_K_ens, oP_K_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_E_ens, oP_E_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_T_ens, oP_T_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_D_ens, oP_D_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_O_ens, oP_O_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_G_ens, oP_G_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_M_ens, oP_M_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_F_ens, oP_F_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_I_ens, oP_I_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(oP_S_ens, oP_S_ens, synapse=tau, transform=Ap_oP)\n",
    "            # self.iP_node_act = self.iP_node_act * (1.0 - DECAY_rate) + self.input_iP\n",
    "            Ap_oP = 1.0 - DECAY\n",
    "            nengo.Connection(iP_K_ens, iP_K_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_E_ens, iP_E_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_T_ens, iP_T_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_D_ens, iP_D_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_O_ens, iP_O_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_G_ens, iP_G_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_M_ens, iP_M_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_F_ens, iP_F_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_I_ens, iP_I_ens, synapse=tau, transform=Ap_oP)\n",
    "            nengo.Connection(iP_S_ens, iP_S_ens, synapse=tau, transform=Ap_oP)\n",
    "            \n",
    "            # relation connections\n",
    "            # self.input_oP[i] += (self.M_node_act[j] * self.MP_con[j][i] * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "            MP_con_val = LEX * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC\n",
    "            nengo.Connection(M_cat_ens, oP_K_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_cat_ens, oP_E_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_cat_ens, oP_T_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_dog_ens, oP_D_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_dog_ens, oP_O_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_dog_ens, oP_G_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_mat_ens, oP_M_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_mat_ens, oP_E_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_mat_ens, oP_T_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_fog_ens, oP_F_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_fog_ens, oP_O_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_fog_ens, oP_G_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_fish_ens, oP_F_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_fish_ens, oP_I_ens, synapse=tau, transform=MP_con_val)\n",
    "            nengo.Connection(M_fish_ens, oP_S_ens, synapse=tau, transform=MP_con_val)\n",
    "            # self.input_oP[i] += (self.iP_node_act[j] * self.PP_con[j][i] * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "            PP_con_val = LEX * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC\n",
    "            nengo.Connection(iP_K_ens, oP_K_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_E_ens, oP_E_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_T_ens, oP_T_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_D_ens, oP_D_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_O_ens, oP_O_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_G_ens, oP_G_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_M_ens, oP_M_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_F_ens, oP_F_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_I_ens, oP_I_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(iP_S_ens, oP_S_ens, synapse=tau, transform=PP_con_val)\n",
    "            # self.input_iP[i] += (self.oP_node_act[j] * self.PP_con[j][i] * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "            nengo.Connection(oP_K_ens, iP_K_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_E_ens, iP_E_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_T_ens, iP_T_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_D_ens, iP_D_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_O_ens, iP_O_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_G_ens, iP_G_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_M_ens, iP_M_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_F_ens, iP_F_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_I_ens, iP_I_ens, synapse=tau, transform=PP_con_val)\n",
    "            nengo.Connection(oP_S_ens, iP_S_ens, synapse=tau, transform=PP_con_val)\n",
    "            # self.input_iM[i] += (self.iP_node_act[j] * self.PiM_con[j][i])\n",
    "            PiM_con_val = FR * LEX\n",
    "            nengo.Connection(iP_K_ens, iM_cat_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_E_ens, iM_cat_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_T_ens, iM_cat_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_D_ens, iM_dog_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_O_ens, iM_dog_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_G_ens, iM_dog_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_M_ens, iM_mat_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_E_ens, iM_mat_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_T_ens, iM_mat_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_F_ens, iM_fog_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_O_ens, iM_fog_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_G_ens, iM_fog_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_F_ens, iM_fish_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_I_ens, iM_fish_ens, synapse=tau, transform=PiM_con_val)\n",
    "            nengo.Connection(iP_S_ens, iM_fish_ens, synapse=tau, transform=PiM_con_val)\n",
    "            \n",
    "            ### SYLLABLE PROGRAMS\n",
    "            \n",
    "            # create syllable program ensembles\n",
    "            S_cat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            S_dog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            S_mat_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            S_fog_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            S_fish_ens = nengo.Ensemble(n_neurons=N_NEURONS, dimensions=DIM, neuron_type=nengo.Direct())\n",
    "            \n",
    "            # connections b/w syllable programs\n",
    "            \n",
    "            # recurrent connections\n",
    "            # self.S_node_act = self.S_node_act * (1.0 - DECAY_rate) + self.input_S\n",
    "            Ap_S = 1.0 - DECAY\n",
    "            nengo.Connection(S_cat_ens, S_cat_ens, synapse=tau, transform=Ap_S)\n",
    "            nengo.Connection(S_dog_ens, S_dog_ens, synapse=tau, transform=Ap_S)\n",
    "            nengo.Connection(S_mat_ens, S_mat_ens, synapse=tau, transform=Ap_S)\n",
    "            nengo.Connection(S_fog_ens, S_fog_ens, synapse=tau, transform=Ap_S)\n",
    "            nengo.Connection(S_fish_ens, S_fish_ens, synapse=tau, transform=Ap_S)\n",
    "            \n",
    "            # relation connections\n",
    "            # self.input_S[i] += (self.oP_node_act[j] * self.PS_con[j][i] * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC)\n",
    "            PS_con_val = LEX * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC\n",
    "            nengo.Connection(oP_K_ens, S_cat_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_E_ens, S_cat_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_T_ens, S_cat_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_D_ens, S_dog_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_O_ens, S_dog_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_G_ens, S_dog_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_M_ens, S_mat_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_E_ens, S_mat_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_T_ens, S_mat_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_F_ens, S_fog_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_O_ens, S_fog_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_G_ens, S_fog_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_F_ens, S_fish_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_I_ens, S_fish_ens, synapse=tau, transform=PS_con_val)\n",
    "            nengo.Connection(oP_S_ens, S_fish_ens, synapse=tau, transform=PS_con_val)\n",
    "            \n",
    "            # probes\n",
    "            if task == NAMING:\n",
    "                probe_in = nengo.Probe(cat_input)\n",
    "                \n",
    "            if task == COMPREHENSION or task == REPETITION:\n",
    "                probe_in = nengo.Probe(pK_input)\n",
    "                \n",
    "            probe_C = nengo.Probe(C_cat_ens)\n",
    "            probe_S = nengo.Probe(S_cat_ens)\n",
    "            probe_CT = nengo.Probe(C_cat_ens)\n",
    "            probe_CR = nengo.Probe(C_dog_ens)\n",
    "            probe_LT = nengo.Probe(L_cat_ens)\n",
    "            probe_LR = nengo.Probe(L_dog_ens)\n",
    "            probe_ST = nengo.Probe(S_cat_ens)\n",
    "            probe_SR = nengo.Probe(S_mat_ens)\n",
    "            \n",
    "        with nengo.Simulator(model, progress_bar=False) as sim:\n",
    "            sim.run(T)\n",
    "            t = sim.trange()\n",
    "            x = sim.data[probe_in]\n",
    "            x_C = sim.data[probe_C]\n",
    "            x_S = sim.data[probe_S]\n",
    "            x_CT = sim.data[probe_CT]\n",
    "            x_CR = sim.data[probe_CR]\n",
    "            x_LT = sim.data[probe_LT]\n",
    "            x_LR = sim.data[probe_LR]\n",
    "            x_ST = sim.data[probe_ST]\n",
    "            x_SR = sim.data[probe_SR]\n",
    "            \n",
    "        # saving activation of critical nodes\n",
    "        self.ACT_C[lesion_value, :, group, task] = x_C.flatten()\n",
    "        self.ACT_S[lesion_value, :, group, task] = x_S.flatten()\n",
    "        self.ACT_CT[lesion_value, :, group, task] = x_CT.flatten()\n",
    "        self.ACT_CR[lesion_value, :, group, task] = x_CR.flatten()\n",
    "        self.ACT_LT[lesion_value, :, group, task] = x_LT.flatten()\n",
    "        self.ACT_LR[lesion_value, :, group, task] = x_LR.flatten()\n",
    "        self.ACT_ST[lesion_value, :, group, task] = x_ST.flatten()\n",
    "        self.ACT_SR[lesion_value, :, group, task] = x_SR.flatten()\n",
    "            \n",
    "        return t, x, x_C\n",
    "        \n",
    "        \n",
    "    def plot_activation(self):\n",
    "        plt.figure()\n",
    "        # N_lesion_values, N_STEPs, N_GROUPs, N_TASKs\n",
    "        # NORMAL = 0, NONFLUENT_AGRAMMATIC = 1, SEMANTIC_DEMENTIA = 2, LOGOPENIC = 3\n",
    "        # NAMING = 0, COMPREHENSION = 1, REPETITION = 2\n",
    "        for i in range(N_lesion_values):\n",
    "            plt.plot(self.ACT_C[i, :, 0, 0], label=f'{i}')\n",
    "        plt.title('Roelof C')\n",
    "        plt.ylim([0, None])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        for i in range(N_lesion_values):\n",
    "            plt.plot(self.ACT_LT[i, :, 0, 0], label=f'{i}')\n",
    "        plt.title('Roelof LT')\n",
    "        plt.ylim([0, None])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        for i in range(N_lesion_values):\n",
    "            plt.plot(self.ACT_CR[i, :, 0, 0], label=f'{i}')\n",
    "        plt.title('Roelof CR')\n",
    "        plt.ylim([0, None])\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def plot_activation_nengo(self, lesion_value, group, task):\n",
    "        t, x, x_hat = self.nengo_model(lesion_value, group, task)\n",
    "        \n",
    "        in_ = [4.9125000000000005,9.825000000000001,9.825000667781561,9.825001869959381,9.82500272509615,4.912503216953124,3.473655303682204e-06,2.9325537966604885e-06,1.7906538489855988e-06,9.63473050570425e-07,4.843373821926735e-07,2.3333969116069153e-07,1.0918798138585572e-07,5.002012645852661e-08,2.2547664159710646e-08,1.0035568397812841e-08,4.421091893642436e-09,1.9312881556992187e-09,8.376981386632366e-10,3.6116936621432784e-10,1.549105882223694e-10,6.614409630769253e-11,2.8130674802232873e-11,1.1921922038953034e-11,5.036805048828655e-12,2.1220068047741253e-12,8.917448078573953e-13,3.738860483154391e-13,1.56434194543311e-13,6.532740149957534e-14,2.7233176926876737e-14,1.1334448610236372e-14,4.710367330404825e-15,1.9548288778105695e-15,8.102230822401824e-16,3.3541336106352664e-16,1.3869800781853782e-16,5.729347567274587e-17,2.3643583098526635e-17,9.748104270532727e-18,4.015587830498096e-18,1.6528047251513252e-18,6.797622089241884e-19,2.7936601342577654e-19,1.1473286209620463e-19,4.7088530987580616e-20,1.9313888856985247e-20,7.917075176297147e-21,3.243489642635408e-21,1.3280804131208161e-21,5.43514294473893e-22,2.2232189857064505e-22,9.089656592833824e-23,3.714628366805963e-23,1.5173790673690383e-23,6.1957130309921946e-24,2.5287983341741494e-24,1.0317383755172254e-24,4.207884947193939e-25,1.7155487101427824e-25,6.991862547162191e-26,2.8486476816550304e-26,1.1602343968857989e-26,4.7240960291726706e-27,1.9229246895834228e-27,7.824935648706835e-28,3.183305796660626e-28,1.2946696737943068e-28,5.264127188245033e-29,2.1398539461979123e-29,8.696322941893424e-30,3.53333006060192e-30,1.4352676148527774e-30,5.828873884972542e-31,2.366695395436088e-31,9.607463016533419e-32,3.8992970818546317e-32,1.5822593328911906e-32,6.419262450593736e-33,2.6038203225619146e-33]\n",
    "        \n",
    "        plt.figure()\n",
    "        #plt.plot(t, x, label='Input')\n",
    "        plt.plot(t, x_hat, label='Output')\n",
    "        #plt.plot(t, in_, label='Input R*')\n",
    "        plt.legend()\n",
    "        plt.title('Nengo')\n",
    "        plt.ylim([0, None])\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def set_real_data_matrix(self, assessment):\n",
    "        if assessment == ENGLISH:\n",
    "            self.REAL_DATA = REAL_DATA_ENGLISH\n",
    "        elif assessment == DUTCH:\n",
    "            self.REAL_DATA = REAL_DATA_DUTCH\n",
    "        elif assessment == BRAMBATI_T1:\n",
    "            self.REAL_DATA = REAL_DATA_BRAMBATI_T1\n",
    "        elif assessment == BRAMBATI_T2:\n",
    "            self.REAL_DATA = REAL_DATA_BRAMBATI_T2\n",
    "        elif assessment == ROHRERMANDELLI_T1:\n",
    "            self.REAL_DATA = REAL_DATA_ROHRERMANDELLI_T1\n",
    "        elif (assessment == ROHRERMANDELLI_T2):\n",
    "            self.REAL_DATA = REAL_DATA_ROHRERMANDELLI_T2\n",
    "                    \n",
    "                    \n",
    "    def set_spreading_rates(self):\n",
    "        self.ACT_C = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_S = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_CT = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_CR = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_LT = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_LR = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_ST = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "        self.ACT_SR = np.zeros(shape=(N_lesion_values, N_STEPs, N_GROUPs, N_TASKs))\n",
    "\n",
    "        self.CC_con *= SEM_rate\n",
    "        self.CL_con *= LEM_rate\n",
    "        self.LM_con *= LEX_rate\n",
    "        self.MP_con *= LEX_rate\n",
    "        self.PS_con *= LEX_rate\n",
    "\n",
    "        # connections for input phonemes to output phonemes, input morphemes, input morphemes to lemmas\n",
    "\n",
    "        self.PP_con *= LEX_rate\n",
    "        self.PiM_con *= (FR * LEX_rate)\n",
    "        self.iMM_con *= LEX_rate\n",
    "        self.iML_con *= LEX_rate\n",
    "        \n",
    "        \n",
    "    def reset_network(self):\n",
    "        self.C_node_act = np.zeros(N_CONCEPTs)\n",
    "        self.L_node_act = np.zeros(N_LEMMAs)\n",
    "        self.M_node_act = np.zeros(N_MORPHEMEs)\n",
    "        self.iM_node_act = np.zeros(N_MORPHEMEs)\n",
    "        self.iP_node_act = np.zeros(N_PHONEMEs)\n",
    "        self.oP_node_act = np.zeros(N_PHONEMEs)\n",
    "        self.S_node_act = np.zeros(N_SYLLABLEs)\n",
    "        \n",
    "        \n",
    "    def set_aphasic_parameters(self, group, lesion_value):\n",
    "        WEIGHT_FACTOR, DECAY_FACTOR = 0.0, 0.0\n",
    "\n",
    "        if WEIGHT_LESION:\n",
    "            WEIGHT_FACTOR = self.WEIGHT_value[lesion_value]  \n",
    "        else:\n",
    "            WEIGHT_FACTOR = 1.0\n",
    "\n",
    "        if DECAY_LESION:\n",
    "            DECAY_FACTOR = self.DECAY_value[lesion_value]   \n",
    "        else:\n",
    "            DECAY_FACTOR = 1.0\n",
    "\n",
    "\n",
    "        # setting of weight parameters\n",
    "\n",
    "        if group == NONFLUENT_AGRAMMATIC:\n",
    "            self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC = WEIGHT_FACTOR\n",
    "        else:\n",
    "            self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC = 1.0 # normal \n",
    "\n",
    "        if group == SEMANTIC_DEMENTIA:\n",
    "            self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA = WEIGHT_FACTOR\n",
    "        else:\n",
    "            self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA = 1.0 # normal\n",
    "\n",
    "        if group == LOGOPENIC:\n",
    "            self.CONNECTION_DECREASE_LOGOPENIC = WEIGHT_FACTOR\n",
    "        else:\n",
    "            self.CONNECTION_DECREASE_LOGOPENIC = 1.0 # normal\n",
    "\n",
    "        # setting of decay parameters\n",
    "\n",
    "        if group == NONFLUENT_AGRAMMATIC:\n",
    "            self.DECAY_INCREASE_NONFLUENT_AGRAMMATIC = DECAY_FACTOR\n",
    "        else:\n",
    "            self.DECAY_INCREASE_NONFLUENT_AGRAMMATIC = 1.0 # normal\n",
    "\n",
    "        if group == SEMANTIC_DEMENTIA:\n",
    "            self.DECAY_INCREASE_SEMANTIC_DEMENTIA = DECAY_FACTOR\n",
    "        else:\n",
    "            self.DECAY_INCREASE_SEMANTIC_DEMENTIA = 1.0 # normal\n",
    "\n",
    "        if group == LOGOPENIC:\n",
    "            self.DECAY_INCREASE_LOGOPENIC = DECAY_FACTOR\n",
    "        else:\n",
    "            self.DECAY_INCREASE_LOGOPENIC = 1.0 # normal\n",
    "            \n",
    "        \n",
    "    # NETWORK UPDATING ROUTINES \n",
    "\n",
    "    def update_network(self, task, T):\n",
    "        self.set_input_to_zero()\n",
    "        self.get_external_input(task, T)\n",
    "        self.get_internal_input()\n",
    "        self.update_activation_of_nodes()\n",
    "        \n",
    "        \n",
    "    def set_input_to_zero(self):\n",
    "        self.input_C = np.zeros(N_CONCEPTs)\n",
    "        self.input_L = np.zeros(N_LEMMAs)\n",
    "        self.input_M = np.zeros(N_MORPHEMEs)\n",
    "        self.input_iM = np.zeros(N_MORPHEMEs)\n",
    "        self.input_iP = np.zeros(N_PHONEMEs)\n",
    "        self.input_oP = np.zeros(N_PHONEMEs)\n",
    "        self.input_S = np.zeros(N_SYLLABLEs)\n",
    "        \n",
    "        \n",
    "    def get_external_input(self, task, T):\n",
    "        if task == NAMING:\n",
    "            # picture input\n",
    "            if (T >= 0 and T < PICTURE_DURATION):\n",
    "                self.input_C[CAT] += self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA * EXTIN\n",
    "\n",
    "            # enhancement\n",
    "            if ((T >= (CYCLE_TIME)) and  (T < (CYCLE_TIME + PICTURE_DURATION))):\n",
    "                self.input_C[CAT] += EXTIN\n",
    "        \n",
    "\n",
    "        if (task == COMPREHENSION or task == REPETITION): \n",
    "\n",
    "            # spoken word input\n",
    "            if ((0 <= T) and (T < SEGMENT_DURATION)):\n",
    "                self.input_iP[pK] += EXTIN\n",
    "\n",
    "            if ((SEGMENT_DURATION <= T) and (T < (2 * SEGMENT_DURATION))):\n",
    "                self.input_iP[pE] += EXTIN\n",
    "\n",
    "\n",
    "            if ((2 * SEGMENT_DURATION <= T) and (T < (3 * SEGMENT_DURATION))): \n",
    "                self.input_iP[pT] += EXTIN\n",
    "                \n",
    "                \n",
    "    def get_internal_input(self):\n",
    "        # input activation for concept nodes\n",
    "\n",
    "        for i in range(N_CONCEPTs):\n",
    "            for j in range(N_CONCEPTs):\n",
    "                self.input_C[i] += (self.C_node_act[j] * (self.CC_con[j][i] * self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA))\n",
    "                \n",
    "        for i in range(N_CONCEPTs):\n",
    "            for j in range(N_LEMMAs):\n",
    "                self.input_C[i] += (self.L_node_act[j] * self.CL_con[j][i] * self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA)\n",
    "\n",
    "        # input activation for lemma nodes\n",
    "        for i in range(N_LEMMAs):\n",
    "            for j in range(N_CONCEPTs):\n",
    "                self.input_L[i] += (self.C_node_act[j] * self.CL_con[j][i] *  self.CONNECTION_DECREASE_SEMANTIC_DEMENTIA)\n",
    "                \n",
    "        for i in range(N_LEMMAs):\n",
    "            for j in range(N_MORPHEMEs):                 \n",
    "                self.input_L[i] += (self.iM_node_act[j] * self.iML_con[j][i])\n",
    "                \n",
    "        # input activation for output morpheme nodes\n",
    "        for i in range(N_MORPHEMEs):\n",
    "            for j in range(N_LEMMAs):\n",
    "                self.input_M[i] += (self.L_node_act[j] * LEMLEXFRAC * self.LM_con[j][i] \n",
    "                                    * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "\n",
    "        for i in range(N_MORPHEMEs):\n",
    "            for j in range(N_MORPHEMEs):\n",
    "                self.input_M[i] += (self.iM_node_act[j] * self.iMM_con[j][i] * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "\n",
    "        # input activation for output phoneme nodes\n",
    "        for i in range(N_PHONEMEs):\n",
    "            for j in range(N_MORPHEMEs):\n",
    "                self.input_oP[i] += (self.M_node_act[j] * self.MP_con[j][i] \n",
    "                                     * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "\n",
    "        for i in range(N_PHONEMEs):\n",
    "            for j in range(N_PHONEMEs):\n",
    "                self.input_oP[i] += (self.iP_node_act[j] * self.PP_con[j][i] \n",
    "                                     * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "        \n",
    "        # input activation for syllable program nodes\n",
    "        for i in range(N_SYLLABLEs):\n",
    "            for j in range(N_PHONEMEs):\n",
    "                self.input_S[i] += (self.oP_node_act[j] * self.PS_con[j][i] \n",
    "                                    * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC)\n",
    "\n",
    "        # input activation for input phoneme nodes\n",
    "        for i in range(N_PHONEMEs):\n",
    "            for j in range(N_PHONEMEs):\n",
    "                self.input_iP[i] += (self.oP_node_act[j] * self.PP_con[j][i] \n",
    "                                     * self.CONNECTION_DECREASE_NONFLUENT_AGRAMMATIC * self.CONNECTION_DECREASE_LOGOPENIC)\n",
    "        \n",
    "        # input activation for input morpheme nodes\n",
    "        for i in range(N_MORPHEMEs):\n",
    "            for j in range(N_PHONEMEs):\n",
    "                self.input_iM[i] += (self.iP_node_act[j] * self.PiM_con[j][i])\n",
    "        \n",
    "                \n",
    "                \n",
    "    def update_activation_of_nodes(self):\n",
    "        self.C_node_act = self.C_node_act * (1.0 - (DECAY_rate * self.DECAY_INCREASE_SEMANTIC_DEMENTIA)) + self.input_C\n",
    "        self.L_node_act = self.L_node_act * (1.0 - DECAY_rate) + self.input_L\n",
    "        self.M_node_act = self.M_node_act * (1.0 - (DECAY_rate * self.DECAY_INCREASE_LOGOPENIC)) + self.input_M\n",
    "        self.oP_node_act = self.oP_node_act * (1.0 - (DECAY_rate * self.DECAY_INCREASE_NONFLUENT_AGRAMMATIC)) + self.input_oP\n",
    "        self.iP_node_act = self.iP_node_act * (1.0 - DECAY_rate) + self.input_iP\n",
    "        self.iM_node_act = self.iM_node_act * (1.0 - DECAY_rate) + self.input_iM\n",
    "        self.S_node_act = self.S_node_act * (1.0 - DECAY_rate) + self.input_S\n",
    "            \n",
    "    \n",
    "    def determine_activation_critical_nodes(self, lesion_value, step, group, task):\n",
    "        self.ACT_C[lesion_value][step][group][task] = self.C_node_act[CAT]\n",
    "        self.ACT_S[lesion_value][step][group][task] = self.S_node_act[CAT]\n",
    "        self.ACT_CT[lesion_value][step][group][task] = self.C_node_act[CAT]\n",
    "        self.ACT_CR[lesion_value][step][group][task] = self.C_node_act[DOG]\n",
    "        self.ACT_LT[lesion_value][step][group][task] = self.L_node_act[CAT]\n",
    "        self.ACT_LR[lesion_value][step][group][task] = self.L_node_act[DOG]\n",
    "        self.ACT_ST[lesion_value][step][group][task] = self.S_node_act[CAT]\n",
    "        self.ACT_SR[lesion_value][step][group][task] = self.S_node_act[MAT]\n",
    "        \n",
    "        \n",
    "    def compute_activation_results(self):\n",
    "        self.TOTAL_ACT_C = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_S = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_C = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_S = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "\n",
    "        self.TOTAL_ACT_CT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_CR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_CT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_CR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "\n",
    "        self.TOTAL_ACT_LT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_LR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_LT = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_LR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "\n",
    "        self.TOTAL_ACT_ST = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.TOTAL_ACT_SR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_ST = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "        self.MEAN_ACT_SR = np.zeros(shape=(N_lesion_values, N_GROUPs, N_TASKs))\n",
    "\n",
    "        for lesion_value in range(N_lesion_values):\n",
    "            for group in range(N_GROUPs):\n",
    "                for task in range(N_TASKs): \n",
    "                    for i in range(N_STEPs): \n",
    "                        self.TOTAL_ACT_C[lesion_value][group][task] += self.ACT_C[lesion_value][i][group][task]\n",
    "                        self.TOTAL_ACT_S[lesion_value][group][task] += self.ACT_S[lesion_value][i][group][task]\n",
    "                        self.TOTAL_ACT_CT[lesion_value][group][task] += self.ACT_CT[lesion_value][i][group][task]\n",
    "                        self.TOTAL_ACT_CR[lesion_value][group][task] += self.ACT_CR[lesion_value][i][group][task]\n",
    "                        self.TOTAL_ACT_LT[lesion_value][group][task] += self.ACT_LT[lesion_value][i][group][task]\n",
    "                        self.TOTAL_ACT_LR[lesion_value][group][task] += self.ACT_LR[lesion_value][i][group][task]\n",
    "                        self.TOTAL_ACT_ST[lesion_value][group][task] += self.ACT_ST[lesion_value][i][group][task]\n",
    "                        self.TOTAL_ACT_SR[lesion_value][group][task] += self.ACT_SR[lesion_value][i][group][task]\n",
    "\n",
    "                    self.MEAN_ACT_C[lesion_value][group][task] = (self.TOTAL_ACT_C[lesion_value][group][task] / N_STEPs)\n",
    "                    self.MEAN_ACT_S[lesion_value][group][task] = (self.TOTAL_ACT_S[lesion_value][group][task] / N_STEPs)\n",
    "                    self.MEAN_ACT_CT[lesion_value][group][task] = (self.TOTAL_ACT_CT[lesion_value][group][task] / N_STEPs)\n",
    "                    self.MEAN_ACT_CR[lesion_value][group][task] = (self.TOTAL_ACT_CR[lesion_value][group][task] / N_STEPs)\n",
    "                    self.MEAN_ACT_LT[lesion_value][group][task] = (self.TOTAL_ACT_LT[lesion_value][group][task] / N_STEPs)\n",
    "                    self.MEAN_ACT_LR[lesion_value][group][task] = (self.TOTAL_ACT_LR[lesion_value][group][task] / N_STEPs)\n",
    "                    self.MEAN_ACT_ST[lesion_value][group][task] = (self.TOTAL_ACT_ST[lesion_value][group][task] / N_STEPs)\n",
    "                    self.MEAN_ACT_SR[lesion_value][group][task] = (self.TOTAL_ACT_SR[lesion_value][group][task] / N_STEPs)\n",
    "                    \n",
    "                    \n",
    "    # FITS AND PRINTING\n",
    "\n",
    "    def print_heading(self):\n",
    "        print(\"\\n\")\n",
    "        print(\"WEAVER++/ARC model simulation of primary progressive aphasia (c) Ardi Roelofs\\n\")\n",
    "        print(\"Simulation of group studies \\n\")\n",
    "        \n",
    "        \n",
    "    def print_parameters(self):\n",
    "        print(\"Parameter values:\\n\")\n",
    "        print(f\"cycle time : {CYCLE_TIME : 6d} [ms]\\n\")\n",
    "        print(f\"sem_rate   : {SEM_rate/STEP_SIZE : .4f} [prop/ms]\\n\")\n",
    "        print(f\"lem_rate   : {LEM_rate/STEP_SIZE : .4f} [prop/ms]\\n\")\n",
    "        print(f\"exin       : {EXTIN/STEP_SIZE : .4f} [act_units/ms]\\n\")\n",
    "        print(f\"d          : {DECAY_rate/STEP_SIZE : .4f} [prop/ms]\\n\")\n",
    "        \n",
    "        \n",
    "    def compute_fits_and_print_results_on_screen(self, assessment):\n",
    "        LV = 0.0 # lesion value\n",
    "\n",
    "        self.SIM_DATA = np.zeros(shape=(N_GROUPs, N_TASKs))\n",
    "        self.GOODNESS_OF_FIT = np.zeros(N_lesion_values)\n",
    "\n",
    "        if assessment == ENGLISH:\n",
    "            print(\"\\nAssessment is Savage et al. (2013), English\\n\")\n",
    "        if assessment == DUTCH:\n",
    "            print(\"\\nAssessment is Janssen et al. (2022), Dutch\\n\")\n",
    "        if assessment == BRAMBATI_T1:\n",
    "            print(\"\\nAssessment is Brambati et al. (2015), baseline T1\\n\")\n",
    "        if assessment == BRAMBATI_T2:\n",
    "            print(\"\\nAssessment is Brambati et al. (2015), follow up T2\\n\")\n",
    "        if assessment == ROHRERMANDELLI_T1:\n",
    "            print(\"\\nAssessment is Rohrer et al. (2013) and Mandelli et al. (2016), baseline T1\\n\")\n",
    "        if assessment == ROHRERMANDELLI_T2:\n",
    "            print(\"\\nAssessment is Rohrer et al. (2013) and Mandelli et al. (2016), follow up T2\\n\")\n",
    "\n",
    "\n",
    "        for group in range(N_GROUPs): \n",
    "            print(\" \\n\")\n",
    "\n",
    "            if group == NORMAL:\n",
    "                print(\"NORMAL \\n\")\n",
    "            elif group == NONFLUENT_AGRAMMATIC:\n",
    "                print(\"NONFLUENT/AGRAMMATIC \\n\")\n",
    "            elif group == SEMANTIC_DEMENTIA:\n",
    "                print(\"SEMANTIC DEMENTIA  \\n\")\n",
    "            elif group == LOGOPENIC:\n",
    "                print(\"LOGOPENIC  \\n\")\n",
    "\n",
    "            if assessment == ENGLISH:\n",
    "                print(\"\\nSavage et al. (2013), English\\n\")\n",
    "            if assessment == DUTCH:\n",
    "                print(\"\\nAssessment is Janssen et al. (2022), Dutch\\n\")\n",
    "            if assessment == BRAMBATI_T1:\n",
    "                print(\"\\nAssessment is Brambati et al. (2015), baseline T1\\n\")\n",
    "            if assessment == BRAMBATI_T2:\n",
    "                print(\"\\nAssessment is Brambati et al. (2015), follow up T2\\n\")\n",
    "            if assessment == ROHRERMANDELLI_T1:\n",
    "                print(\"\\nAssessment is Rohrer et al. (2013) and Mandelli et al. (2016), baseline T1\\n\")\n",
    "            if assessment == ROHRERMANDELLI_T2:\n",
    "                print(\"\\nAssessment is Rohrer et al. (2013) and Mandelli et al. (2016), follow up T2\\n\")\n",
    "\n",
    "            print(\"        Naming   Comprehension  Repetition \\n\")\n",
    "            print(f\"Real:   {self.REAL_DATA[group][NAMING] : 5.2f}         {self.REAL_DATA[group][COMPREHENSION] : 5.2f}        {self.REAL_DATA[group][REPETITION] : 5.2f} \\n\")\n",
    "            print(\"Lesion:                                    MAE\\n\")\n",
    "\n",
    "\n",
    "            for lesion_value in range(N_lesion_values): \n",
    "\n",
    "                self.SIM_DATA[group][NAMING] = (self.MEAN_ACT_ST[lesion_value][group][NAMING] - self.MEAN_ACT_SR[lesion_value][group][NAMING]) / (self.MEAN_ACT_ST[lesion_value][NORMAL][NAMING] - self.MEAN_ACT_SR[lesion_value][NORMAL][NAMING]) * 100.0\n",
    "\n",
    "                self.SIM_DATA[group][COMPREHENSION] = (self.MEAN_ACT_CT[lesion_value][group][COMPREHENSION] - self.MEAN_ACT_CR[lesion_value][group][COMPREHENSION]) / (self.MEAN_ACT_CT[lesion_value][NORMAL][COMPREHENSION] - self.MEAN_ACT_CR[lesion_value][NORMAL][COMPREHENSION]) * 100.0\n",
    "\n",
    "                self.SIM_DATA[group][REPETITION] = (self.MEAN_ACT_ST[lesion_value][group][REPETITION] - self.MEAN_ACT_SR[lesion_value][group][REPETITION]) / (self.MEAN_ACT_ST[lesion_value][NORMAL][REPETITION] - self.MEAN_ACT_SR[lesion_value][NORMAL][REPETITION]) * 100.0\n",
    "\n",
    "                if group == NORMAL:\n",
    "                    LV = 1.0\n",
    "                elif WEIGHT_LESION:\n",
    "                    LV = self.WEIGHT_value[lesion_value]\n",
    "                elif DECAY_LESION:\n",
    "                    LV = self.DECAY_value[lesion_value]\n",
    "\n",
    "                self.GOODNESS_OF_FIT[lesion_value] = (abs(self.REAL_DATA[group][NAMING] - self.SIM_DATA[group][NAMING])\n",
    "                    + abs(self.REAL_DATA[group][COMPREHENSION] - self.SIM_DATA[group][COMPREHENSION])\n",
    "                    + abs(self.REAL_DATA[group][REPETITION] - self.SIM_DATA[group][REPETITION]) ) / 3.0\n",
    "\n",
    "                if SHOW_RESULTS_ALL_VALUES: # toggle for printing the results for all lesion values \n",
    "                    sim_combined = (abs(self.REAL_DATA[group][NAMING] - self.SIM_DATA[group][NAMING]) \n",
    "                                    + abs(self.REAL_DATA[group][COMPREHENSION] - self.SIM_DATA[group][COMPREHENSION]) \n",
    "                                    + abs(self.REAL_DATA[group][REPETITION] - self.SIM_DATA[group][REPETITION])) / 3.0\n",
    "                    \n",
    "                    print(f\"{LV : 5.2f}   {self.SIM_DATA[group][NAMING] : 5.2f}        {self.SIM_DATA[group][COMPREHENSION] : 5.2f}        {self.SIM_DATA[group][REPETITION] : 5.2f}     {sim_combined : 5.2f}\\n\")\n",
    "\n",
    "            a = 0\n",
    "            for i in range(N_lesion_values):\n",
    "                if self.GOODNESS_OF_FIT[a] > self.GOODNESS_OF_FIT[i]:\n",
    "                    a = i\n",
    "\n",
    "\n",
    "            if WEIGHT_LESION:\n",
    "                print(f\"Best fit weight value = {self.WEIGHT_value[a] : .2f}   MAE = {self.GOODNESS_OF_FIT[a] : .2f}\\n\")\n",
    "            if DECAY_LESION:\n",
    "                print(f\"Best fit decay value = {self.DECAY_value[a] : .2f}   MAE = {self.GOODNESS_OF_FIT[a] : .2f}\\n\")\n",
    "\n",
    "            sim_naming = (self.MEAN_ACT_ST[a][group][NAMING] - self.MEAN_ACT_SR[a][group][NAMING]) / (self.MEAN_ACT_ST[a][NORMAL][NAMING] - self.MEAN_ACT_SR[a][NORMAL][NAMING]) * 100.0\n",
    "            sim_comprehension = (self.MEAN_ACT_CT[a][group][COMPREHENSION] - self.MEAN_ACT_CR[a][group][COMPREHENSION]) / (self.MEAN_ACT_CT[a][NORMAL][COMPREHENSION] - self.MEAN_ACT_CR[a][NORMAL][COMPREHENSION]) * 100.0\n",
    "            sim_repetition = (self.MEAN_ACT_ST[a][group][REPETITION] - self.MEAN_ACT_SR[a][group][REPETITION]) / (self.MEAN_ACT_ST[a][NORMAL][REPETITION] - self.MEAN_ACT_SR[a][NORMAL][REPETITION]) * 100.0\n",
    "                \n",
    "            print(f\"Sim:   {sim_naming : 5.2f}         {sim_comprehension : 5.2f}        {sim_repetition : 5.2f} \\n\")\n",
    "\n",
    "\n",
    "    def print_assessment_results(self):\n",
    "        for assessment in range(N_ASSESSMENTs):\n",
    "            self.set_real_data_matrix(assessment)\n",
    "            self.compute_activation_results()\n",
    "            self.compute_fits_and_print_results_on_screen(assessment)\n",
    "            input()\n",
    "            \n",
    "    \n",
    "    # MAIN ROUTINES \n",
    "\n",
    "    def main(self):\n",
    "        ls = 0.0 # exact lesion value \n",
    "\n",
    "        self.print_heading()\n",
    "        self.print_parameters()\n",
    "        self.set_spreading_rates()\n",
    "\n",
    "        if WEIGHT_LESION:\n",
    "            ls = 0.0\n",
    "            for lesion_value in range(N_lesion_values):\n",
    "                # values between maximally damaged, 0.0, and minimally damaged, 0.99\n",
    "                self.WEIGHT_value[lesion_value] = ls \n",
    "                ls += 0.01\n",
    "\n",
    "        if DECAY_LESION:\n",
    "             # values between minimally damaged, 1.01, and maximally damaged, i.e., full decay, 1.66\n",
    "            ls = 1.01\n",
    "            for lesion_value in range(N_lesion_values):\n",
    "                self.DECAY_value[lesion_value] = ls\n",
    "                ls += 0.01\n",
    "                \n",
    "        \n",
    "        # running model\n",
    "        for group in range(N_GROUPs):\n",
    "            for task in range(N_TASKs): \n",
    "                for lesion_value in range(N_lesion_values): \n",
    "                    print(f'Running group {group}, task {task}, lv {lesion_value}.')\n",
    "                        \n",
    "                    self.reset_network()\n",
    "                    self.set_aphasic_parameters(group, lesion_value)\n",
    "                        \n",
    "                    self.nengo_model(lesion_value, group, task)\n",
    "                        \n",
    "                        \n",
    "                    '''\n",
    "\n",
    "                    T = 0 # time in ms\n",
    "                    step = 0\n",
    "                    while T < (N_STEPs * STEP_SIZE):\n",
    "\n",
    "                        self.update_network(task, T)\n",
    "                        self.determine_activation_critical_nodes(lesion_value, step, group, task)\n",
    "\n",
    "                        T += STEP_SIZE\n",
    "                        step += 1\n",
    "                    '''\n",
    "                            \n",
    "                    if group == 0 and task == 0 and lesion_value == 0:\n",
    "                        self.plot_activation_nengo(lesion_value, group, task)\n",
    "                            \n",
    "\n",
    "        # MAPPING TO HUMAN DATA\n",
    "        self.print_assessment_results()\n",
    "\n",
    "        print('Finished.')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8c0fb",
   "metadata": {},
   "source": [
    "### Run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b142c8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WEAVER++/ARC model simulation of primary progressive aphasia (c) Ardi Roelofs\n",
      "\n",
      "Simulation of group studies \n",
      "\n",
      "Parameter values:\n",
      "\n",
      "cycle time :     25 [ms]\n",
      "\n",
      "sem_rate   :  0.0101 [prop/ms]\n",
      "\n",
      "lem_rate   :  0.0074 [prop/ms]\n",
      "\n",
      "exin       :  0.1965 [act_units/ms]\n",
      "\n",
      "d          :  0.0240 [prop/ms]\n",
      "\n",
      "Running group 0, task 0, lv 0.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGxCAYAAABBZ+3pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABal0lEQVR4nO3dd3zTdf4H8Nc3aZN0Jd0LCpRSRguUsvcQWQoeLnCBKA5O9ESOU3uOU29wuH6oiJwewwWix5ATT4ZQhhSk0LILBQotpXulM13f3x9pArGDpk3yTdLX8/HIQ5N8v9+8v5TYl58piKIogoiIiMiOyaQugIiIiOhWGFiIiIjI7jGwEBERkd1jYCEiIiK7x8BCREREdo+BhYiIiOweAwsRERHZPQYWIiIisnsMLERERGT3GFiIqF3WrVsHQRCgUqlw9erVRu+PHz8effv2laAyInImDCxEZBE6nQ6vvvqq1GUQkZNiYCEii5g6dSrWr1+PEydOSF0KETkhBhYisogXX3wRfn5+eOmll1o8ThRFrFy5EgMGDICbmxt8fHxw33334fLlyybHGbqSjh49ijFjxsDd3R3du3fHP//5T9TX15sce+bMGUyePBnu7u4ICAjAwoULsX37dgiCgPj4eJNj16xZg5iYGKhUKvj6+uLuu+/GuXPnLPJnQETWw8BCRBbh5eWFV199FTt27MCePXuaPe7pp5/GokWLcPvtt2Pr1q1YuXIlzpw5g5EjRyInJ8fk2OzsbDz88MN45JFHsG3bNkybNg1xcXH46quvjMdkZWVh3LhxOH/+PD755BN88cUXKC0txbPPPtvos5cuXYr58+cjOjoamzdvxgcffICTJ09ixIgRSE1NtdwfBhFZnkhE1A5r164VAYhHjx4VdTqd2L17d3Hw4MFifX29KIqiOG7cODE6OloURVFMSEgQAYjvvfeeyTUyMjJENzc38cUXXzS+Nm7cOBGAeOTIEZNjo6KixClTphif/+lPfxIFQRDPnDljctyUKVNEAOLevXtFURTFoqIi0c3NTbzjjjtMjktPTxeVSqX40EMPte8Pgoisii0sRGQxCoUCf/vb35CYmIhvv/220fs//PADBEHAI488gtraWuMjODgYMTExjbpvgoODMXToUJPX+vfvbzIbad++fejbty+ioqJMjnvwwQdNnickJKCyshLz5s0zeT0sLAy33XYbfv755zbcMRHZCgMLEVnUAw88gIEDB+KVV15BTU2NyXs5OTkQRRFBQUFwdXU1eRw+fBj5+fkmx/v5+TW6vlKpRGVlpfF5QUEBgoKCGh3329cKCgoAACEhIY2ODQ0NNb5PRPbJReoCiMi5CIKAZcuWYdKkSfj0009N3vP394cgCDhw4ACUSmWjc5t67Vb8/PwajX0B9ONffnscoB/z8lvXr1+Hv7+/2Z9NRLbDFhYisrjbb78dkyZNwltvvYWysjLj69OnT4coisjMzMTgwYMbPfr162f2Z40bNw6nT5/G2bNnTV7/5ptvTJ6PGDECbm5uJgN2AeDatWvYs2cPJk6caPZnE5HtsIWFiKxi2bJlGDRoEHJzcxEdHQ0AGDVqFJ566ik89thjSExMxNixY+Hh4YGsrCwcPHgQ/fr1w+9//3uzPmfRokVYs2YNpk2bhrfeegtBQUFYv349UlJSAAAymf7/y7y9vfHaa6/hz3/+M+bOnYsHH3wQBQUFePPNN6FSqfCXv/zFsn8ARGRRbGEhIquIjY1tNPAVAP71r39hxYoV2L9/Px544AHceeedeP3111FeXt5ogG1rhIaGYt++fejZsycWLFiAhx9+GAqFAm+99RYAfVAxiIuLw7///W+cOHECM2fOxLPPPovo6GgcOnQIkZGRbb5XIrI+QRRFUeoiiIgs7amnnsKGDRtQUFAAhUIhdTlE1E7sEiIih/fWW28hNDQU3bt3R1lZGX744Qf8+9//xquvvsqwQuQkGFiIyOG5urrinXfewbVr11BbW4vIyEi8//77eP7556UujYgshF1CREREZPc46JaIiIjsHgMLERER2T0GFiIiIrJ7TjPotr6+HtevX4eXlxcEQZC6HCIiImoFURRRWlqK0NBQ40KPTXGawHL9+nWEhYVJXQYRERG1QUZGBjp37tzs+04TWLy8vADob1itVktcDREREbWGVqtFWFiY8fd4c5wmsBi6gdRqNQMLERGRg7nVcA4OuiUiIiK7x8BCREREdo+BhYiIiOye04xhISIiak5dXR1qamqkLqNDksvlcHFxafeSIwwsRETk1MrKynDt2jVw6zzpuLu7IyQkpF27pzOwEBGR06qrq8O1a9fg7u6OgIAALixqY6Ioorq6Gnl5eUhLS0NkZGSLi8O1hIGFiIicVk1NDURRREBAANzc3KQup0Nyc3ODq6srrl69iurqaqhUqjZdh4NuiYjI6bFlRVptbVUxuYYF6iAiIiKyKgYWIiIisnsMLERERGT3GFiIiIjsVEZGBubPn4/Q0FAoFAp07doVzz//PAoKClp9jStXrkAQBCQnJ1ulRkEQsHXrVqtc+2YMLERERHbo8uXLGDx4MC5cuIANGzbg4sWLWLVqFX7++WeMGDEChYWFUpdoUwwsduZ0Zgl+/9UxXMork7oUIiKnI4oiKqprJXmYu3DdwoULoVAosHPnTowbNw5dunTBtGnTsHv3bmRmZuKVV14B0HQLh7e3N9atWwcACA8PBwDExsZCEASMHz8eADBv3jzMnDkTb775JgIDA6FWq/H000+jurraeJ1u3bph+fLlJtceMGAA3njjDeP7AHD33XdDEATjc2vgOix2Zv7nR5Gj1SE1twy7F4+TuhwiIqdSWVOHqNd3SPLZZ9+aAndF637tFhYWYseOHfj73//eaP2Y4OBgPPzww9i4cSNWrlx5y2v9+uuvGDp0KHbv3o3o6GiT1WZ//vlnqFQq7N27F1euXMFjjz0Gf39//P3vf29VnUePHkVgYCDWrl2LqVOnQi6Xt+q8tmALi53J0eoAABdz2cJCRNRRpaamQhRF9OnTp8n3+/Tpg6KiIuTl5d3yWgEBAQAAPz8/BAcHw9fX1/ieQqHAmjVrEB0djTvvvBNvvfUWPvzwQ9TX17eqTsO1vb29ERwcbHxuDWxhISKiDsPNVY6zb02R7LMtxdC91N4F8WJiYuDu7m58PmLECJSVlSEjIwNdu3Zt17UtjYHFjvy2f7OovBo+Hm3fKIqIiEwJgtDqbhkp9ejRA4Ig4OzZs5g5c2aj91NSUuDj4wN/f38IgtDo90d7d6Y2BCGZTGbxa7cVu4TsSFGF6V+CCzmlElVCRERS8vPzw6RJk7By5UpUVlaavJednY2vv/4as2fPhiAICAgIQFZWlvH91NRUVFRUGJ8bxqzU1dU1+pwTJ06YXP/w4cPw9PRE586dAaDRtbVaLdLS0kyu4erq2uS1LY2BxY5cLzb9S8nAQkTUca1YsQI6nQ5TpkzB/v37kZGRgZ9++gmTJk1Cp06djANjb7vtNqxYsQLHjx9HYmIiFixYAFdXV+N1AgMD4ebmhp9++gk5OTkoKSkxvlddXY358+fj7Nmz+N///oe//OUvePbZZ417/9x222348ssvceDAAZw+fRqPPvpoo4G13bp1w88//4zs7GwUFRVZ7c+DgcWO/DawpGQzsBARdVSRkZFITExEREQEZs+ejYiICDz11FOYMGECEhISjINn33vvPYSFhWHs2LF46KGHsGTJEpNxKS4uLvjwww/xr3/9C6Ghofjd735nfG/ixImIjIzE2LFjMWvWLMyYMcM4ZRkA4uLiMHbsWEyfPh133HEHZs6ciYiICJM633vvPezatQthYWGIjY212p+HIJoxMXzp0qXYvHkzUlJS4ObmhpEjR2LZsmXo1auX8RhRFPHmm2/i008/RVFREYYNG4aPP/4Y0dHRLV5706ZNeO2113Dp0iVERETg73//O+6+++5W34hWq4VGo0FJSQnUanWrz7Mn635Jwxv/PWt83q+TBv99brSEFRERObaqqiqkpaUhPDwcKpVK6nLsyrx581BcXGyTVWpb+jm09ve3WS0s+/btw8KFC3H48GHs2rULtbW1mDx5MsrLy43HvP3223j//fexYsUKHD16FMHBwZg0aRJKS5tvLUhISMDs2bMxZ84cnDhxAnPmzMGsWbNw5MgRc8pzeFklVQCAqdHBAIBzWVpUVlu/X5CIiMjemRVYfvrpJ8ybNw/R0dGIiYnB2rVrkZ6ejmPHjgHQt64sX74cr7zyCu655x707dsXn3/+OSoqKrB+/fpmr7t8+XJMmjQJcXFx6N27N+Li4jBx4sRGq+s5u8yGLqHB3XwQpFaitl7E6esltziLiIjI+bVrDIth4I6hHy0tLQ3Z2dmYPHmy8RilUolx48bh0KFDzV4nISHB5BwAmDJlSovn6HQ6aLVak4ejM4xhCfV2Q2yYDwDg2FXrDWAiIqKOa926dTbpDrKUNgcWURSxePFijB49Gn379gWgn2oFAEFBQSbHBgUFGd9rSnZ2ttnnLF26FBqNxvgICwtr663YDUOXUKi3G4aE60PgLxfzpSyJiIjILrQ5sDz77LM4efIkNmzY0Oi93668J4riLVfjM/ecuLg4lJSUGB8ZGRlmVG9/aurqkaNtCCwaFcb19AcAHEkr5DgWIqJ2MnfjQbIsS/z5tymwPPfcc9i2bRv27t1rXFwG0G/IBKBRy0hubm6jFpSbBQcHm32OUqmEWq02eTiyHG0V6kXAVS7A31OJiABPhGpUqK6tx+G0AqnLIyJySIY1Q27egZhsz7CQ3c3rw5jLrPWJRVHEc889hy1btiA+Pt64ZbVBeHg4goODsWvXLuNc7Orqauzbtw/Lli1r9rojRozArl278MILLxhf27lzJ0aOHGlOeQ7N0B0UonGDTKZvWRrfOxDrj6Tjx5NZmNArUMryiIgckouLC9zd3ZGXlwdXV1fjgmhkG6IooqKiArm5ufD29m7Xbs5mBZaFCxdi/fr1+P777+Hl5WVsFdFoNHBzc4MgCFi0aBH+8Y9/IDIyEpGRkfjHP/4Bd3d3PPTQQ8brzJ07F506dcLSpUsBAM8//zzGjh2LZcuW4Xe/+x2+//577N69GwcPHmzzjTkaw4DbEM2N+ekzB3TSB5ZTWXjrd33hprDett1ERM5IEASEhIQgLS0NV69elbqcDsuwm3N7mBVYPvnkEwDA+PHjTV5fu3Yt5s2bBwB48cUXUVlZiWeeeca4cNzOnTvh5eVlPD49Pd0k5Y4cORLffPMNXn31Vbz22muIiIjAxo0bMWzYsDbeluMxTGnu5O1mfG1wVx+E+boho7ASW5Mz8eDQLlKVR0TksBQKBSIjI9ktJBFXV9d2tawYmLXSrT1z9JVuX9t6Gl8evopnJ/TAkik3Vg7+94HL+Nv2c+js44a9S8bDVc7mTCIich5WWemWrOfmNVhu9vCwrvD3VOJaUSU+2J0qRWlERESSY2CxE4YuoRBv0z0W3BRyvHFXFADg4/iLyC/T2bw2IiIiqTGw2AnDLKFOv2lhAYDp/UMRpFZCFIGs4ipbl0ZERCQ5BhY7UKarRUllDQDTWUI383ZTAIDxOCIioo6EgcUOZDV0B3mpXOClanpRHY27/vXiSo5yJyKijoeBxQ5cb6E7yEDjpg8sbGEhIqKOiIHFDjQ3Q+hmhsBSXMHAQkREHQ8Dix1oapXb3/JuCCxatrAQEVEHxMBiB643zPxhCwsREVHTGFjswI0uoRZaWNw5hoWIiDouBhY7kKO9sVNzc9QcdEtERB0YA4vERFE0LhrX4hgWd/06LMUMLERE1AExsEhMW1mLypo6AECQuvnAouGgWyIi6sAYWCSWpdWPX/Fxd4XKtfntt28MuuXCcURE1PEwsEjM0B0U3ML4FeDGtOby6jrU1NVbvS4iIiJ7wsAisZxWjF8Bbgy6BTjwloiIOh4GFondaGFpObDIZQK8VC4AGFiIiKjjYWCRWLYhsLQw4NaA+wkREVFHxcAisSxt61pYgJsWj+Nqt0RE1MEwsEgsu+TW+wgZsIWFiIg6KgYWiWW3ctAtwKnNRETUcTGwSKhcVwttVS2AW09rBgCNG1e7JSKijomBRULZDeNXPJUu8FS63PJ4Xw99C0tROVtYiIioY2FgkVB2K6c0G/h6KAEABQwsRETUwTCwSKg1mx7ezM9D3yVUyMBCREQdDAOLhHK0rV+DBQB8GViIiKiDYmCRUJYZU5qBG4GFXUJERNTRMLBIKLuVGx8aGAJLUXk1RFG0Wl1ERET2hoFFQjf2EVK26nhDYKmtF43ToYmIiDoCBhYJ3RjD0roWFpWrHB4KOQCOYyEioo6FgUUiuto65JfpQ0drx7AAgK+nYeCtzip1ERER2SMGFonkavWBQ+kiM25q2BrGtVjK2MJCREQdh9mBZf/+/ZgxYwZCQ0MhCAK2bt1q8r4gCE0+3nnnnWavuW7duibPqaqqMvuGHMXNa7AIgtDq87gWCxERdURmB5by8nLExMRgxYoVTb6flZVl8lizZg0EQcC9997b4nXVanWjc1Wq1neVOBrDlOagVq7BYsCpzURE1BHdegOb35g2bRqmTZvW7PvBwcEmz7///ntMmDAB3bt3b/G6giA0OteZGQbcmjN+BWALCxERdUxWHcOSk5OD7du3Y/78+bc8tqysDF27dkXnzp0xffp0JCUltXi8TqeDVqs1eTiSLDPXYDG4eS0WIiKijsKqgeXzzz+Hl5cX7rnnnhaP6927N9atW4dt27Zhw4YNUKlUGDVqFFJTU5s9Z+nSpdBoNMZHWFiYpcu3qmwz9xEyYJcQERF1RFYNLGvWrMHDDz98y7Eow4cPxyOPPIKYmBiMGTMG3377LXr27ImPPvqo2XPi4uJQUlJifGRkZFi6fKvKMnOnZgPuJ0RERB2R2WNYWuvAgQM4f/48Nm7caPa5MpkMQ4YMabGFRalUQqls3Qqx9sjcjQ8N/Dz195xfxnVYiIio47BaC8vq1asxaNAgxMTEmH2uKIpITk5GSEiIFSqTXn29iNxSfeAwt4Ul0EsfWPJKdaiv535CRETUMZjdwlJWVoaLFy8an6elpSE5ORm+vr7o0qULAECr1eK7777De++91+Q15s6di06dOmHp0qUAgDfffBPDhw9HZGQktFotPvzwQyQnJ+Pjjz9uyz3ZvYLyatTVixCEG7N+Wsu/oYWltl5EcWWNsYuIiIjImZkdWBITEzFhwgTj88WLFwMAHn30Uaxbtw4A8M0330AURTz44INNXiM9PR0y2Y3GneLiYjz11FPIzs6GRqNBbGws9u/fj6FDh5pbnkMwdAf5eyrhIjevkUvhIoOvhwKF5dXILa1iYCEiog5BEEXRKfoVtFotNBoNSkpKoFarpS6nRXtScvD4ukT07aTGD8+NMfv8qcv3IyW7FF88PhRjewZYoUIiIiLbaO3vb+4lJIGchn2EgrzatpJvQMM4FsM4GCIiImfHwCIBw8aHgWbOEDIIbAg6uaXOu9cSERHRzRhYJJDTEDQMM37MFahuaGHRsoWFiIg6BgYWCeQ2DLo1d+NDgwDPG1ObiYiIOgIGFgkYx7Co29nCwi4hIiLqIBhYJJDTzhaWG2NY2MJCREQdAwOLjdXVi8Zl9QPb2sLidWMMi5PMSiciImoRA4uNFZTpUC8CMgHw82hfl1BlTR3KdLWWLI+IiMguMbDYmGH8SoCXEnKZ0KZruCtc4KnUL1LMbiEiIuoIGFhsrL3jVwwMA3ZzSjjwloiInB8Di43dWIOlfYEl1NsNAHCdgYWIiDoABhYby9G2b8CtQaimIbAUV7a7JiIiInvHwGJjeQ0tLG3dR8ggxFt/flYJAwsRETk/BhYba++icQaGLqHMYnYJERGR82NgsTFLDbo1dAllsUuIiIg6AAYWG7PYGJaGLqHrxZVcPI6IiJweA4sN1dbVo6C8IbC0dwxLQwtLeXUdtJVcPI6IiJwbA4sN5ZdVQxQBuUyAn4eiXddyU8jh23CN6xx4S0RETo6BxYYM41cCvZSQtXGV25vd3C1ERETkzBhYbMgYWNo54NbA0C3ExeOIiMjZMbDYUE7Dvj9BXu0bcGvQyTC1uYgtLERE5NwYWGwo19jCYpnA0tlHH1gyiioscj0iIiJ7xcBiQ7lay8wQMuji6w4AyChkYCEiIufGwGJDeWWGwGKZFpYufvrAcrWAgYWIiJwbA4sN5TWMYQmwVGBpaGEpqaxBSUWNRa5JRERkjxhYbCi/oYXF39MygcVd4WIMP1cLyy1yTSIiInvEwGIj9fWiMbBYqoUFALo2tLKkcxwLERE5MQYWGymprEFNnX7PHz/P9q1yezOOYyEioo6AgcVGDK0rGjdXKF3kFruuYRxLOgMLERE5MQYWG7H0gFuDroYWFo5hISIiJ8bAYiOGKc0BFhpwa9DF1wMAW1iIiMi5MbDYiKGFxd/CLSzd/fWB5XpJFSqqay16bSIiInthdmDZv38/ZsyYgdDQUAiCgK1bt5q8P2/ePAiCYPIYPnz4La+7adMmREVFQalUIioqClu2bDG3NLtmrRYWHw8F/Dz0g3gv57FbiIiInJPZgaW8vBwxMTFYsWJFs8dMnToVWVlZxsePP/7Y4jUTEhIwe/ZszJkzBydOnMCcOXMwa9YsHDlyxNzy7FZ+aTUAy49hAYCIQE8AwMXcMotfm4iIyB64mHvCtGnTMG3atBaPUSqVCA4ObvU1ly9fjkmTJiEuLg4AEBcXh3379mH58uXYsGFDk+fodDrodDrjc61W2+rPk0KecdE4y01pNogI8MSvaYUMLERE5LSsMoYlPj4egYGB6NmzJ5588knk5ua2eHxCQgImT55s8tqUKVNw6NChZs9ZunQpNBqN8REWFmaR2q3FWrOEAKBHQwvLpTwGFiIick4WDyzTpk3D119/jT179uC9997D0aNHcdttt5m0hvxWdnY2goKCTF4LCgpCdnZ2s+fExcWhpKTE+MjIyLDYPViDpZflv1lEgH7gLVtYiIjIWZndJXQrs2fPNv573759MXjwYHTt2hXbt2/HPffc0+x5giCYPBdFsdFrN1MqlVAqLf/L3xrq6kUUWHin5psZWliuFJSjtq4eLnJO/iIiIudi9d9sISEh6Nq1K1JTU5s9Jjg4uFFrSm5ubqNWF0dVWF6NehEQBMDXw/JjWEI1bnBzlaOmTsRV7ilEREROyOqBpaCgABkZGQgJCWn2mBEjRmDXrl0mr+3cuRMjR460dnk2YegO8nVXWKX1QyYTEBGo7xa6kF1q8esTERFJzezfnmVlZUhOTkZycjIAIC0tDcnJyUhPT0dZWRmWLFmChIQEXLlyBfHx8ZgxYwb8/f1x9913G68xd+5c44wgAHj++eexc+dOLFu2DCkpKVi2bBl2796NRYsWtfsG7YE1B9waRIWoAQDnsux7thQREVFbmD2GJTExERMmTDA+X7x4MQDg0UcfxSeffIJTp07hiy++QHFxMUJCQjBhwgRs3LgRXl5exnPS09Mhk93ISiNHjsQ333yDV199Fa+99hoiIiKwceNGDBs2rD33ZjdsGVjOMrAQEZETMjuwjB8/HqIoNvv+jh07bnmN+Pj4Rq/dd999uO+++8wtxyFYc4aQQR9jCwu7hIiIyPlwOokN2KKFpU+oPrBkFleiuKLaap9DREQkBQYWG8i30j5CN1OrXBHm6waA3UJEROR8GFhswLgsv5flpzTfzDiO5ToDCxERORcGFhswdgl5qqz6OVEhGgBsYSEiIufDwGID+WXW26n5Zn1C9DOx2MJCRETOhoHFymrq6lFYrg8s1tip+WYxYd4AgAs5pSjX1Vr1s4iIiGyJgcXKDGFFLhPg427dwBKkViFUo0K9CJy4VmzVzyIiIrIlBhYrM8wQ8nFXQCZrfjNHS4nt4gMASEovtvpnERER2QoDi5XZqjvIILaLNwAGFiIici4MLFZW0DDg1hq7NDfF0MKSnFHU4orEREREjoSBxcoKym0bWKJD1XCVC8gvq8a1okqbfCYREZG1MbBYWYEN9hG6mcpVjqhQ/Xosx9OLbPKZRERE1sbAYmWFNm5hAYDBXfXdQocvF9rsM4mIiKyJgcXKDF1CfjYadAsAI7r7AQASLuXb7DOJiIisiYHFygxdQn42bGEZ2t0XMgG4UlCBrBKOYyEiIsfHwGJlhcYWFtuMYQH0Ozf366Qfx5JwqcBmn0tERGQtDCxWZutpzQYjIvwBAIcYWIiIyAkwsFiRrrYOpQ17+vh72K6FBQBGRBjGsRRwPRYiInJ4DCxWZOgOcpEJULu52PSzh3TzgUIuQ2ZxJS7lldv0s4mIiCyNgcWKDN1BPh4KCIL19xG6mbvCBcO6+wIA9qbk2vSziYiILI2BxYqMU5ptPH7F4LbegQCAPQwsRETk4BhYrKiwvGFKsw3XYLmZIbAcvVIIbVWNJDUQERFZAgOLFRm6hPxsPODWoKufB7oHeKC2XsTBVC4iR0REjouBxYpsvfFhUyY2tLLsPJMtWQ1ERETtxcBiRTc2PpQusEztGwIA2H0uF1U1dZLVQURE1B4MLFZ0Y+NDabqEACA2zBuhGhXKdLXYfyFPsjqIiIjag4HFiuyhS0gmE3BHP30ry/ZTWZLVQURE1B4MLFZkGHQrZZcQANzZv6Fb6GwOu4WIiMghMbBYUaEdtLAAwIAwb3TydkN5dR0XkSMiIofEwGIlVTV1KGvYR8iWOzU3RRAE3DUgFADw3bFrktZCRETUFgwsVmJoXXGVC1CrbLuPUFPuH9QZABB/Phc52iqJqyEiIjKP2YFl//79mDFjBkJDQyEIArZu3Wp8r6amBi+99BL69esHDw8PhIaGYu7cubh+/XqL11y3bh0EQWj0qKpy3F+shvErvhLsI9SU7gGeGNLNB/UisOk4W1mIiMixmB1YysvLERMTgxUrVjR6r6KiAsePH8drr72G48ePY/Pmzbhw4QLuuuuuW15XrVYjKyvL5KFSqcwtz24UNCzLL+WU5t+6f3AYAOC7xGsQRVHiaoiIiFrP7L6KadOmYdq0aU2+p9FosGvXLpPXPvroIwwdOhTp6eno0qVLs9cVBAHBwcHmlmO3CiXe+LApd/YLwZvbziAtvxwJlwowsoe/1CURERG1itXHsJSUlEAQBHh7e7d4XFlZGbp27YrOnTtj+vTpSEpKavF4nU4HrVZr8rAnRRX6zQa93V0lruQGD6UL7h7YCQCw9tAVaYshIiIyg1UDS1VVFV5++WU89NBDUKvVzR7Xu3dvrFu3Dtu2bcOGDRugUqkwatQopKamNnvO0qVLodFojI+wsDBr3EKbFVfYx5Tm35o3MhwAsPtcDq4WlEtcDRERUetYLbDU1NTggQceQH19PVauXNniscOHD8cjjzyCmJgYjBkzBt9++y169uyJjz76qNlz4uLiUFJSYnxkZGRY+hbaxdAl5O1uX4GlR6AnxvYMgCgCnx+6KnU5RERErWKVwFJTU4NZs2YhLS0Nu3btarF1pcmiZDIMGTKkxRYWpVIJtVpt8rAnxQ1dQj521CVk8NiobgCA7xIzjGvFEBER2TOLBxZDWElNTcXu3bvh5+dn9jVEUURycjJCQkIsXZ7NFDV0CfnYWQsLAIyLDED3AA+U6mrx1WG2shARkf0zO7CUlZUhOTkZycnJAIC0tDQkJycjPT0dtbW1uO+++5CYmIivv/4adXV1yM7ORnZ2Nqqrq43XmDt3LuLi4ozP33zzTezYsQOXL19GcnIy5s+fj+TkZCxYsKD9dygRw6BbHzsbwwLoN0T8/bgIAMBn+y+jopqtLEREZN/MDiyJiYmIjY1FbGwsAGDx4sWIjY3F66+/jmvXrmHbtm24du0aBgwYgJCQEOPj0KFDxmukp6cjK+vGzsHFxcV46qmn0KdPH0yePBmZmZnYv38/hg4daoFblEZRuaGFxf66hABgZmwnhPm6oaC8GuuPpEtdDhERUYsE0UlWENNqtdBoNCgpKbGL8Sy9Xv0fdLX1OPDiBIT5uktdTpM2/JqOuM2nEOClxIEXJ0DlKpe6JCIi6mBa+/ubewlZQWV1HXS19QDsax2W37p3YGeEalTIK9WxlYWIiOwaA4sVGAbcusgEeCql3/iwOQoXGRbe1gMAsGLvRWiraiSuiIiIqGkMLFZgnCFkJxsftmT24DB0D/BAYXk1/rXvktTlEBERNYmBxQqKyu13DZbfcpHL8PLU3gCAfx9IQ1ZJpcQVERERNcbAYgWGFhZ7W+W2OZOigjCkmw90tfV4b+cFqcshIiJqhIHFCoor7HtK828JgoC4O/oAADYdv4bkjGJpCyIiIvoNBhYrMCwaZ28bH7ZkYBcf3DOwE0QReHXrKdTVO8VsdyIichIMLFZgrxsf3krctD7wUrngdKYWXx/hkv1ERGQ/GFiswNG6hAwCvJR4cUovAMA7O84jr1QncUVERER6DCxWYOgScrQWFgB4aFhX9OukQWlVLf76w1mpyyEiIgLAwGIVhhYWXwcMLHKZgL/f3RcyAdh24jp2nMmWuiQiIiIGFmu4sVOzY3UJGfTv7I2nG3ZzfmXLaeNGjkRERFJhYLGCIgcddHuzRbdHIjLQE/llOrzx3zNSl0NERB0cA4uF1dTVo1RXCwDwceDAonSR4537YyATgO+Tr+On01lSl0RERB0YA4uFFTd0BwkCoHFzzC4hgwFhN7qGXt58CtklVRJXREREHRUDi4UZBtxq3Fwhl9n3xoet8cLtPdG3kxrFFTV4YWMyF5QjIiJJMLBYmGHROEfuDrqZwkWGDx+IhbtCjoTLBVjFHZ2JiEgCDCwWdmMNFsfuDrpZ9wBPvHlXNADg/V0XcDy9SOKKiIioo2FgsbCSSudqYTG4b1Bn3BUTirp6EX/YkGTs+iIiIrIFBhYLMwy6dfQBt78lCAL+dndfdPF1x7WiSrywMRn1HM9CREQ2wsBiYSWVzhlYAECtcsUnjwyE0kWGvefz8NGei1KXREREHQQDi4U5c2ABgOhQDf5xdz8AwPKfL2Dv+VyJKyIioo6AgcXCnD2wAMC9gzrjkeFdIIrAom+SkVFYIXVJRETk5BhYLKwjBBYAeG16FAaEeaOksgZPfXkM5Q2r+xIREVkDA4uFdZTAonSRY+XDA+HvqcS5LC0H4RIRkVUxsFiYMbA40ToszQn1dsO/5gyCQi7DzrM5eHfnealLIiIiJ8XAYmEdpYXFYFBXHyy7Tz8Id2X8JWw+fk3iioiIyBkxsFhQfb0IbUNg8e4ggQUA7o7tjIUTGjZJ3HQKx64WSlwRERE5GwYWCyqrroVhGIe6AwUWAPjjpF6YEh2E6rp6PPXFMaQXcOYQERFZDgOLBZU0rHKrdJFB5SqXuBrbkskE/N/sAYgOVaOgvBqPrv0VBWU6qcsiIiInwcBiQR1t/MpvuStcsHbeEHTydkNafjnmf56Iyuo6qcsiIiInwMBiQR09sABAoFqFzx8fAo2bK5IzivHchiTU1tVLXRYRETk4swPL/v37MWPGDISGhkIQBGzdutXkfVEU8cYbbyA0NBRubm4YP348zpw5c8vrbtq0CVFRUVAqlYiKisKWLVvMLU1yDCx6PQK9sPrRwVC6yLD7XA7+su0MRJFrtBARUduZHVjKy8sRExODFStWNPn+22+/jffffx8rVqzA0aNHERwcjEmTJqG0tLTZayYkJGD27NmYM2cOTpw4gTlz5mDWrFk4cuSIueVJyhBYvDvAGiy3MribLz54IBaCAHx9JB0r4y9JXRIRETkwQWzH//oKgoAtW7Zg5syZAPStK6GhoVi0aBFeeuklAIBOp0NQUBCWLVuGp59+usnrzJ49G1qtFv/73/+Mr02dOhU+Pj7YsGFDq2rRarXQaDQoKSmBWq1u6y21yyfxl7DspxTcM7AT3p81QJIa7M3nh67gL9v0LWz/uLsfHhrWReKKiIjInrT297dFx7CkpaUhOzsbkydPNr6mVCoxbtw4HDp0qNnzEhISTM4BgClTprR4jk6ng1arNXlIjV1CjT06sptxjZZXtp7C98mZEldERESOyKKBJTs7GwAQFBRk8npQUJDxvebOM/ecpUuXQqPRGB9hYWHtqNwyGFiatmRyL8wZ3hWiCPzx2xP4+VyO1CUREZGDscosIUEQTJ6LotjotfaeExcXh5KSEuMjIyOj7QVbiJaBpUmCIODNu6Jxd2wn1NaLeObr40i4VCB1WURE5EAsGliCg4MBoFHLSG5ubqMWlN+eZ+45SqUSarXa5CE1trA0TyYT8PZ9/XF7nyDoauvxxOdHcSKjWOqyiIjIQVg0sISHhyM4OBi7du0yvlZdXY19+/Zh5MiRzZ43YsQIk3MAYOfOnS2eY484S6hlrnIZVjwUi5ERfiivrsOja3/FhZzmZ48REREZmB1YysrKkJycjOTkZAD6gbbJyclIT0+HIAhYtGgR/vGPf2DLli04ffo05s2bB3d3dzz00EPGa8ydOxdxcXHG588//zx27tyJZcuWISUlBcuWLcPu3buxaNGidt+gLRVXVgNgC0tLVK5yfDp3MAaEeaO4ogYPfXYEF3PLpC6LiIjsnNmBJTExEbGxsYiNjQUALF68GLGxsXj99dcBAC+++CIWLVqEZ555BoMHD0ZmZiZ27twJLy8v4zXS09ORlZVlfD5y5Eh88803WLt2Lfr3749169Zh48aNGDZsWHvvz6YMewkxsLTMU+mCdY8NQVSIGvllOjz42WFcymNoISKi5rVrHRZ7IvU6LPX1IiJe+RGiCPz6ykQEeqlsXoOjKSyvxkOfHUZKdikCvZTY+PQIhPt7SF0WERHZkCTrsHRkpVW1MEQ/trC0jq+HAl8/MQy9gryQW6rDg58expX8cqnLIiIiO8TAYiGGAbcqVxmULnKJq3Ecfp5KfP3kMEQGeiJbW4UHPzuM9IIKqcsiIiI7w8BiIZzS3Hb+nkqsf3I4egR6IqtEH1oyChlaiIjoBgYWCymt0gcWLxUDS1sEeCmx/slh6B7ggcziSjzA7iEiIroJA4uFaKtqAQBeKheJK3FcgV4qfPPkcGNomfWvBFzM5TotRETEwGIxbGGxjEC1ChufGoHewfqBuLP/dRhnr0u/sSUREUmLgcVCShtaWNRsYWm3AC8lNjw5HH07qVFQXo0HPzuMk9eKpS6LiIgkxMBiIVq2sFiUj4cCXz8xHAO7eKOksgYPf3YEx64WSl0WERFJhIHFQtjCYnkaN1d8MX8YhoX7olRXizmrf8WhS/lSl0VERBJgYLGQG2NYGFgsSb+M/1CMifRHRXUdHlt7FHtScqQui4iIbIyBxUJKjbOE2CVkaW4KOf796GDc3icIutp6PPnFMWw+fk3qsoiIyIYYWCyklNOarUrpIscnjwzEPQM7oa5exOJvT+DfBy5LXRYREdkIA4uFcFqz9bnKZXj3vhg8MTocAPC37efw9k8pcJL9O4mIqAUMLBbCQbe2IZMJeOXOPnhxai8AwMr4S/jzllOoq2doISJyZgwsFsJpzbYjCAKeGd8DS+/pB5kAbPg1A8+uPw5dbZ3UpRERkZUwsFgIl+a3vQeHdsHKhwdCIZfhf6ez8djao8auOSIici4MLBagq61DdW09AEDNFhabmto3BOseGwIPhRyHLhXg/lUJyC6pkrosIiKyMAYWCzCMXwEAT7aw2NzIHv7Y+PQI+HsqkZJdirtX/oKUbO4/RETkTBhYLMAQWDwUcshlgsTVdEx9O2mw5ZmR6BHoiaySKtz/SQIOpnJVXCIiZ8HAYgGc0mwfwnzdsWnBSONS/vPW/or/HOMCc0REzoCBxQKMU5rd2B0kNY27K76YPxQzYkJRWy9iyXcn8OHPqVyrhYjIwTGwWABbWOyL0kWOD2YPwIJxEQCA93ddwEubTqKmrl7iyoiIqK0YWCxAW8kpzfZGJhPw8rTe+OvMvpAJwLeJ1zBv7a8oqeC0ZyIiR8TAYgFcNM5+zRneFZ/NHQx3hRy/XCzA3St/weW8MqnLIiIiMzGwWAA3PrRvE/sE4T8LRiJUo8Ll/HLM/PgX/HKRM4iIiBwJA4sFMLDYv6hQNbY+OwqxXbyhrarF3DW/4usjV6Uui4iIWomBxQIMg265yq19C/RSYcOTwzFzQCjq6kW8suU03th2BrUcjEtEZPcYWCyAOzU7DpWrHP83ewD+NEW/2/O6Q1fw2LqjKKnkYFwiInvGwGIBpToOunUkgiBg4YQeWPXIQLi5ynEgNR93r/wFF3M5GJeIyF4xsFgApzU7pql9Q/DdghEIVqtwOU8/GHfX2RypyyIioiYwsFgAF45zXH07afDf50ZjaDdflOlq8eQXifi/XRdQX8+VcYmI7AkDiwVwlpBjC/BS4usnh2HeyG4AgA9+TsVTXyYa19chIiLpWTywdOvWDYIgNHosXLiwyePj4+ObPD4lJcXSpVkNA4vjc5XL8MZd0Xj3/hgoXGTYfS4XM1f8gou5pVKXRkREACz+G/bo0aOoq6szPj99+jQmTZqE+++/v8Xzzp8/D7VabXweEBBg6dKsQldbh+qGabFeSnYJObr7BnVGzyBPLPjyWMMic4fw3qwYTIkOlro0IqIOzeItLAEBAQgODjY+fvjhB0RERGDcuHEtnhcYGGhynlwub/F4nU4HrVZr8pBCue5GOPNQtlwzOYb+nb2x7bnRGBauH9fy9JfH8M6OFK7XQkQkIauOYamursZXX32Fxx9/HIIgtHhsbGwsQkJCMHHiROzdu/eW1166dCk0Go3xERYWZqmyzVKu03cHqVxlcJFzSJCz8PdU4qsnhuHxUeEAgI/3XsIjq48gt7RK4sqIiDomq/6G3bp1K4qLizFv3rxmjwkJCcGnn36KTZs2YfPmzejVqxcmTpyI/fv3t3jtuLg4lJSUGB8ZGRkWrr51yhoCi6eS41ecjatchtdnROGjB2PhoZDj8OVC3PHBQSRcKpC6NCKiDkcQRdFq8zenTJkChUKB//73v2adN2PGDAiCgG3btrX6HK1WC41Gg5KSEpOxMNaWeKUQ961KQFc/d+z70wSbfS7Z1qW8Miz8+jhSskshE4A/Tu6F34+LgEzWcsshERG1rLW/v63WwnL16lXs3r0bTzzxhNnnDh8+HKmpqVaoyvJKG1pYPBRsYXFmEQGe2PLMKNw/qDPqReCdHefx+OdHUVReLXVpREQdgtUCy9q1axEYGIg777zT7HOTkpIQEhJihaoszzCGxZNTmp2em0KOd+6Pwdv39YfSRYb483m488MDOJ5eJHVpREROzyq/Zevr67F27Vo8+uijcHEx/Yi4uDhkZmbiiy++AAAsX74c3bp1Q3R0tHGQ7qZNm7Bp0yZrlGZx5RzD0uHMGhyGfp00eObr40jLL8esVQn405ReeHJMd3YRERFZiVVaWHbv3o309HQ8/vjjjd7LyspCenq68Xl1dTWWLFmC/v37Y8yYMTh48CC2b9+Oe+65xxqlWVxZw7RmDwaWDqVPiBrbnh2FO/uHoLZexNL/peDRtb8iV8tZRERE1mDVQbe2JNWg2w9/TsX7uy7gwaFhWHpPf5t9LtkHURSx8WgG3vjvGVTV1MPPQ4F374/BhN6BUpdGROQQJB9021GUcdBthyYIAh4Y2gU/PDcavYO9UFBejcfWHcVb/z0LXW3drS9AREStwsDSTmUcdEsAegR6YevCUcYNFNf8koa7Pz6ES3ll0hZGROQkGFjaiYNuyUDlKscbd0Xj33MHw8fdFWeztJj+4UF8ezQDTtLzSkQkGQaWdjIEFg66JYPbo4Lw06KxGNHdD5U1dXhx00ks+OoYCsp0UpdGROSwGFjaqbSKgYUaC1Kr8NUTw/Di1F5wlQvYcSYHU5bvx+6zOVKXRkTkkBhY2qm8Wh9YvBhY6DfkMgHPjO+BrQtHoWeQJ/LLqvHEF4l46T8njWOfiIiodRhY2qmc67DQLUSHarDt2dF4ckw4BAHYmJiBaR/sx69phVKXRkTkMBhY2sk4rVkpl7gSsmcqVzleuTMKG54cjk7ebsgorMTsTxOw9H/nOP2ZiKgVGFjaqayKs4So9YZ398NPi8bgvkGdIYrAv/Zdxu9W/IJT10qkLo2IyK4xsLRDXb2Iyhr9/x0zsFBrealc8e79MVj1yCD4eiiQkl2KmSt/wds/paCqhq0tRERNYWBpB8OAW4BjWMh8U/sGY+cLY3Fn/xDU1YtYGX8J0z86yN2fiYiawMDSDoY1WFxkApQu/KMk8/l7KvHxQwOx6pGB8PdU4mJuGe775BD+vv0sKqvZ2kJEZMDfsu1QdtMaLIIgSFwNObKpfUOw64WxuCe2E+pF4LMDaZxJRER0EwaWdijjsvxkQT4eCrw/ewDWzBuMYLUKVwoqMOtfCfjL96e5bgsRdXgMLO1gWIOFgYUs6bbeQdi5eCweGBIGAPg84Spuf28fdpzJlrgyIiLpMLC0A9dgIWtRq1zxz3v746v5w9DVzx3Z2io8/eUxPPlFIq4XV0pdHhGRzTGwtAM3PiRrGx3pjx2LxmLhhAi4yATsOpuDSe/vw5qDaair5w7QRNRxMLC0g6GFxUvFwELWo3KV409TeuPH58dgUFcflFfX4a0fzmLmx1xwjog6DgaWdjB2CSkYWMj6egZ54bunR2DpPf2gVrngVGYJfvfxQbz137MclEtETo+BpR3YJUS2JpMJeHBoF/z8x/H43YBQ1IvAml/SMPG9eHyfnAlRZDcRETknBpZ2KOegW5JIgJcSHzwQi88fH4qufu7I0erw/DfJmP3pYaRka6Uuj4jI4hhY2qGiYSVStrCQVMb1DMCORWOxZHJPqFxl+DWtEHd+eBBvbDuDksoaqcsjIrIYBpZ2MAQWd1e2sJB0VK5yPHtbJH7+43hM6xuMunoR6w5dwcT34vFdYgbqOZuIiJwAA0s7VDRsfujOFhayA5283fDJI4Pw5fyh6B7ggfyyavzpPydx76pDnE1ERA6PgaUdyg0tLAq2sJD9GBMZgJ+eH4u4ab3hrpAjKb0Yd318EH/89gRytFVSl0dE1CYMLO1g2E2X05rJ3ihcZHh6XAT2NMwmEkVg0/FrGP9OPD7YncqdoInI4TCwtEN5Q5eQG1tYyE4Fa1T44IFYbHlmJAZ28UZlTR3+b/cFTHg3HpuPX+P4FiJyGAws7cAWFnIUsV18sOn3I/HRg7Ho5O2GbG0VFn97Anev/AVHrxRKXR4R0S0xsLSDYR0WtrCQIxAEATNiQvHzH8fhxam94Kl0wYlrJbh/VQIWfn0cVwvKpS6RiKhZDCztUFljWIeFgYUch8pVjmfG98DeJePx4NAwyARg+6ksTHxvH17//jTySnVSl0hE1AgDSxtV19ajpk7f/+/uyi4hcjwBXkosvac/tv9hDMb3CkBtvYgvEq5i3Dt78f7O8yit4sJzRGQ/LB5Y3njjDQiCYPIIDg5u8Zx9+/Zh0KBBUKlU6N69O1atWmXpsizu5lkW7BIiR9YnRI11jw3FhieHIybMGxXVdfhwz0WMeyceqw+mQVfLGUVEJD2rtLBER0cjKyvL+Dh16lSzx6alpeGOO+7AmDFjkJSUhD//+c/4wx/+gE2bNlmjNIsxzBBylQtQuLChihzfiAg/bH1mJFY9MhDdAzxQWF6Nv/5wFre9uw+bjl1DHWcUEZGErNKX4eLicstWFYNVq1ahS5cuWL58OQCgT58+SExMxLvvvot7773XGuVZhHFZfs4QIiciCAKm9g3B7X2C8N2xa1i++wIyiyvxx+9O4LMDl/HCpJ6YHBUEQRCkLpWIOhirNA2kpqYiNDQU4eHheOCBB3D58uVmj01ISMDkyZNNXpsyZQoSExNRU9N8H7pOp4NWqzV52JJxWX52B5ETcpHL8ODQLohfMgEvTe0NtcoFKdmlePrLY5j+0UH8fC4HosgWFyKyHYsHlmHDhuGLL77Ajh078NlnnyE7OxsjR45EQUFBk8dnZ2cjKCjI5LWgoCDU1tYiPz+/2c9ZunQpNBqN8REWFmbR+7iVCi7LTx2Am0KO34+PwP4XJ+DZCT3goZDjzHUt5n+eiJkf/4L487kMLkRkExYPLNOmTcO9996Lfv364fbbb8f27dsBAJ9//nmz5/y2ednwH8CWmp3j4uJQUlJifGRkZFig+tYztLB4cOND6gC83RVYMqUXDrx0GxaMi4CbqxwnrpVg3tqjuPeTQziYms/gQkRWZfXRoh4eHujXrx9SU1ObfD84OBjZ2dkmr+Xm5sLFxQV+fn7NXlepVEKtVps8bKlcp29hcXNlCwt1HL4eCrw8rTcOvDQBT44Jh9JFhuPpxXhk9RHM/vQwEi413ZJKRNReVg8sOp0O586dQ0hISJPvjxgxArt27TJ5befOnRg8eDBcXV2tXV6bGZflZwsLdUD+nkq8cmcUDrw4AfNGdoPCRYZf0wrx4GeHcf+qQ+wqIiKLs3hgWbJkCfbt24e0tDQcOXIE9913H7RaLR599FEA+q6cuXPnGo9fsGABrl69isWLF+PcuXNYs2YNVq9ejSVLlli6NIvixodEQKBahTfuisa+P43HnOFdoZDLcPRKEeatPYq7VvyCn05ncYNFIrIIiweWa9eu4cEHH0SvXr1wzz33QKFQ4PDhw+jatSsAICsrC+np6cbjw8PD8eOPPyI+Ph4DBgzAX//6V3z44Yd2PaUZuDHo1oOBhQghGjf8dWZfHHhpAp4YHQ43VzlOZZZgwVfHMWX5fmxJuobaunqpyyQiByaITtJuq9VqodFoUFJSYpPxLO/sSMHHey9h3shueOOuaKt/HpEjKSyvxtpf0rDu0BWUVulbI7v4umPBuAjcO6gTlC4M+kSk19rf31yitY04rZmoeb4eCvxxci/88vJt+NOUXvDzUCC9sAJ/3nIKY9/ei0/3X4KWexURkRkYWNqoQsfAQnQrapUrFk7ogYMv3YbXp0chWK1CjlaHf/yYgpFL9+AfP57D9eJKqcskIgfAwNJGFTVcmp+otdwUcjw+Ohz7XhyPt+/tjx6BnijT1eLT/Zcx9u29eGFjMs5cL5G6TCKyY/xt20YVOi7NT2QupYscs4aE4b5BnbHvQh7+tf8SDl8uxJakTGxJysToHv54amx3jIn0535FRGSCgaWNjGNYuA4LkdlkMgETegdiQu9AnLxWjM8OpOHHU1k4eDEfBy/mo3ewF+aPDseMmFCouDgjEYFdQm1m3PyQ/zElapf+nb3x0YOxiF8yHo+PCoe7Qo6U7FL86T8nMeqfe/DezvPILqmSukwikhgDSxvdaGFhYCGyhDBfd7w+IwoJL0/Ei1N7IUSjQkF5NT7acxGjl+3Bs+uP49jVQq6gS9RBsT+jjW5Ma+YfIZEladxd8cz4HnhqTHfsPJuDdYeu4Ne0QvxwMgs/nMxC305qzBsZjun9Q9hdRNSBsIWljYy7NXPQLZFVuMhluKNfCL59egS2/2E0Zg3uDKWLDKcztVjy3QmM+ucevLvjPLJKOC2aqCNgYGmj8oYWFu4lRGR90aEavH1fDBLiTLuLVuy9iFH/3IMnPk/E3pRc1HHfIiKnxf6MNqitq0d1rX5fFA92CRHZjK+HwthdtKuhu+hIWiF2n8vB7nM56OTthgeHhmHW4DAEqlVSl0tEFsTftm1gWDQO4KBbIim4yGWY1i8E0/qF4GJuGTb8mo7/HLuGzOJKvLvzApbvTsXtfYLw8PAuGBXhD5mMa7oQOToGljaobOgOkssEKOTsVSOSUo9AT7w2PQp/mtILP57Kwvoj6Ui8WoSfzmTjpzPZ6OLrjgeHdsF9gzojwEspdblE1EYMLG1QUqnftM1T6cLVOInshMpVjnsGdsY9AzvjfHYp1h+5is3HM5FeWIFlP6Xg3Z3nMaFXIO4f3Bm39Q6EK/9ng8ihMLC0gWERqxAN+8iJ7FGvYC+8+bu+eGlab/xwIgvrf01HckaxcayLn4cCM2M74f7BndE7uPnt7InIfjCwtIEhsARxUB+RXXNXuGDWkDDMGhKG1JxS/OfYNWw6non8Mh1WH0zD6oNp6N9Zg/sHdcZdMZ2gcXeVumQiagYDSxtksYWFyOFEBnkh7o4+WDKlF/adz8N3xzLw87lcnLxWgpPXSvDX7ecwOSoI9w7qjDE9/OHCLiMiu8LA0gbZWn1gCWZgIXI4rnIZbo8Kwu1RQcgv02FrUib+c+waUrJLjavp+nsqML1/KGbGdkJMZw3HqhHZAQaWNshuWFmTLSxEjs3fU4knxnTH/NHhOJ2pxXfHMvDDySzkl1Vj3aErWHfoCrr5ueN3AzphZmwnhPt7SF0yUYfFwNIGhi6hYI2bxJUQkSUIgoB+nTXo11mD16ZH4WBqPrYkZWLn2WxcKajABz+n4oOfUxET5o2ZA0IxvX8op0gT2RgDSxsYu4Q46JbI6bjKZZjQOxATegeiXFeLnWezsTXpOg6k5uFERjFOZBTjb9vPYVQPf0zvH4IpUcEcrEtkAwwsZqqqqUNxhX4dFgYWIufmoXTB3bGdcXdsZ+SV6vDDyevYmnwdJzKKsf9CHvZfyMMr8lMY1cMfd/YLwWSGFyKrEURRdIrdwrRaLTQaDUpKSqBWW29dhfSCCox9Zy9UrjKce2sqB+MRdUBp+eX44cR1bD+VhZTsUuPrrnIBo3v4487+oZgUFQSNG8ML0a209vc3W1jMlFuq7w4K9FIxrBB1UOH+HnhuYiSemxiJi7ll+PFUFrafzML5nFLsPZ+Hvefz4CoXMDYyAHf0C8HtDC9E7cbAYqbcUh0AcMAdEQHQ72X0h4mR+MPESFzMLcX2k9nYfuo6LuSU4eeUXPyckgsXmYAREX6YHBWESVHBXBKBqA0YWMyUqzW0sDCwEJGpHoFeeP52Lzx/eyQu5JRi+8ks/HgqC6m5ZTiQmo8Dqfl47fsziAnzxuSoIEyJDkaPQE+pyyZyCAwsZjK0sDCwEFFLegZ5oeckL7wwqScu55Vh19kc7DiTjaSGmUYnMorxzo7z6B7ggclRwZgcHYQBnb0hk7GrmagpDCxmMgYWzhAiolbqHuCJp8d54ulxEcjVVmH3uVzsPJuNQxcLcDmvHKv2XcKqfZcQ6KXExD6BuK13EEb18IO7gv+JJjLgt8FMHMNCRO0RqFbhoWFd8NCwLiitqkH8+TzsPJuDvSm5yC3VYcOvGdjwawYULjIM7+6H23oF4LbeQeji5y516USSYmAxE8ewEJGleKlcMSMmFDNiQqGrrcPhy4XYcy4He87nIqOw0rjWyxv/PYuIAA/c1rCg3ZBuvnDl5ozUwTCwmCnPOIaFXUJEZDlKFznG9QzAuJ4BeEMUcSmvDHtScrEnJReJV4pwKa8cl/LS8NmBNHgpXTCmpz/G9wrE2MgAzjqiDoGBxQw1dfUoKK8GAASq2cJCRNYhCAJ6BHqhR6AXnhobAW1VDQ5cyMeelFzEn89FQXk1fjyVjR9PZQMAegZ5YkxkAMZE+mNYuB/cFHKJ74DI8iweWJYuXYrNmzcjJSUFbm5uGDlyJJYtW4ZevXo1e058fDwmTJjQ6PVz586hd+/eli6xzQytKy4yAb7uComrIaKOQq1yxZ39Q3Bn/xDU14s4mVmCPSm52HchDyevFeNCThku5JRh9cE0KOQyDAn3wege+gATFaLmzCNyChYPLPv27cPChQsxZMgQ1NbW4pVXXsHkyZNx9uxZeHi0vDX7+fPnTZblDQgIsHR57WIYcOvvqeR/AIhIEjKZgAFh3hgQ5o3Fk3qiuKIav1wswIHUPBxIzUdmcSV+uViAXy4WYNlPgJ+HAqMj/TEmMgCje/iz+4gclsUDy08//WTyfO3atQgMDMSxY8cwduzYFs8NDAyEt7e3pUuyGOOAW3YHEZGd8HZXGFtfRFHE5fxyHLiQh4MX83HoUgEKyqvxffJ1fJ98HYB+W4Hh3f0wIsIPI7r7ccYjOQyrj2EpKSkBAPj6+t7y2NjYWFRVVSEqKgqvvvpqk91EBjqdDjqdzvhcq9W2v9hb4KJxRGTPBEFARIAnIgI8MW9UOKpr65GUXtSwym4eTmWWIC2/HGn55djwazoA/dYCIxoCzPDufvD1YHc32SerBhZRFLF48WKMHj0affv2bfa4kJAQfPrppxg0aBB0Oh2+/PJLTJw4EfHx8c22yixduhRvvvmmtUpv0o01WNikSkT2T+Eiw7DufhjW3Q9LpvRCSWUNjqYVIuFyARIuFeBcthYXc8twMbcMXx6+CgDoHexlbH0ZFu4HjTs3bST7IIiiKFrr4gsXLsT27dtx8OBBdO7c2axzZ8yYAUEQsG3btibfb6qFJSws7JbbU7dH3OaT2PBrBp6fGIkXJvW0ymcQEdlKUXk1jqTpw0vC5QJcyClrdEyvIC8MCffBkG6+GNzNF5283SSolJyZVquFRqO55e9vq7WwPPfcc9i2bRv2799vdlgBgOHDh+Orr75q9n2lUgml0rZdM/ll+inN/uwSIiIn4OOhwNS+IZjaNwQAkF+mw+HLNwLM5bxynM8pxfmcUnx1WN+F1MnbDYO7+WBwN18M7eaLyEBPTkIgm7B4YBFFEc899xy2bNmC+Ph4hIeHt+k6SUlJCAkJsXB17VPYsAaLP/t4icgJ+XsqMb1/KKb3DwWgDzCJVwpx9EoREq8U4vR1LTKLK5GZXGkcxKtWuWBwN18M6eaLId180LeTBipXrgNDlmfxwLJw4UKsX78e33//Pby8vJCdrV/YSKPRwM1N35QYFxeHzMxMfPHFFwCA5cuXo1u3boiOjkZ1dTW++uorbNq0CZs2bbJ0ee1SUKbvgvLzZAsLETk/f0+lSQtMua4WyRnFOHqlEEevFOL41WJoq2qNK/ICgKtcQFSIGrFdfBDbxRuxYT4I83WDILAVhtrH4oHlk08+AQCMHz/e5PW1a9di3rx5AICsrCykp6cb36uursaSJUuQmZkJNzc3REdHY/v27bjjjjssXV67FDR0CXEUPRF1RB5KF4zq4Y9RPfwB6Ff/PpelxdErRTiaVojEq4XIL6vGiWslOHGtBOsO6c/z81Dow0sXH8SGeaN/mDc8lVxoncxj1UG3ttTaQTttpautQ69X9WvMJL8+Cd5c6ZaIyIQoirhWVImkjGIkpRchKb0YZ66XoKbO9NeMIAA9A70aQow3+nf2RmSgJ1y4oWOHJPmgW2djGL/iIhOgVnGaHxHRbwmCgDBfd4T5uuOuGP04mKqaOpzN0iIpXR9ikjOKca2o0jiY95ujGQAAlasMfULU6N9Jg76dNOjf2RsRAR4MMWTEwNJKhu4gHw8FR8QTEbWSylWOgV18MLCLDwD9JIzc0iokpxcbW2LOZGpRqqttCDXFN50rQ3SoBv06NTw6axAR4Ak5/xvcITGwtJJhl2Y/jl8hImqXQC8VJkcHY3J0MACgvl7ElYJynMoswalrJTiVWYLTmSUor67DsatFOHa1yHium6sc0aFq9O2kQVSIGlGhavQI9OTMpA6AgaWVDDOE/DlDiIjIomQyAd0DPNE9wBO/G9AJgD7EpBWUGwPMqcwSnGkIMYlXi5B4U4iRywREBHggKkSNPg2PqFA1/3vtZBhYWokzhIiIbEcmu7Ev0sxYfYipqxeRll+OU5nFOJ2pxbks/aOoogYXcspwIacMWxvWhwGAAC+lPryEqNEnxAtRIWqE+3NcjKNiYGklY5eQJwMLEZEU5DIBPQI90SPQE3fH6l8TRRHZ2qqG8FKKs9f1ISatoBx5pTrkleZh/4U84zWULjL0CPREzyAvRAZ5oleQF3oGeaGTtxvHJ9o5BpZWYpcQEZH9EQQBIRo3hGjccFvvIOPrFdW1SMkuNbbCnL2uRUp2KSqq63DmuhZnrmtNruOukCMy0BORQV7o1RBmegZ5IUSj4qJ3doKBpZUM05rZJUREZP/cFS43zU7Sq68XkV5YgQs5pUjNLcP57FJcyCnF5bxyVFTXGRe8u5mX0sUYXiKDvBAR4IGIAE+EertxtpKNMbC0Uj5nCREROTSZTEA3fw908/fA5Ogbr9fW1eNKgT7IXMgpRWpOGc7nlCItvxylulocTy/G8ZumWwP6rqVwf4+GcTYe6N4w3qZ7gAc8uIqvVfBPtZW4jxARkXNykcuMY2Pu6Hdj011dbR3S8sv1A3qzS3ExtwyX88twJb8Cutp6pGSXIiW7tNH1gtUqRAR6oLu/PsxEBOpnQIWoVRwn0w4MLK1UyBYWIqIORekiR+9gNXoHq4GYG6/X1tUjs7gSl/LKcCm3HJfzb/wzv6wa2doqZGur8MvFApPrKVxk6Orrjq5+Hujm546u/vp/dvPzYBdTKzCwtEJFdS0qqusAcJYQEVFH5yKXoaufB7r6eeC23qbvFVdU41JeOS7nld30zzJcLahAdW09UnPLkJpb1uiarnIBYT7u6OpnGmjC/TzQyccNrpyKzcDSGoY1WBQuMu4wSkREzfJ2V2BQVwUGdfUxeb22rh7Xi6twpaAcVwvKcaWgwvjP9IIKVNfV43J+OS7nlwPIMzlXLhPQydsNYb5uCPNxR2cfN4T5uqOzjzvCfNwQ4KXsEDOZ+Nu3FW7uDuoIfymIiMiyXOQydPFzRxc/dwABJu/V1evXkrmaf3OQKcfVggpcKShHVU090gsrkF5YAaCg0bWVLjJ08tGHmTBft4YgcyPY+Li7OsXvLgaWViiurAGgT85ERESWZGhB6eTthpE9TN8TRRG5pTpcyS/HtaJKZBRV6P9ZqP9nVkkldLX1uJxXjst55U1e30Mh14cYX/16NaHebgj1ViHU2w0hGhWC1CqH6HJiYGmF4gp9C4u3m6vElRARUUciCAKC1PpQMayJ92vq6pFVXIVrRRUmYSajqBLXiiqQo9WhvLoO53NKcT6n8YwmAJAJ+g0pQ71VCGkITiEafaAJ1ejDja8d9DAwsLRCcYW+hcXHg4GFiIjsh6tJV1NjVTV1uF5caQwwWcVVuF5ciesllbheXIXskipU19UbZzbhN+vNGChdZAj1dsO79/fHoK6+Vryj5jGwtEJRQwuLxo1dQkRE5DhUrnLjTthNqa8XkV+uMwaZzOJKZJUYQo3+n3mlOuhq65GWXw6Vq9zGd3ADA0srGFtY3NnCQkREzkMmExDopUKglwoxYd5NHqOrrUNOiQ7XSyoR0UzwsQUGllYwjmFhYCEiog5G6SJvsdvJVux/WLAd4CwhIiIiaTGwtEJRQ5cQZwkRERFJg4GlFUoauoR8uI8QERGRJBhYWoEtLERERNJiYLmFunoR2iqOYSEiIpISA8staCtrIIr6f9ewhYWIiEgSDCy3YJgh5Kl0gcKFf1xERERS4G/gW7ixyi1bV4iIiKTCwHILJdxHiIiISHIMLLdQZNypmQNuiYiIpMLAcguGfYS4LD8REZF0rBZYVq5cifDwcKhUKgwaNAgHDhxo8fh9+/Zh0KBBUKlU6N69O1atWmWt0szCfYSIiIikZ5XAsnHjRixatAivvPIKkpKSMGbMGEybNg3p6elNHp+WloY77rgDY8aMQVJSEv785z/jD3/4AzZt2mSN8sximCXkwzVYiIiIJGOVwPL+++9j/vz5eOKJJ9CnTx8sX74cYWFh+OSTT5o8ftWqVejSpQuWL1+OPn364IknnsDjjz+Od9991xrlmcWwyi1nCREREUnHxdIXrK6uxrFjx/Dyyy+bvD558mQcOnSoyXMSEhIwefJkk9emTJmC1atXo6amBq6ujcOCTqeDTqczPi8pKQEAaLXa9t6CidyCItTrKqCs11n82kRERB2d4XeraFiltRkWDyz5+fmoq6tDUFCQyetBQUHIzs5u8pzs7Owmj6+trUV+fj5CQkIanbN06VK8+eabjV4PCwtrR/XNm7vcKpclIiIiAKWlpdBoNM2+b/HAYiAIgslzURQbvXar45t63SAuLg6LFy82Pq+vr0dhYSH8/Pxa/BxzabVahIWFISMjA2q12mLXtRfOfn+A89+js98f4Pz3yPtzfM5+j9a8P1EUUVpaitDQ0BaPs3hg8ff3h1wub9Sakpub26gVxSA4OLjJ411cXODn59fkOUqlEkql0uQ1b2/vthd+C2q12in/Eho4+/0Bzn+Pzn5/gPPfI+/P8Tn7PVrr/lpqWTGw+KBbhUKBQYMGYdeuXSav79q1CyNHjmzynBEjRjQ6fufOnRg8eHCT41eIiIioY7HKLKHFixfj3//+N9asWYNz587hhRdeQHp6OhYsWABA350zd+5c4/ELFizA1atXsXjxYpw7dw5r1qzB6tWrsWTJEmuUR0RERA7GKmNYZs+ejYKCArz11lvIyspC37598eOPP6Jr164AgKysLJM1WcLDw/Hjjz/ihRdewMcff4zQ0FB8+OGHuPfee61RnlmUSiX+8pe/NOp+chbOfn+A89+js98f4Pz3yPtzfM5+j/Zwf4J4q3lERERERBLjXkJERERk9xhYiIiIyO4xsBAREZHdY2AhIiIiu8fAQkRERHavwwWWlStXIjw8HCqVCoMGDcKBAwdaPH7fvn0YNGgQVCoVunfvjlWrVjU6ZtOmTYiKioJSqURUVBS2bNlirfJbxZx73Lx5MyZNmoSAgACo1WqMGDECO3bsMDlm3bp1EASh0aOqqsrat9Ikc+4vPj6+ydpTUlJMjnPkn+G8efOavMfo6GjjMfb0M9y/fz9mzJiB0NBQCIKArVu33vIcR/oemnt/jvYdNPf+HPE7aO49Otp3cOnSpRgyZAi8vLwQGBiImTNn4vz587c8T+rvYYcKLBs3bsSiRYvwyiuvICkpCWPGjMG0adNM1oS5WVpaGu644w6MGTMGSUlJ+POf/4w//OEP2LRpk/GYhIQEzJ49G3PmzMGJEycwZ84czJo1C0eOHLHVbZkw9x7379+PSZMm4ccff8SxY8cwYcIEzJgxA0lJSSbHqdVqZGVlmTxUKpUtbsmEufdncP78eZPaIyMjje85+s/wgw8+MLm3jIwM+Pr64v777zc5zl5+huXl5YiJicGKFStadbyjfQ/NvT9H+w6ae38GjvQdNPceHe07uG/fPixcuBCHDx/Grl27UFtbi8mTJ6O8vLzZc+zieyh2IEOHDhUXLFhg8lrv3r3Fl19+ucnjX3zxRbF3794mrz399NPi8OHDjc9nzZolTp061eSYKVOmiA888ICFqjaPuffYlKioKPHNN980Pl+7dq2o0WgsVWK7mHt/e/fuFQGIRUVFzV7T2X6GW7ZsEQVBEK9cuWJ8zZ5+hjcDIG7ZsqXFYxzxe2jQmvtrij1/B2/WmvtzxO/gzdryM3Sk76AoimJubq4IQNy3b1+zx9jD97DDtLBUV1fj2LFjmDx5ssnrkydPxqFDh5o8JyEhodHxU6ZMQWJiImpqalo8prlrWlNb7vG36uvrUVpaCl9fX5PXy8rK0LVrV3Tu3BnTp09v9H9/ttCe+4uNjUVISAgmTpyIvXv3mrznbD/D1atX4/bbbzeuLG1gDz/DtnC072F72fN3sD0c5TtoCY72HSwpKQGARn/nbmYP38MOE1jy8/NRV1fXaMfooKCgRjtFG2RnZzd5fG1tLfLz81s8prlrWlNb7vG33nvvPZSXl2PWrFnG13r37o1169Zh27Zt2LBhA1QqFUaNGoXU1FSL1n8rbbm/kJAQfPrpp9i0aRM2b96MXr16YeLEidi/f7/xGGf6GWZlZeF///sfnnjiCZPX7eVn2BaO9j1sL3v+DraFo30H28vRvoOiKGLx4sUYPXo0+vbt2+xx9vA9tMpeQvZMEAST56IoNnrtVsf/9nVzr2ltba1nw4YNeOONN/D9998jMDDQ+Prw4cMxfPhw4/NRo0Zh4MCB+Oijj/Dhhx9arvBWMuf+evXqhV69ehmfjxgxAhkZGXj33XcxduzYNl3TFtpaz7p16+Dt7Y2ZM2eavG5vP0NzOeL3sC0c5TtoDkf9DraVo30Hn332WZw8eRIHDx685bFSfw87TAuLv78/5HJ5o6SXm5vbKBEaBAcHN3m8i4sL/Pz8WjymuWtaU1vu0WDjxo2YP38+vv32W9x+++0tHiuTyTBkyBCb/59Be+7vZsOHDzep3Vl+hqIoYs2aNZgzZw4UCkWLx0r1M2wLR/setpUjfActxZ6/g+3haN/B5557Dtu2bcPevXvRuXPnFo+1h+9hhwksCoUCgwYNwq5du0xe37VrF0aOHNnkOSNGjGh0/M6dOzF48GC4urq2eExz17SmttwjoP+/unnz5mH9+vW48847b/k5oigiOTkZISEh7a7ZHG29v99KSkoyqd0ZfoaAfuT/xYsXMX/+/Ft+jlQ/w7ZwtO9hWzjKd9BS7Pk72B6O8h0URRHPPvssNm/ejD179iA8PPyW59jF99AiQ3cdxDfffCO6urqKq1evFs+ePSsuWrRI9PDwMI7kfvnll8U5c+YYj798+bLo7u4uvvDCC+LZs2fF1atXi66uruJ//vMf4zG//PKLKJfLxX/+85/iuXPnxH/+85+ii4uLePjwYZvfnyiaf4/r168XXVxcxI8//ljMysoyPoqLi43HvPHGG+JPP/0kXrp0SUxKShIfe+wx0cXFRTxy5Ijd39///d//iVu2bBEvXLggnj59Wnz55ZdFAOKmTZuMxzj6z9DgkUceEYcNG9bkNe3pZ1haWiomJSWJSUlJIgDx/fffF5OSksSrV6+Kouj430Nz78/RvoPm3p8jfgfNvUcDR/kO/v73vxc1Go0YHx9v8neuoqLCeIw9fg87VGARRVH8+OOPxa5du4oKhUIcOHCgyTSuRx99VBw3bpzJ8fHx8WJsbKyoUCjEbt26iZ988kmja3733Xdir169RFdXV7F3794mX0QpmHOP48aNEwE0ejz66KPGYxYtWiR26dJFVCgUYkBAgDh58mTx0KFDNrwjU+bc37Jly8SIiAhRpVKJPj4+4ujRo8Xt27c3uqYj/wxFURSLi4tFNzc38dNPP23yevb0MzRMc23u75yjfw/NvT9H+w6ae3+O+B1sy99RR/oONnVvAMS1a9caj7HH76HQUDwRERGR3eowY1iIiIjIcTGwEBERkd1jYCEiIiK7x8BCREREdo+BhYiIiOweAwsRERHZPQYWIiIisnsMLERERGT3GFiIiIjI7jGwEBERkd1jYCEiIiK79/+CcKo0FmHcxQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running group 0, task 0, lv 1.\n",
      "Running group 0, task 0, lv 2.\n",
      "Running group 0, task 0, lv 3.\n",
      "Running group 0, task 0, lv 4.\n",
      "Running group 0, task 0, lv 5.\n",
      "Running group 0, task 0, lv 6.\n",
      "Running group 0, task 0, lv 7.\n",
      "Running group 0, task 0, lv 8.\n",
      "Running group 0, task 0, lv 9.\n",
      "Running group 0, task 0, lv 10.\n",
      "Running group 0, task 0, lv 11.\n",
      "Running group 0, task 0, lv 12.\n",
      "Running group 0, task 0, lv 13.\n",
      "Running group 0, task 0, lv 14.\n",
      "Running group 0, task 0, lv 15.\n",
      "Running group 0, task 0, lv 16.\n",
      "Running group 0, task 0, lv 17.\n",
      "Running group 0, task 0, lv 18.\n",
      "Running group 0, task 0, lv 19.\n",
      "Running group 0, task 0, lv 20.\n",
      "Running group 0, task 0, lv 21.\n",
      "Running group 0, task 0, lv 22.\n",
      "Running group 0, task 0, lv 23.\n",
      "Running group 0, task 0, lv 24.\n",
      "Running group 0, task 0, lv 25.\n",
      "Running group 0, task 0, lv 26.\n",
      "Running group 0, task 0, lv 27.\n",
      "Running group 0, task 0, lv 28.\n",
      "Running group 0, task 0, lv 29.\n",
      "Running group 0, task 0, lv 30.\n",
      "Running group 0, task 0, lv 31.\n",
      "Running group 0, task 0, lv 32.\n",
      "Running group 0, task 0, lv 33.\n",
      "Running group 0, task 0, lv 34.\n",
      "Running group 0, task 0, lv 35.\n",
      "Running group 0, task 0, lv 36.\n",
      "Running group 0, task 0, lv 37.\n",
      "Running group 0, task 0, lv 38.\n",
      "Running group 0, task 0, lv 39.\n",
      "Running group 0, task 0, lv 40.\n",
      "Running group 0, task 0, lv 41.\n",
      "Running group 0, task 0, lv 42.\n",
      "Running group 0, task 0, lv 43.\n",
      "Running group 0, task 0, lv 44.\n",
      "Running group 0, task 0, lv 45.\n",
      "Running group 0, task 0, lv 46.\n",
      "Running group 0, task 0, lv 47.\n",
      "Running group 0, task 0, lv 48.\n",
      "Running group 0, task 0, lv 49.\n",
      "Running group 0, task 0, lv 50.\n",
      "Running group 0, task 0, lv 51.\n",
      "Running group 0, task 0, lv 52.\n",
      "Running group 0, task 0, lv 53.\n",
      "Running group 0, task 0, lv 54.\n",
      "Running group 0, task 0, lv 55.\n",
      "Running group 0, task 0, lv 56.\n",
      "Running group 0, task 0, lv 57.\n",
      "Running group 0, task 0, lv 58.\n",
      "Running group 0, task 0, lv 59.\n",
      "Running group 0, task 0, lv 60.\n",
      "Running group 0, task 0, lv 61.\n",
      "Running group 0, task 0, lv 62.\n",
      "Running group 0, task 0, lv 63.\n",
      "Running group 0, task 0, lv 64.\n",
      "Running group 0, task 0, lv 65.\n",
      "Running group 0, task 0, lv 66.\n",
      "Running group 0, task 0, lv 67.\n",
      "Running group 0, task 0, lv 68.\n",
      "Running group 0, task 0, lv 69.\n",
      "Running group 0, task 0, lv 70.\n",
      "Running group 0, task 0, lv 71.\n",
      "Running group 0, task 0, lv 72.\n",
      "Running group 0, task 0, lv 73.\n",
      "Running group 0, task 0, lv 74.\n",
      "Running group 0, task 0, lv 75.\n",
      "Running group 0, task 0, lv 76.\n",
      "Running group 0, task 0, lv 77.\n",
      "Running group 0, task 0, lv 78.\n",
      "Running group 0, task 0, lv 79.\n",
      "Running group 0, task 0, lv 80.\n",
      "Running group 0, task 0, lv 81.\n",
      "Running group 0, task 0, lv 82.\n",
      "Running group 0, task 0, lv 83.\n",
      "Running group 0, task 0, lv 84.\n",
      "Running group 0, task 0, lv 85.\n",
      "Running group 0, task 0, lv 86.\n",
      "Running group 0, task 0, lv 87.\n",
      "Running group 0, task 0, lv 88.\n",
      "Running group 0, task 0, lv 89.\n",
      "Running group 0, task 0, lv 90.\n",
      "Running group 0, task 0, lv 91.\n",
      "Running group 0, task 0, lv 92.\n",
      "Running group 0, task 0, lv 93.\n",
      "Running group 0, task 0, lv 94.\n",
      "Running group 0, task 0, lv 95.\n",
      "Running group 0, task 0, lv 96.\n",
      "Running group 0, task 0, lv 97.\n",
      "Running group 0, task 0, lv 98.\n",
      "Running group 0, task 0, lv 99.\n",
      "Running group 0, task 1, lv 0.\n",
      "Running group 0, task 1, lv 1.\n",
      "Running group 0, task 1, lv 2.\n",
      "Running group 0, task 1, lv 3.\n",
      "Running group 0, task 1, lv 4.\n",
      "Running group 0, task 1, lv 5.\n",
      "Running group 0, task 1, lv 6.\n",
      "Running group 0, task 1, lv 7.\n",
      "Running group 0, task 1, lv 8.\n",
      "Running group 0, task 1, lv 9.\n",
      "Running group 0, task 1, lv 10.\n",
      "Running group 0, task 1, lv 11.\n",
      "Running group 0, task 1, lv 12.\n",
      "Running group 0, task 1, lv 13.\n",
      "Running group 0, task 1, lv 14.\n",
      "Running group 0, task 1, lv 15.\n",
      "Running group 0, task 1, lv 16.\n",
      "Running group 0, task 1, lv 17.\n",
      "Running group 0, task 1, lv 18.\n",
      "Running group 0, task 1, lv 19.\n",
      "Running group 0, task 1, lv 20.\n",
      "Running group 0, task 1, lv 21.\n",
      "Running group 0, task 1, lv 22.\n",
      "Running group 0, task 1, lv 23.\n",
      "Running group 0, task 1, lv 24.\n",
      "Running group 0, task 1, lv 25.\n",
      "Running group 0, task 1, lv 26.\n",
      "Running group 0, task 1, lv 27.\n",
      "Running group 0, task 1, lv 28.\n",
      "Running group 0, task 1, lv 29.\n",
      "Running group 0, task 1, lv 30.\n",
      "Running group 0, task 1, lv 31.\n",
      "Running group 0, task 1, lv 32.\n",
      "Running group 0, task 1, lv 33.\n",
      "Running group 0, task 1, lv 34.\n",
      "Running group 0, task 1, lv 35.\n",
      "Running group 0, task 1, lv 36.\n",
      "Running group 0, task 1, lv 37.\n",
      "Running group 0, task 1, lv 38.\n",
      "Running group 0, task 1, lv 39.\n",
      "Running group 0, task 1, lv 40.\n",
      "Running group 0, task 1, lv 41.\n",
      "Running group 0, task 1, lv 42.\n",
      "Running group 0, task 1, lv 43.\n",
      "Running group 0, task 1, lv 44.\n",
      "Running group 0, task 1, lv 45.\n",
      "Running group 0, task 1, lv 46.\n",
      "Running group 0, task 1, lv 47.\n",
      "Running group 0, task 1, lv 48.\n",
      "Running group 0, task 1, lv 49.\n",
      "Running group 0, task 1, lv 50.\n",
      "Running group 0, task 1, lv 51.\n",
      "Running group 0, task 1, lv 52.\n",
      "Running group 0, task 1, lv 53.\n",
      "Running group 0, task 1, lv 54.\n",
      "Running group 0, task 1, lv 55.\n",
      "Running group 0, task 1, lv 56.\n",
      "Running group 0, task 1, lv 57.\n",
      "Running group 0, task 1, lv 58.\n",
      "Running group 0, task 1, lv 59.\n",
      "Running group 0, task 1, lv 60.\n",
      "Running group 0, task 1, lv 61.\n",
      "Running group 0, task 1, lv 62.\n",
      "Running group 0, task 1, lv 63.\n",
      "Running group 0, task 1, lv 64.\n",
      "Running group 0, task 1, lv 65.\n",
      "Running group 0, task 1, lv 66.\n",
      "Running group 0, task 1, lv 67.\n",
      "Running group 0, task 1, lv 68.\n",
      "Running group 0, task 1, lv 69.\n",
      "Running group 0, task 1, lv 70.\n",
      "Running group 0, task 1, lv 71.\n",
      "Running group 0, task 1, lv 72.\n",
      "Running group 0, task 1, lv 73.\n",
      "Running group 0, task 1, lv 74.\n",
      "Running group 0, task 1, lv 75.\n",
      "Running group 0, task 1, lv 76.\n",
      "Running group 0, task 1, lv 77.\n",
      "Running group 0, task 1, lv 78.\n",
      "Running group 0, task 1, lv 79.\n",
      "Running group 0, task 1, lv 80.\n",
      "Running group 0, task 1, lv 81.\n",
      "Running group 0, task 1, lv 82.\n",
      "Running group 0, task 1, lv 83.\n",
      "Running group 0, task 1, lv 84.\n",
      "Running group 0, task 1, lv 85.\n",
      "Running group 0, task 1, lv 86.\n",
      "Running group 0, task 1, lv 87.\n",
      "Running group 0, task 1, lv 88.\n",
      "Running group 0, task 1, lv 89.\n",
      "Running group 0, task 1, lv 90.\n",
      "Running group 0, task 1, lv 91.\n",
      "Running group 0, task 1, lv 92.\n",
      "Running group 0, task 1, lv 93.\n",
      "Running group 0, task 1, lv 94.\n",
      "Running group 0, task 1, lv 95.\n",
      "Running group 0, task 1, lv 96.\n",
      "Running group 0, task 1, lv 97.\n",
      "Running group 0, task 1, lv 98.\n",
      "Running group 0, task 1, lv 99.\n",
      "Running group 0, task 2, lv 0.\n",
      "Running group 0, task 2, lv 1.\n",
      "Running group 0, task 2, lv 2.\n",
      "Running group 0, task 2, lv 3.\n",
      "Running group 0, task 2, lv 4.\n",
      "Running group 0, task 2, lv 5.\n",
      "Running group 0, task 2, lv 6.\n",
      "Running group 0, task 2, lv 7.\n",
      "Running group 0, task 2, lv 8.\n",
      "Running group 0, task 2, lv 9.\n",
      "Running group 0, task 2, lv 10.\n",
      "Running group 0, task 2, lv 11.\n",
      "Running group 0, task 2, lv 12.\n",
      "Running group 0, task 2, lv 13.\n",
      "Running group 0, task 2, lv 14.\n",
      "Running group 0, task 2, lv 15.\n",
      "Running group 0, task 2, lv 16.\n",
      "Running group 0, task 2, lv 17.\n",
      "Running group 0, task 2, lv 18.\n",
      "Running group 0, task 2, lv 19.\n",
      "Running group 0, task 2, lv 20.\n",
      "Running group 0, task 2, lv 21.\n",
      "Running group 0, task 2, lv 22.\n",
      "Running group 0, task 2, lv 23.\n",
      "Running group 0, task 2, lv 24.\n",
      "Running group 0, task 2, lv 25.\n",
      "Running group 0, task 2, lv 26.\n",
      "Running group 0, task 2, lv 27.\n",
      "Running group 0, task 2, lv 28.\n",
      "Running group 0, task 2, lv 29.\n",
      "Running group 0, task 2, lv 30.\n",
      "Running group 0, task 2, lv 31.\n",
      "Running group 0, task 2, lv 32.\n",
      "Running group 0, task 2, lv 33.\n",
      "Running group 0, task 2, lv 34.\n",
      "Running group 0, task 2, lv 35.\n",
      "Running group 0, task 2, lv 36.\n",
      "Running group 0, task 2, lv 37.\n",
      "Running group 0, task 2, lv 38.\n",
      "Running group 0, task 2, lv 39.\n",
      "Running group 0, task 2, lv 40.\n",
      "Running group 0, task 2, lv 41.\n",
      "Running group 0, task 2, lv 42.\n",
      "Running group 0, task 2, lv 43.\n",
      "Running group 0, task 2, lv 44.\n",
      "Running group 0, task 2, lv 45.\n",
      "Running group 0, task 2, lv 46.\n",
      "Running group 0, task 2, lv 47.\n",
      "Running group 0, task 2, lv 48.\n",
      "Running group 0, task 2, lv 49.\n",
      "Running group 0, task 2, lv 50.\n",
      "Running group 0, task 2, lv 51.\n",
      "Running group 0, task 2, lv 52.\n",
      "Running group 0, task 2, lv 53.\n",
      "Running group 0, task 2, lv 54.\n",
      "Running group 0, task 2, lv 55.\n",
      "Running group 0, task 2, lv 56.\n",
      "Running group 0, task 2, lv 57.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running group 0, task 2, lv 58.\n",
      "Running group 0, task 2, lv 59.\n",
      "Running group 0, task 2, lv 60.\n",
      "Running group 0, task 2, lv 61.\n",
      "Running group 0, task 2, lv 62.\n",
      "Running group 0, task 2, lv 63.\n",
      "Running group 0, task 2, lv 64.\n",
      "Running group 0, task 2, lv 65.\n",
      "Running group 0, task 2, lv 66.\n",
      "Running group 0, task 2, lv 67.\n",
      "Running group 0, task 2, lv 68.\n",
      "Running group 0, task 2, lv 69.\n",
      "Running group 0, task 2, lv 70.\n",
      "Running group 0, task 2, lv 71.\n",
      "Running group 0, task 2, lv 72.\n",
      "Running group 0, task 2, lv 73.\n",
      "Running group 0, task 2, lv 74.\n",
      "Running group 0, task 2, lv 75.\n",
      "Running group 0, task 2, lv 76.\n",
      "Running group 0, task 2, lv 77.\n",
      "Running group 0, task 2, lv 78.\n",
      "Running group 0, task 2, lv 79.\n",
      "Running group 0, task 2, lv 80.\n",
      "Running group 0, task 2, lv 81.\n",
      "Running group 0, task 2, lv 82.\n",
      "Running group 0, task 2, lv 83.\n",
      "Running group 0, task 2, lv 84.\n",
      "Running group 0, task 2, lv 85.\n",
      "Running group 0, task 2, lv 86.\n",
      "Running group 0, task 2, lv 87.\n",
      "Running group 0, task 2, lv 88.\n",
      "Running group 0, task 2, lv 89.\n",
      "Running group 0, task 2, lv 90.\n",
      "Running group 0, task 2, lv 91.\n",
      "Running group 0, task 2, lv 92.\n",
      "Running group 0, task 2, lv 93.\n",
      "Running group 0, task 2, lv 94.\n",
      "Running group 0, task 2, lv 95.\n",
      "Running group 0, task 2, lv 96.\n",
      "Running group 0, task 2, lv 97.\n",
      "Running group 0, task 2, lv 98.\n",
      "Running group 0, task 2, lv 99.\n",
      "Running group 1, task 0, lv 0.\n",
      "Running group 1, task 0, lv 1.\n",
      "Running group 1, task 0, lv 2.\n",
      "Running group 1, task 0, lv 3.\n",
      "Running group 1, task 0, lv 4.\n",
      "Running group 1, task 0, lv 5.\n",
      "Running group 1, task 0, lv 6.\n",
      "Running group 1, task 0, lv 7.\n",
      "Running group 1, task 0, lv 8.\n",
      "Running group 1, task 0, lv 9.\n",
      "Running group 1, task 0, lv 10.\n",
      "Running group 1, task 0, lv 11.\n",
      "Running group 1, task 0, lv 12.\n",
      "Running group 1, task 0, lv 13.\n",
      "Running group 1, task 0, lv 14.\n",
      "Running group 1, task 0, lv 15.\n",
      "Running group 1, task 0, lv 16.\n",
      "Running group 1, task 0, lv 17.\n",
      "Running group 1, task 0, lv 18.\n",
      "Running group 1, task 0, lv 19.\n",
      "Running group 1, task 0, lv 20.\n",
      "Running group 1, task 0, lv 21.\n",
      "Running group 1, task 0, lv 22.\n",
      "Running group 1, task 0, lv 23.\n",
      "Running group 1, task 0, lv 24.\n",
      "Running group 1, task 0, lv 25.\n",
      "Running group 1, task 0, lv 26.\n",
      "Running group 1, task 0, lv 27.\n",
      "Running group 1, task 0, lv 28.\n",
      "Running group 1, task 0, lv 29.\n",
      "Running group 1, task 0, lv 30.\n",
      "Running group 1, task 0, lv 31.\n",
      "Running group 1, task 0, lv 32.\n",
      "Running group 1, task 0, lv 33.\n",
      "Running group 1, task 0, lv 34.\n",
      "Running group 1, task 0, lv 35.\n",
      "Running group 1, task 0, lv 36.\n",
      "Running group 1, task 0, lv 37.\n",
      "Running group 1, task 0, lv 38.\n",
      "Running group 1, task 0, lv 39.\n",
      "Running group 1, task 0, lv 40.\n",
      "Running group 1, task 0, lv 41.\n",
      "Running group 1, task 0, lv 42.\n",
      "Running group 1, task 0, lv 43.\n",
      "Running group 1, task 0, lv 44.\n",
      "Running group 1, task 0, lv 45.\n",
      "Running group 1, task 0, lv 46.\n",
      "Running group 1, task 0, lv 47.\n",
      "Running group 1, task 0, lv 48.\n",
      "Running group 1, task 0, lv 49.\n",
      "Running group 1, task 0, lv 50.\n",
      "Running group 1, task 0, lv 51.\n",
      "Running group 1, task 0, lv 52.\n",
      "Running group 1, task 0, lv 53.\n",
      "Running group 1, task 0, lv 54.\n",
      "Running group 1, task 0, lv 55.\n",
      "Running group 1, task 0, lv 56.\n",
      "Running group 1, task 0, lv 57.\n",
      "Running group 1, task 0, lv 58.\n",
      "Running group 1, task 0, lv 59.\n",
      "Running group 1, task 0, lv 60.\n",
      "Running group 1, task 0, lv 61.\n",
      "Running group 1, task 0, lv 62.\n",
      "Running group 1, task 0, lv 63.\n",
      "Running group 1, task 0, lv 64.\n",
      "Running group 1, task 0, lv 65.\n",
      "Running group 1, task 0, lv 66.\n",
      "Running group 1, task 0, lv 67.\n",
      "Running group 1, task 0, lv 68.\n",
      "Running group 1, task 0, lv 69.\n",
      "Running group 1, task 0, lv 70.\n",
      "Running group 1, task 0, lv 71.\n",
      "Running group 1, task 0, lv 72.\n",
      "Running group 1, task 0, lv 73.\n",
      "Running group 1, task 0, lv 74.\n",
      "Running group 1, task 0, lv 75.\n",
      "Running group 1, task 0, lv 76.\n",
      "Running group 1, task 0, lv 77.\n",
      "Running group 1, task 0, lv 78.\n",
      "Running group 1, task 0, lv 79.\n",
      "Running group 1, task 0, lv 80.\n",
      "Running group 1, task 0, lv 81.\n",
      "Running group 1, task 0, lv 82.\n",
      "Running group 1, task 0, lv 83.\n",
      "Running group 1, task 0, lv 84.\n",
      "Running group 1, task 0, lv 85.\n",
      "Running group 1, task 0, lv 86.\n",
      "Running group 1, task 0, lv 87.\n",
      "Running group 1, task 0, lv 88.\n",
      "Running group 1, task 0, lv 89.\n",
      "Running group 1, task 0, lv 90.\n",
      "Running group 1, task 0, lv 91.\n",
      "Running group 1, task 0, lv 92.\n",
      "Running group 1, task 0, lv 93.\n",
      "Running group 1, task 0, lv 94.\n",
      "Running group 1, task 0, lv 95.\n",
      "Running group 1, task 0, lv 96.\n",
      "Running group 1, task 0, lv 97.\n",
      "Running group 1, task 0, lv 98.\n",
      "Running group 1, task 0, lv 99.\n",
      "Running group 1, task 1, lv 0.\n",
      "Running group 1, task 1, lv 1.\n",
      "Running group 1, task 1, lv 2.\n",
      "Running group 1, task 1, lv 3.\n",
      "Running group 1, task 1, lv 4.\n",
      "Running group 1, task 1, lv 5.\n",
      "Running group 1, task 1, lv 6.\n",
      "Running group 1, task 1, lv 7.\n",
      "Running group 1, task 1, lv 8.\n",
      "Running group 1, task 1, lv 9.\n",
      "Running group 1, task 1, lv 10.\n",
      "Running group 1, task 1, lv 11.\n",
      "Running group 1, task 1, lv 12.\n",
      "Running group 1, task 1, lv 13.\n",
      "Running group 1, task 1, lv 14.\n",
      "Running group 1, task 1, lv 15.\n",
      "Running group 1, task 1, lv 16.\n",
      "Running group 1, task 1, lv 17.\n",
      "Running group 1, task 1, lv 18.\n",
      "Running group 1, task 1, lv 19.\n",
      "Running group 1, task 1, lv 20.\n",
      "Running group 1, task 1, lv 21.\n",
      "Running group 1, task 1, lv 22.\n",
      "Running group 1, task 1, lv 23.\n",
      "Running group 1, task 1, lv 24.\n",
      "Running group 1, task 1, lv 25.\n",
      "Running group 1, task 1, lv 26.\n",
      "Running group 1, task 1, lv 27.\n",
      "Running group 1, task 1, lv 28.\n",
      "Running group 1, task 1, lv 29.\n",
      "Running group 1, task 1, lv 30.\n",
      "Running group 1, task 1, lv 31.\n",
      "Running group 1, task 1, lv 32.\n",
      "Running group 1, task 1, lv 33.\n",
      "Running group 1, task 1, lv 34.\n",
      "Running group 1, task 1, lv 35.\n",
      "Running group 1, task 1, lv 36.\n",
      "Running group 1, task 1, lv 37.\n",
      "Running group 1, task 1, lv 38.\n",
      "Running group 1, task 1, lv 39.\n",
      "Running group 1, task 1, lv 40.\n",
      "Running group 1, task 1, lv 41.\n",
      "Running group 1, task 1, lv 42.\n",
      "Running group 1, task 1, lv 43.\n",
      "Running group 1, task 1, lv 44.\n",
      "Running group 1, task 1, lv 45.\n",
      "Running group 1, task 1, lv 46.\n",
      "Running group 1, task 1, lv 47.\n",
      "Running group 1, task 1, lv 48.\n",
      "Running group 1, task 1, lv 49.\n",
      "Running group 1, task 1, lv 50.\n",
      "Running group 1, task 1, lv 51.\n",
      "Running group 1, task 1, lv 52.\n",
      "Running group 1, task 1, lv 53.\n",
      "Running group 1, task 1, lv 54.\n",
      "Running group 1, task 1, lv 55.\n",
      "Running group 1, task 1, lv 56.\n",
      "Running group 1, task 1, lv 57.\n",
      "Running group 1, task 1, lv 58.\n",
      "Running group 1, task 1, lv 59.\n",
      "Running group 1, task 1, lv 60.\n",
      "Running group 1, task 1, lv 61.\n",
      "Running group 1, task 1, lv 62.\n",
      "Running group 1, task 1, lv 63.\n",
      "Running group 1, task 1, lv 64.\n",
      "Running group 1, task 1, lv 65.\n",
      "Running group 1, task 1, lv 66.\n",
      "Running group 1, task 1, lv 67.\n",
      "Running group 1, task 1, lv 68.\n",
      "Running group 1, task 1, lv 69.\n",
      "Running group 1, task 1, lv 70.\n",
      "Running group 1, task 1, lv 71.\n",
      "Running group 1, task 1, lv 72.\n",
      "Running group 1, task 1, lv 73.\n",
      "Running group 1, task 1, lv 74.\n",
      "Running group 1, task 1, lv 75.\n",
      "Running group 1, task 1, lv 76.\n",
      "Running group 1, task 1, lv 77.\n",
      "Running group 1, task 1, lv 78.\n",
      "Running group 1, task 1, lv 79.\n",
      "Running group 1, task 1, lv 80.\n",
      "Running group 1, task 1, lv 81.\n",
      "Running group 1, task 1, lv 82.\n",
      "Running group 1, task 1, lv 83.\n",
      "Running group 1, task 1, lv 84.\n",
      "Running group 1, task 1, lv 85.\n",
      "Running group 1, task 1, lv 86.\n",
      "Running group 1, task 1, lv 87.\n",
      "Running group 1, task 1, lv 88.\n",
      "Running group 1, task 1, lv 89.\n",
      "Running group 1, task 1, lv 90.\n",
      "Running group 1, task 1, lv 91.\n",
      "Running group 1, task 1, lv 92.\n",
      "Running group 1, task 1, lv 93.\n",
      "Running group 1, task 1, lv 94.\n",
      "Running group 1, task 1, lv 95.\n",
      "Running group 1, task 1, lv 96.\n",
      "Running group 1, task 1, lv 97.\n",
      "Running group 1, task 1, lv 98.\n",
      "Running group 1, task 1, lv 99.\n",
      "Running group 1, task 2, lv 0.\n",
      "Running group 1, task 2, lv 1.\n",
      "Running group 1, task 2, lv 2.\n",
      "Running group 1, task 2, lv 3.\n",
      "Running group 1, task 2, lv 4.\n",
      "Running group 1, task 2, lv 5.\n",
      "Running group 1, task 2, lv 6.\n",
      "Running group 1, task 2, lv 7.\n",
      "Running group 1, task 2, lv 8.\n",
      "Running group 1, task 2, lv 9.\n",
      "Running group 1, task 2, lv 10.\n",
      "Running group 1, task 2, lv 11.\n",
      "Running group 1, task 2, lv 12.\n",
      "Running group 1, task 2, lv 13.\n",
      "Running group 1, task 2, lv 14.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running group 1, task 2, lv 15.\n",
      "Running group 1, task 2, lv 16.\n",
      "Running group 1, task 2, lv 17.\n",
      "Running group 1, task 2, lv 18.\n",
      "Running group 1, task 2, lv 19.\n",
      "Running group 1, task 2, lv 20.\n",
      "Running group 1, task 2, lv 21.\n",
      "Running group 1, task 2, lv 22.\n",
      "Running group 1, task 2, lv 23.\n",
      "Running group 1, task 2, lv 24.\n",
      "Running group 1, task 2, lv 25.\n",
      "Running group 1, task 2, lv 26.\n",
      "Running group 1, task 2, lv 27.\n",
      "Running group 1, task 2, lv 28.\n",
      "Running group 1, task 2, lv 29.\n",
      "Running group 1, task 2, lv 30.\n",
      "Running group 1, task 2, lv 31.\n",
      "Running group 1, task 2, lv 32.\n",
      "Running group 1, task 2, lv 33.\n",
      "Running group 1, task 2, lv 34.\n",
      "Running group 1, task 2, lv 35.\n",
      "Running group 1, task 2, lv 36.\n",
      "Running group 1, task 2, lv 37.\n",
      "Running group 1, task 2, lv 38.\n",
      "Running group 1, task 2, lv 39.\n",
      "Running group 1, task 2, lv 40.\n",
      "Running group 1, task 2, lv 41.\n",
      "Running group 1, task 2, lv 42.\n",
      "Running group 1, task 2, lv 43.\n",
      "Running group 1, task 2, lv 44.\n",
      "Running group 1, task 2, lv 45.\n",
      "Running group 1, task 2, lv 46.\n",
      "Running group 1, task 2, lv 47.\n",
      "Running group 1, task 2, lv 48.\n",
      "Running group 1, task 2, lv 49.\n",
      "Running group 1, task 2, lv 50.\n",
      "Running group 1, task 2, lv 51.\n",
      "Running group 1, task 2, lv 52.\n",
      "Running group 1, task 2, lv 53.\n",
      "Running group 1, task 2, lv 54.\n",
      "Running group 1, task 2, lv 55.\n",
      "Running group 1, task 2, lv 56.\n",
      "Running group 1, task 2, lv 57.\n",
      "Running group 1, task 2, lv 58.\n",
      "Running group 1, task 2, lv 59.\n",
      "Running group 1, task 2, lv 60.\n",
      "Running group 1, task 2, lv 61.\n",
      "Running group 1, task 2, lv 62.\n",
      "Running group 1, task 2, lv 63.\n",
      "Running group 1, task 2, lv 64.\n",
      "Running group 1, task 2, lv 65.\n",
      "Running group 1, task 2, lv 66.\n",
      "Running group 1, task 2, lv 67.\n",
      "Running group 1, task 2, lv 68.\n",
      "Running group 1, task 2, lv 69.\n",
      "Running group 1, task 2, lv 70.\n",
      "Running group 1, task 2, lv 71.\n",
      "Running group 1, task 2, lv 72.\n",
      "Running group 1, task 2, lv 73.\n",
      "Running group 1, task 2, lv 74.\n",
      "Running group 1, task 2, lv 75.\n",
      "Running group 1, task 2, lv 76.\n",
      "Running group 1, task 2, lv 77.\n",
      "Running group 1, task 2, lv 78.\n",
      "Running group 1, task 2, lv 79.\n",
      "Running group 1, task 2, lv 80.\n",
      "Running group 1, task 2, lv 81.\n",
      "Running group 1, task 2, lv 82.\n",
      "Running group 1, task 2, lv 83.\n",
      "Running group 1, task 2, lv 84.\n",
      "Running group 1, task 2, lv 85.\n",
      "Running group 1, task 2, lv 86.\n",
      "Running group 1, task 2, lv 87.\n",
      "Running group 1, task 2, lv 88.\n",
      "Running group 1, task 2, lv 89.\n",
      "Running group 1, task 2, lv 90.\n",
      "Running group 1, task 2, lv 91.\n",
      "Running group 1, task 2, lv 92.\n",
      "Running group 1, task 2, lv 93.\n",
      "Running group 1, task 2, lv 94.\n",
      "Running group 1, task 2, lv 95.\n",
      "Running group 1, task 2, lv 96.\n",
      "Running group 1, task 2, lv 97.\n",
      "Running group 1, task 2, lv 98.\n",
      "Running group 1, task 2, lv 99.\n",
      "Running group 2, task 0, lv 0.\n",
      "Running group 2, task 0, lv 1.\n",
      "Running group 2, task 0, lv 2.\n",
      "Running group 2, task 0, lv 3.\n",
      "Running group 2, task 0, lv 4.\n",
      "Running group 2, task 0, lv 5.\n",
      "Running group 2, task 0, lv 6.\n",
      "Running group 2, task 0, lv 7.\n",
      "Running group 2, task 0, lv 8.\n",
      "Running group 2, task 0, lv 9.\n",
      "Running group 2, task 0, lv 10.\n",
      "Running group 2, task 0, lv 11.\n",
      "Running group 2, task 0, lv 12.\n",
      "Running group 2, task 0, lv 13.\n",
      "Running group 2, task 0, lv 14.\n",
      "Running group 2, task 0, lv 15.\n",
      "Running group 2, task 0, lv 16.\n",
      "Running group 2, task 0, lv 17.\n",
      "Running group 2, task 0, lv 18.\n",
      "Running group 2, task 0, lv 19.\n",
      "Running group 2, task 0, lv 20.\n",
      "Running group 2, task 0, lv 21.\n",
      "Running group 2, task 0, lv 22.\n",
      "Running group 2, task 0, lv 23.\n",
      "Running group 2, task 0, lv 24.\n",
      "Running group 2, task 0, lv 25.\n",
      "Running group 2, task 0, lv 26.\n",
      "Running group 2, task 0, lv 27.\n",
      "Running group 2, task 0, lv 28.\n",
      "Running group 2, task 0, lv 29.\n",
      "Running group 2, task 0, lv 30.\n",
      "Running group 2, task 0, lv 31.\n",
      "Running group 2, task 0, lv 32.\n",
      "Running group 2, task 0, lv 33.\n",
      "Running group 2, task 0, lv 34.\n",
      "Running group 2, task 0, lv 35.\n",
      "Running group 2, task 0, lv 36.\n",
      "Running group 2, task 0, lv 37.\n",
      "Running group 2, task 0, lv 38.\n",
      "Running group 2, task 0, lv 39.\n",
      "Running group 2, task 0, lv 40.\n",
      "Running group 2, task 0, lv 41.\n",
      "Running group 2, task 0, lv 42.\n",
      "Running group 2, task 0, lv 43.\n",
      "Running group 2, task 0, lv 44.\n",
      "Running group 2, task 0, lv 45.\n",
      "Running group 2, task 0, lv 46.\n",
      "Running group 2, task 0, lv 47.\n",
      "Running group 2, task 0, lv 48.\n",
      "Running group 2, task 0, lv 49.\n",
      "Running group 2, task 0, lv 50.\n",
      "Running group 2, task 0, lv 51.\n",
      "Running group 2, task 0, lv 52.\n",
      "Running group 2, task 0, lv 53.\n",
      "Running group 2, task 0, lv 54.\n",
      "Running group 2, task 0, lv 55.\n",
      "Running group 2, task 0, lv 56.\n",
      "Running group 2, task 0, lv 57.\n",
      "Running group 2, task 0, lv 58.\n",
      "Running group 2, task 0, lv 59.\n",
      "Running group 2, task 0, lv 60.\n",
      "Running group 2, task 0, lv 61.\n",
      "Running group 2, task 0, lv 62.\n",
      "Running group 2, task 0, lv 63.\n",
      "Running group 2, task 0, lv 64.\n",
      "Running group 2, task 0, lv 65.\n",
      "Running group 2, task 0, lv 66.\n",
      "Running group 2, task 0, lv 67.\n",
      "Running group 2, task 0, lv 68.\n",
      "Running group 2, task 0, lv 69.\n",
      "Running group 2, task 0, lv 70.\n",
      "Running group 2, task 0, lv 71.\n",
      "Running group 2, task 0, lv 72.\n",
      "Running group 2, task 0, lv 73.\n",
      "Running group 2, task 0, lv 74.\n",
      "Running group 2, task 0, lv 75.\n",
      "Running group 2, task 0, lv 76.\n",
      "Running group 2, task 0, lv 77.\n",
      "Running group 2, task 0, lv 78.\n",
      "Running group 2, task 0, lv 79.\n",
      "Running group 2, task 0, lv 80.\n",
      "Running group 2, task 0, lv 81.\n",
      "Running group 2, task 0, lv 82.\n",
      "Running group 2, task 0, lv 83.\n",
      "Running group 2, task 0, lv 84.\n",
      "Running group 2, task 0, lv 85.\n",
      "Running group 2, task 0, lv 86.\n",
      "Running group 2, task 0, lv 87.\n",
      "Running group 2, task 0, lv 88.\n",
      "Running group 2, task 0, lv 89.\n",
      "Running group 2, task 0, lv 90.\n",
      "Running group 2, task 0, lv 91.\n",
      "Running group 2, task 0, lv 92.\n",
      "Running group 2, task 0, lv 93.\n",
      "Running group 2, task 0, lv 94.\n",
      "Running group 2, task 0, lv 95.\n",
      "Running group 2, task 0, lv 96.\n",
      "Running group 2, task 0, lv 97.\n",
      "Running group 2, task 0, lv 98.\n",
      "Running group 2, task 0, lv 99.\n",
      "Running group 2, task 1, lv 0.\n",
      "Running group 2, task 1, lv 1.\n",
      "Running group 2, task 1, lv 2.\n",
      "Running group 2, task 1, lv 3.\n",
      "Running group 2, task 1, lv 4.\n",
      "Running group 2, task 1, lv 5.\n",
      "Running group 2, task 1, lv 6.\n",
      "Running group 2, task 1, lv 7.\n",
      "Running group 2, task 1, lv 8.\n",
      "Running group 2, task 1, lv 9.\n",
      "Running group 2, task 1, lv 10.\n",
      "Running group 2, task 1, lv 11.\n",
      "Running group 2, task 1, lv 12.\n",
      "Running group 2, task 1, lv 13.\n",
      "Running group 2, task 1, lv 14.\n",
      "Running group 2, task 1, lv 15.\n",
      "Running group 2, task 1, lv 16.\n",
      "Running group 2, task 1, lv 17.\n",
      "Running group 2, task 1, lv 18.\n",
      "Running group 2, task 1, lv 19.\n",
      "Running group 2, task 1, lv 20.\n",
      "Running group 2, task 1, lv 21.\n",
      "Running group 2, task 1, lv 22.\n",
      "Running group 2, task 1, lv 23.\n",
      "Running group 2, task 1, lv 24.\n",
      "Running group 2, task 1, lv 25.\n",
      "Running group 2, task 1, lv 26.\n",
      "Running group 2, task 1, lv 27.\n",
      "Running group 2, task 1, lv 28.\n",
      "Running group 2, task 1, lv 29.\n",
      "Running group 2, task 1, lv 30.\n",
      "Running group 2, task 1, lv 31.\n",
      "Running group 2, task 1, lv 32.\n",
      "Running group 2, task 1, lv 33.\n",
      "Running group 2, task 1, lv 34.\n",
      "Running group 2, task 1, lv 35.\n",
      "Running group 2, task 1, lv 36.\n",
      "Running group 2, task 1, lv 37.\n",
      "Running group 2, task 1, lv 38.\n",
      "Running group 2, task 1, lv 39.\n",
      "Running group 2, task 1, lv 40.\n",
      "Running group 2, task 1, lv 41.\n",
      "Running group 2, task 1, lv 42.\n",
      "Running group 2, task 1, lv 43.\n",
      "Running group 2, task 1, lv 44.\n",
      "Running group 2, task 1, lv 45.\n",
      "Running group 2, task 1, lv 46.\n",
      "Running group 2, task 1, lv 47.\n",
      "Running group 2, task 1, lv 48.\n",
      "Running group 2, task 1, lv 49.\n",
      "Running group 2, task 1, lv 50.\n",
      "Running group 2, task 1, lv 51.\n",
      "Running group 2, task 1, lv 52.\n",
      "Running group 2, task 1, lv 53.\n",
      "Running group 2, task 1, lv 54.\n",
      "Running group 2, task 1, lv 55.\n",
      "Running group 2, task 1, lv 56.\n",
      "Running group 2, task 1, lv 57.\n",
      "Running group 2, task 1, lv 58.\n",
      "Running group 2, task 1, lv 59.\n",
      "Running group 2, task 1, lv 60.\n",
      "Running group 2, task 1, lv 61.\n",
      "Running group 2, task 1, lv 62.\n",
      "Running group 2, task 1, lv 63.\n",
      "Running group 2, task 1, lv 64.\n",
      "Running group 2, task 1, lv 65.\n",
      "Running group 2, task 1, lv 66.\n",
      "Running group 2, task 1, lv 67.\n",
      "Running group 2, task 1, lv 68.\n",
      "Running group 2, task 1, lv 69.\n",
      "Running group 2, task 1, lv 70.\n",
      "Running group 2, task 1, lv 71.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running group 2, task 1, lv 72.\n",
      "Running group 2, task 1, lv 73.\n",
      "Running group 2, task 1, lv 74.\n",
      "Running group 2, task 1, lv 75.\n",
      "Running group 2, task 1, lv 76.\n",
      "Running group 2, task 1, lv 77.\n",
      "Running group 2, task 1, lv 78.\n",
      "Running group 2, task 1, lv 79.\n",
      "Running group 2, task 1, lv 80.\n",
      "Running group 2, task 1, lv 81.\n",
      "Running group 2, task 1, lv 82.\n",
      "Running group 2, task 1, lv 83.\n",
      "Running group 2, task 1, lv 84.\n",
      "Running group 2, task 1, lv 85.\n",
      "Running group 2, task 1, lv 86.\n",
      "Running group 2, task 1, lv 87.\n",
      "Running group 2, task 1, lv 88.\n",
      "Running group 2, task 1, lv 89.\n",
      "Running group 2, task 1, lv 90.\n",
      "Running group 2, task 1, lv 91.\n",
      "Running group 2, task 1, lv 92.\n",
      "Running group 2, task 1, lv 93.\n",
      "Running group 2, task 1, lv 94.\n",
      "Running group 2, task 1, lv 95.\n",
      "Running group 2, task 1, lv 96.\n",
      "Running group 2, task 1, lv 97.\n",
      "Running group 2, task 1, lv 98.\n",
      "Running group 2, task 1, lv 99.\n",
      "Running group 2, task 2, lv 0.\n",
      "Running group 2, task 2, lv 1.\n",
      "Running group 2, task 2, lv 2.\n",
      "Running group 2, task 2, lv 3.\n",
      "Running group 2, task 2, lv 4.\n",
      "Running group 2, task 2, lv 5.\n",
      "Running group 2, task 2, lv 6.\n",
      "Running group 2, task 2, lv 7.\n",
      "Running group 2, task 2, lv 8.\n",
      "Running group 2, task 2, lv 9.\n",
      "Running group 2, task 2, lv 10.\n",
      "Running group 2, task 2, lv 11.\n",
      "Running group 2, task 2, lv 12.\n",
      "Running group 2, task 2, lv 13.\n",
      "Running group 2, task 2, lv 14.\n",
      "Running group 2, task 2, lv 15.\n",
      "Running group 2, task 2, lv 16.\n",
      "Running group 2, task 2, lv 17.\n",
      "Running group 2, task 2, lv 18.\n",
      "Running group 2, task 2, lv 19.\n",
      "Running group 2, task 2, lv 20.\n",
      "Running group 2, task 2, lv 21.\n",
      "Running group 2, task 2, lv 22.\n",
      "Running group 2, task 2, lv 23.\n",
      "Running group 2, task 2, lv 24.\n",
      "Running group 2, task 2, lv 25.\n",
      "Running group 2, task 2, lv 26.\n",
      "Running group 2, task 2, lv 27.\n",
      "Running group 2, task 2, lv 28.\n",
      "Running group 2, task 2, lv 29.\n",
      "Running group 2, task 2, lv 30.\n",
      "Running group 2, task 2, lv 31.\n",
      "Running group 2, task 2, lv 32.\n",
      "Running group 2, task 2, lv 33.\n",
      "Running group 2, task 2, lv 34.\n",
      "Running group 2, task 2, lv 35.\n",
      "Running group 2, task 2, lv 36.\n",
      "Running group 2, task 2, lv 37.\n",
      "Running group 2, task 2, lv 38.\n",
      "Running group 2, task 2, lv 39.\n",
      "Running group 2, task 2, lv 40.\n",
      "Running group 2, task 2, lv 41.\n",
      "Running group 2, task 2, lv 42.\n",
      "Running group 2, task 2, lv 43.\n",
      "Running group 2, task 2, lv 44.\n",
      "Running group 2, task 2, lv 45.\n",
      "Running group 2, task 2, lv 46.\n",
      "Running group 2, task 2, lv 47.\n",
      "Running group 2, task 2, lv 48.\n",
      "Running group 2, task 2, lv 49.\n",
      "Running group 2, task 2, lv 50.\n",
      "Running group 2, task 2, lv 51.\n",
      "Running group 2, task 2, lv 52.\n",
      "Running group 2, task 2, lv 53.\n",
      "Running group 2, task 2, lv 54.\n",
      "Running group 2, task 2, lv 55.\n",
      "Running group 2, task 2, lv 56.\n",
      "Running group 2, task 2, lv 57.\n",
      "Running group 2, task 2, lv 58.\n",
      "Running group 2, task 2, lv 59.\n",
      "Running group 2, task 2, lv 60.\n",
      "Running group 2, task 2, lv 61.\n",
      "Running group 2, task 2, lv 62.\n",
      "Running group 2, task 2, lv 63.\n",
      "Running group 2, task 2, lv 64.\n",
      "Running group 2, task 2, lv 65.\n",
      "Running group 2, task 2, lv 66.\n",
      "Running group 2, task 2, lv 67.\n",
      "Running group 2, task 2, lv 68.\n",
      "Running group 2, task 2, lv 69.\n",
      "Running group 2, task 2, lv 70.\n",
      "Running group 2, task 2, lv 71.\n",
      "Running group 2, task 2, lv 72.\n",
      "Running group 2, task 2, lv 73.\n",
      "Running group 2, task 2, lv 74.\n",
      "Running group 2, task 2, lv 75.\n",
      "Running group 2, task 2, lv 76.\n",
      "Running group 2, task 2, lv 77.\n",
      "Running group 2, task 2, lv 78.\n",
      "Running group 2, task 2, lv 79.\n",
      "Running group 2, task 2, lv 80.\n",
      "Running group 2, task 2, lv 81.\n",
      "Running group 2, task 2, lv 82.\n",
      "Running group 2, task 2, lv 83.\n",
      "Running group 2, task 2, lv 84.\n",
      "Running group 2, task 2, lv 85.\n",
      "Running group 2, task 2, lv 86.\n",
      "Running group 2, task 2, lv 87.\n",
      "Running group 2, task 2, lv 88.\n",
      "Running group 2, task 2, lv 89.\n",
      "Running group 2, task 2, lv 90.\n",
      "Running group 2, task 2, lv 91.\n",
      "Running group 2, task 2, lv 92.\n",
      "Running group 2, task 2, lv 93.\n",
      "Running group 2, task 2, lv 94.\n",
      "Running group 2, task 2, lv 95.\n",
      "Running group 2, task 2, lv 96.\n",
      "Running group 2, task 2, lv 97.\n",
      "Running group 2, task 2, lv 98.\n",
      "Running group 2, task 2, lv 99.\n",
      "Running group 3, task 0, lv 0.\n",
      "Running group 3, task 0, lv 1.\n",
      "Running group 3, task 0, lv 2.\n",
      "Running group 3, task 0, lv 3.\n",
      "Running group 3, task 0, lv 4.\n",
      "Running group 3, task 0, lv 5.\n",
      "Running group 3, task 0, lv 6.\n",
      "Running group 3, task 0, lv 7.\n",
      "Running group 3, task 0, lv 8.\n",
      "Running group 3, task 0, lv 9.\n",
      "Running group 3, task 0, lv 10.\n",
      "Running group 3, task 0, lv 11.\n",
      "Running group 3, task 0, lv 12.\n",
      "Running group 3, task 0, lv 13.\n",
      "Running group 3, task 0, lv 14.\n",
      "Running group 3, task 0, lv 15.\n",
      "Running group 3, task 0, lv 16.\n",
      "Running group 3, task 0, lv 17.\n",
      "Running group 3, task 0, lv 18.\n",
      "Running group 3, task 0, lv 19.\n",
      "Running group 3, task 0, lv 20.\n",
      "Running group 3, task 0, lv 21.\n",
      "Running group 3, task 0, lv 22.\n",
      "Running group 3, task 0, lv 23.\n",
      "Running group 3, task 0, lv 24.\n",
      "Running group 3, task 0, lv 25.\n",
      "Running group 3, task 0, lv 26.\n",
      "Running group 3, task 0, lv 27.\n",
      "Running group 3, task 0, lv 28.\n",
      "Running group 3, task 0, lv 29.\n",
      "Running group 3, task 0, lv 30.\n",
      "Running group 3, task 0, lv 31.\n",
      "Running group 3, task 0, lv 32.\n",
      "Running group 3, task 0, lv 33.\n",
      "Running group 3, task 0, lv 34.\n",
      "Running group 3, task 0, lv 35.\n",
      "Running group 3, task 0, lv 36.\n",
      "Running group 3, task 0, lv 37.\n",
      "Running group 3, task 0, lv 38.\n",
      "Running group 3, task 0, lv 39.\n",
      "Running group 3, task 0, lv 40.\n",
      "Running group 3, task 0, lv 41.\n",
      "Running group 3, task 0, lv 42.\n",
      "Running group 3, task 0, lv 43.\n",
      "Running group 3, task 0, lv 44.\n",
      "Running group 3, task 0, lv 45.\n",
      "Running group 3, task 0, lv 46.\n",
      "Running group 3, task 0, lv 47.\n",
      "Running group 3, task 0, lv 48.\n",
      "Running group 3, task 0, lv 49.\n",
      "Running group 3, task 0, lv 50.\n",
      "Running group 3, task 0, lv 51.\n",
      "Running group 3, task 0, lv 52.\n",
      "Running group 3, task 0, lv 53.\n",
      "Running group 3, task 0, lv 54.\n",
      "Running group 3, task 0, lv 55.\n",
      "Running group 3, task 0, lv 56.\n",
      "Running group 3, task 0, lv 57.\n",
      "Running group 3, task 0, lv 58.\n",
      "Running group 3, task 0, lv 59.\n",
      "Running group 3, task 0, lv 60.\n",
      "Running group 3, task 0, lv 61.\n",
      "Running group 3, task 0, lv 62.\n",
      "Running group 3, task 0, lv 63.\n",
      "Running group 3, task 0, lv 64.\n",
      "Running group 3, task 0, lv 65.\n",
      "Running group 3, task 0, lv 66.\n",
      "Running group 3, task 0, lv 67.\n",
      "Running group 3, task 0, lv 68.\n",
      "Running group 3, task 0, lv 69.\n",
      "Running group 3, task 0, lv 70.\n",
      "Running group 3, task 0, lv 71.\n",
      "Running group 3, task 0, lv 72.\n",
      "Running group 3, task 0, lv 73.\n",
      "Running group 3, task 0, lv 74.\n",
      "Running group 3, task 0, lv 75.\n",
      "Running group 3, task 0, lv 76.\n",
      "Running group 3, task 0, lv 77.\n",
      "Running group 3, task 0, lv 78.\n",
      "Running group 3, task 0, lv 79.\n",
      "Running group 3, task 0, lv 80.\n",
      "Running group 3, task 0, lv 81.\n",
      "Running group 3, task 0, lv 82.\n",
      "Running group 3, task 0, lv 83.\n",
      "Running group 3, task 0, lv 84.\n",
      "Running group 3, task 0, lv 85.\n",
      "Running group 3, task 0, lv 86.\n",
      "Running group 3, task 0, lv 87.\n",
      "Running group 3, task 0, lv 88.\n",
      "Running group 3, task 0, lv 89.\n",
      "Running group 3, task 0, lv 90.\n",
      "Running group 3, task 0, lv 91.\n",
      "Running group 3, task 0, lv 92.\n",
      "Running group 3, task 0, lv 93.\n",
      "Running group 3, task 0, lv 94.\n",
      "Running group 3, task 0, lv 95.\n",
      "Running group 3, task 0, lv 96.\n",
      "Running group 3, task 0, lv 97.\n",
      "Running group 3, task 0, lv 98.\n",
      "Running group 3, task 0, lv 99.\n",
      "Running group 3, task 1, lv 0.\n",
      "Running group 3, task 1, lv 1.\n",
      "Running group 3, task 1, lv 2.\n",
      "Running group 3, task 1, lv 3.\n",
      "Running group 3, task 1, lv 4.\n",
      "Running group 3, task 1, lv 5.\n",
      "Running group 3, task 1, lv 6.\n",
      "Running group 3, task 1, lv 7.\n",
      "Running group 3, task 1, lv 8.\n",
      "Running group 3, task 1, lv 9.\n",
      "Running group 3, task 1, lv 10.\n",
      "Running group 3, task 1, lv 11.\n",
      "Running group 3, task 1, lv 12.\n",
      "Running group 3, task 1, lv 13.\n",
      "Running group 3, task 1, lv 14.\n",
      "Running group 3, task 1, lv 15.\n",
      "Running group 3, task 1, lv 16.\n",
      "Running group 3, task 1, lv 17.\n",
      "Running group 3, task 1, lv 18.\n",
      "Running group 3, task 1, lv 19.\n",
      "Running group 3, task 1, lv 20.\n",
      "Running group 3, task 1, lv 21.\n",
      "Running group 3, task 1, lv 22.\n",
      "Running group 3, task 1, lv 23.\n",
      "Running group 3, task 1, lv 24.\n",
      "Running group 3, task 1, lv 25.\n",
      "Running group 3, task 1, lv 26.\n",
      "Running group 3, task 1, lv 27.\n",
      "Running group 3, task 1, lv 28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running group 3, task 1, lv 29.\n",
      "Running group 3, task 1, lv 30.\n",
      "Running group 3, task 1, lv 31.\n",
      "Running group 3, task 1, lv 32.\n",
      "Running group 3, task 1, lv 33.\n",
      "Running group 3, task 1, lv 34.\n",
      "Running group 3, task 1, lv 35.\n",
      "Running group 3, task 1, lv 36.\n",
      "Running group 3, task 1, lv 37.\n",
      "Running group 3, task 1, lv 38.\n",
      "Running group 3, task 1, lv 39.\n",
      "Running group 3, task 1, lv 40.\n",
      "Running group 3, task 1, lv 41.\n",
      "Running group 3, task 1, lv 42.\n",
      "Running group 3, task 1, lv 43.\n",
      "Running group 3, task 1, lv 44.\n",
      "Running group 3, task 1, lv 45.\n",
      "Running group 3, task 1, lv 46.\n",
      "Running group 3, task 1, lv 47.\n",
      "Running group 3, task 1, lv 48.\n",
      "Running group 3, task 1, lv 49.\n",
      "Running group 3, task 1, lv 50.\n",
      "Running group 3, task 1, lv 51.\n",
      "Running group 3, task 1, lv 52.\n",
      "Running group 3, task 1, lv 53.\n",
      "Running group 3, task 1, lv 54.\n",
      "Running group 3, task 1, lv 55.\n",
      "Running group 3, task 1, lv 56.\n",
      "Running group 3, task 1, lv 57.\n",
      "Running group 3, task 1, lv 58.\n",
      "Running group 3, task 1, lv 59.\n",
      "Running group 3, task 1, lv 60.\n",
      "Running group 3, task 1, lv 61.\n",
      "Running group 3, task 1, lv 62.\n",
      "Running group 3, task 1, lv 63.\n",
      "Running group 3, task 1, lv 64.\n",
      "Running group 3, task 1, lv 65.\n",
      "Running group 3, task 1, lv 66.\n",
      "Running group 3, task 1, lv 67.\n",
      "Running group 3, task 1, lv 68.\n",
      "Running group 3, task 1, lv 69.\n",
      "Running group 3, task 1, lv 70.\n",
      "Running group 3, task 1, lv 71.\n",
      "Running group 3, task 1, lv 72.\n",
      "Running group 3, task 1, lv 73.\n",
      "Running group 3, task 1, lv 74.\n",
      "Running group 3, task 1, lv 75.\n",
      "Running group 3, task 1, lv 76.\n",
      "Running group 3, task 1, lv 77.\n",
      "Running group 3, task 1, lv 78.\n",
      "Running group 3, task 1, lv 79.\n",
      "Running group 3, task 1, lv 80.\n",
      "Running group 3, task 1, lv 81.\n",
      "Running group 3, task 1, lv 82.\n",
      "Running group 3, task 1, lv 83.\n",
      "Running group 3, task 1, lv 84.\n",
      "Running group 3, task 1, lv 85.\n",
      "Running group 3, task 1, lv 86.\n",
      "Running group 3, task 1, lv 87.\n",
      "Running group 3, task 1, lv 88.\n",
      "Running group 3, task 1, lv 89.\n",
      "Running group 3, task 1, lv 90.\n",
      "Running group 3, task 1, lv 91.\n",
      "Running group 3, task 1, lv 92.\n",
      "Running group 3, task 1, lv 93.\n",
      "Running group 3, task 1, lv 94.\n",
      "Running group 3, task 1, lv 95.\n",
      "Running group 3, task 1, lv 96.\n",
      "Running group 3, task 1, lv 97.\n",
      "Running group 3, task 1, lv 98.\n",
      "Running group 3, task 1, lv 99.\n",
      "Running group 3, task 2, lv 0.\n",
      "Running group 3, task 2, lv 1.\n",
      "Running group 3, task 2, lv 2.\n",
      "Running group 3, task 2, lv 3.\n",
      "Running group 3, task 2, lv 4.\n",
      "Running group 3, task 2, lv 5.\n",
      "Running group 3, task 2, lv 6.\n",
      "Running group 3, task 2, lv 7.\n",
      "Running group 3, task 2, lv 8.\n",
      "Running group 3, task 2, lv 9.\n",
      "Running group 3, task 2, lv 10.\n",
      "Running group 3, task 2, lv 11.\n",
      "Running group 3, task 2, lv 12.\n",
      "Running group 3, task 2, lv 13.\n",
      "Running group 3, task 2, lv 14.\n",
      "Running group 3, task 2, lv 15.\n",
      "Running group 3, task 2, lv 16.\n",
      "Running group 3, task 2, lv 17.\n",
      "Running group 3, task 2, lv 18.\n",
      "Running group 3, task 2, lv 19.\n",
      "Running group 3, task 2, lv 20.\n",
      "Running group 3, task 2, lv 21.\n",
      "Running group 3, task 2, lv 22.\n",
      "Running group 3, task 2, lv 23.\n",
      "Running group 3, task 2, lv 24.\n",
      "Running group 3, task 2, lv 25.\n",
      "Running group 3, task 2, lv 26.\n",
      "Running group 3, task 2, lv 27.\n",
      "Running group 3, task 2, lv 28.\n",
      "Running group 3, task 2, lv 29.\n",
      "Running group 3, task 2, lv 30.\n",
      "Running group 3, task 2, lv 31.\n",
      "Running group 3, task 2, lv 32.\n",
      "Running group 3, task 2, lv 33.\n",
      "Running group 3, task 2, lv 34.\n",
      "Running group 3, task 2, lv 35.\n",
      "Running group 3, task 2, lv 36.\n",
      "Running group 3, task 2, lv 37.\n",
      "Running group 3, task 2, lv 38.\n",
      "Running group 3, task 2, lv 39.\n",
      "Running group 3, task 2, lv 40.\n",
      "Running group 3, task 2, lv 41.\n",
      "Running group 3, task 2, lv 42.\n",
      "Running group 3, task 2, lv 43.\n",
      "Running group 3, task 2, lv 44.\n",
      "Running group 3, task 2, lv 45.\n",
      "Running group 3, task 2, lv 46.\n",
      "Running group 3, task 2, lv 47.\n",
      "Running group 3, task 2, lv 48.\n",
      "Running group 3, task 2, lv 49.\n",
      "Running group 3, task 2, lv 50.\n",
      "Running group 3, task 2, lv 51.\n",
      "Running group 3, task 2, lv 52.\n",
      "Running group 3, task 2, lv 53.\n",
      "Running group 3, task 2, lv 54.\n",
      "Running group 3, task 2, lv 55.\n",
      "Running group 3, task 2, lv 56.\n",
      "Running group 3, task 2, lv 57.\n",
      "Running group 3, task 2, lv 58.\n",
      "Running group 3, task 2, lv 59.\n",
      "Running group 3, task 2, lv 60.\n",
      "Running group 3, task 2, lv 61.\n",
      "Running group 3, task 2, lv 62.\n",
      "Running group 3, task 2, lv 63.\n",
      "Running group 3, task 2, lv 64.\n",
      "Running group 3, task 2, lv 65.\n",
      "Running group 3, task 2, lv 66.\n",
      "Running group 3, task 2, lv 67.\n",
      "Running group 3, task 2, lv 68.\n",
      "Running group 3, task 2, lv 69.\n",
      "Running group 3, task 2, lv 70.\n",
      "Running group 3, task 2, lv 71.\n",
      "Running group 3, task 2, lv 72.\n",
      "Running group 3, task 2, lv 73.\n",
      "Running group 3, task 2, lv 74.\n",
      "Running group 3, task 2, lv 75.\n",
      "Running group 3, task 2, lv 76.\n",
      "Running group 3, task 2, lv 77.\n",
      "Running group 3, task 2, lv 78.\n",
      "Running group 3, task 2, lv 79.\n",
      "Running group 3, task 2, lv 80.\n",
      "Running group 3, task 2, lv 81.\n",
      "Running group 3, task 2, lv 82.\n",
      "Running group 3, task 2, lv 83.\n",
      "Running group 3, task 2, lv 84.\n",
      "Running group 3, task 2, lv 85.\n",
      "Running group 3, task 2, lv 86.\n",
      "Running group 3, task 2, lv 87.\n",
      "Running group 3, task 2, lv 88.\n",
      "Running group 3, task 2, lv 89.\n",
      "Running group 3, task 2, lv 90.\n",
      "Running group 3, task 2, lv 91.\n",
      "Running group 3, task 2, lv 92.\n",
      "Running group 3, task 2, lv 93.\n",
      "Running group 3, task 2, lv 94.\n",
      "Running group 3, task 2, lv 95.\n",
      "Running group 3, task 2, lv 96.\n",
      "Running group 3, task 2, lv 97.\n",
      "Running group 3, task 2, lv 98.\n",
      "Running group 3, task 2, lv 99.\n",
      "\n",
      "Assessment is Savage et al. (2013), English\n",
      "\n",
      " \n",
      "\n",
      "NORMAL \n",
      "\n",
      "\n",
      "Savage et al. (2013), English\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    88.70          97.00         99.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.00   MAE =  4.87\n",
      "\n",
      "Sim:    100.00          100.00         100.00 \n",
      "\n",
      " \n",
      "\n",
      "NONFLUENT/AGRAMMATIC \n",
      "\n",
      "\n",
      "Savage et al. (2013), English\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    78.30          94.30         79.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.91   MAE =  0.77\n",
      "\n",
      "Sim:    78.18          93.68         78.13 \n",
      "\n",
      " \n",
      "\n",
      "SEMANTIC DEMENTIA  \n",
      "\n",
      "\n",
      "Savage et al. (2013), English\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    22.70          63.30         95.30 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.58   MAE =  5.39\n",
      "\n",
      "Sim:    10.76          63.42         99.41 \n",
      "\n",
      " \n",
      "\n",
      "LOGOPENIC  \n",
      "\n",
      "\n",
      "Savage et al. (2013), English\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    41.30          84.70         84.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.74   MAE =  9.21\n",
      "\n",
      "Sim:    47.30          84.48         63.30 \n",
      "\n",
      "\n",
      "\n",
      "Assessment is Janssen et al. (2022), Dutch\n",
      "\n",
      " \n",
      "\n",
      "NORMAL \n",
      "\n",
      "\n",
      "Assessment is Janssen et al. (2022), Dutch\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    90.30          96.30         96.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.00   MAE =  5.57\n",
      "\n",
      "Sim:    100.00          100.00         100.00 \n",
      "\n",
      " \n",
      "\n",
      "NONFLUENT/AGRAMMATIC \n",
      "\n",
      "\n",
      "Assessment is Janssen et al. (2022), Dutch\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    77.30          97.70         89.30 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.95   MAE =  4.47\n",
      "\n",
      "Sim:    87.32          96.32         87.28 \n",
      "\n",
      " \n",
      "\n",
      "SEMANTIC DEMENTIA  \n",
      "\n",
      "\n",
      "Assessment is Janssen et al. (2022), Dutch\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    29.00          78.00         96.30 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.84   MAE =  3.95\n",
      "\n",
      "Sim:    29.09          86.56         99.51 \n",
      "\n",
      " \n",
      "\n",
      "LOGOPENIC  \n",
      "\n",
      "\n",
      "Assessment is Janssen et al. (2022), Dutch\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    66.30          93.70         91.30 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.86   MAE =  5.91\n",
      "\n",
      "Sim:    67.78          90.36         78.40 \n",
      "\n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), baseline T1\n",
      "\n",
      " \n",
      "\n",
      "NORMAL \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    90.30          96.30         96.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.00   MAE =  5.57\n",
      "\n",
      "Sim:    100.00          100.00         100.00 \n",
      "\n",
      " \n",
      "\n",
      "NONFLUENT/AGRAMMATIC \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    85.30          99.70         83.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.94   MAE =  1.88\n",
      "\n",
      "Sim:    84.95          95.63         84.92 \n",
      "\n",
      " \n",
      "\n",
      "SEMANTIC DEMENTIA  \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    26.70          88.00         90.60 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.83   MAE =  4.07\n",
      "\n",
      "Sim:    27.70          85.70         99.50 \n",
      "\n",
      " \n",
      "\n",
      "LOGOPENIC  \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    69.30          95.00         69.00 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.87   MAE =  5.10\n",
      "\n",
      "Sim:    69.76          90.93         79.78 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), follow up T2\n",
      "\n",
      " \n",
      "\n",
      "NORMAL \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    90.30          96.30         96.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.00   MAE =  5.57\n",
      "\n",
      "Sim:    100.00          100.00         100.00 \n",
      "\n",
      " \n",
      "\n",
      "NONFLUENT/AGRAMMATIC \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    83.30          94.80         68.00 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.93   MAE =  5.14\n",
      "\n",
      "Sim:    82.64          94.97         82.60 \n",
      "\n",
      " \n",
      "\n",
      "SEMANTIC DEMENTIA  \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    19.30          66.70         82.30 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.62   MAE =  8.17\n",
      "\n",
      "Sim:    12.31          67.12         99.41 \n",
      "\n",
      " \n",
      "\n",
      "LOGOPENIC  \n",
      "\n",
      "\n",
      "Assessment is Brambati et al. (2015), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    52.70          95.00         58.80 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.77   MAE =  6.01\n",
      "\n",
      "Sim:    51.91          85.79         66.84 \n",
      "\n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), baseline T1\n",
      "\n",
      " \n",
      "\n",
      "NORMAL \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    90.30          96.30         96.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.00   MAE =  5.57\n",
      "\n",
      "Sim:    100.00          100.00         100.00 \n",
      "\n",
      " \n",
      "\n",
      "NONFLUENT/AGRAMMATIC \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    76.70          99.00         81.50 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.92   MAE =  3.18\n",
      "\n",
      "Sim:    80.38          94.32         80.34 \n",
      "\n",
      " \n",
      "\n",
      "SEMANTIC DEMENTIA  \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    26.70          88.00         90.60 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.83   MAE =  4.07\n",
      "\n",
      "Sim:    27.70          85.70         99.50 \n",
      "\n",
      " \n",
      "\n",
      "LOGOPENIC  \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), baseline T1\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    61.00          94.00         94.00 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.85   MAE =  8.67\n",
      "\n",
      "Sim:    65.86          89.80         77.04 \n",
      "\n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), follow up T2\n",
      "\n",
      " \n",
      "\n",
      "NORMAL \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    90.30          96.30         96.70 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.00   MAE =  5.57\n",
      "\n",
      "Sim:    100.00          100.00         100.00 \n",
      "\n",
      " \n",
      "\n",
      "NONFLUENT/AGRAMMATIC \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    66.00          90.00         65.50 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.85   MAE =  0.21\n",
      "\n",
      "Sim:    65.94          90.18         65.88 \n",
      "\n",
      " \n",
      "\n",
      "SEMANTIC DEMENTIA  \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    26.70          88.00         90.60 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.83   MAE =  4.07\n",
      "\n",
      "Sim:    27.70          85.70         99.50 \n",
      "\n",
      " \n",
      "\n",
      "LOGOPENIC  \n",
      "\n",
      "\n",
      "Assessment is Rohrer et al. (2013) and Mandelli et al. (2016), follow up T2\n",
      "\n",
      "        Naming   Comprehension  Repetition \n",
      "\n",
      "Real:    43.00          85.00         77.00 \n",
      "\n",
      "Lesion:                                    MAE\n",
      "\n",
      "Best fit weight value =  0.75   MAE =  6.14\n",
      "\n",
      "Sim:    48.80          84.91         64.46 \n",
      "\n",
      "\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "m = Model()\n",
    "m.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba2164e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.52999567e+00 6.21592825e-02 6.21592825e-02]\n",
      "  [5.11718750e-01 0.00000000e+00 0.00000000e+00]\n",
      "  [5.52999567e+00 6.21592825e-02 6.21592825e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.52999721e+00 6.21610213e-02 6.21610213e-02]\n",
      "  [5.16859255e-01 1.64659128e-04 1.64659128e-04]\n",
      "  [5.52999569e+00 6.21608193e-02 6.21608193e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.53000184e+00 6.21662383e-02 6.21662383e-02]\n",
      "  [5.22047650e-01 3.29363052e-04 3.29363052e-04]\n",
      "  [5.52999579e+00 6.21654382e-02 6.21654382e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.54947285e+00 8.43415581e-02 8.43415581e-02]\n",
      "  [4.02336850e+00 6.28245040e-02 6.28245040e-02]\n",
      "  [5.54886637e+00 8.42355458e-02 8.42355458e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.55001776e+00 8.49692722e-02 8.49692722e-02]\n",
      "  [4.43479463e+00 6.92598701e-02 6.92598701e-02]\n",
      "  [5.54960153e+00 8.48960245e-02 8.48960245e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.55057614e+00 8.56129378e-02 8.56129378e-02]\n",
      "  [4.93518290e+00 7.69628210e-02 7.69628210e-02]\n",
      "  [5.55036191e+00 8.55749777e-02 8.55749777e-02]]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save mean activations for later\n",
    "with open('outputs/mean_act_nengo_direct.pkl', 'wb') as f: \n",
    "    pickle.dump([\n",
    "        m.MEAN_ACT_C, \n",
    "        m.MEAN_ACT_S,\n",
    "        m.MEAN_ACT_CT,\n",
    "        m.MEAN_ACT_CR,\n",
    "        m.MEAN_ACT_LT,\n",
    "        m.MEAN_ACT_LR,\n",
    "        m.MEAN_ACT_ST,\n",
    "        m.MEAN_ACT_SR\n",
    "    ], f)\n",
    "    \n",
    "print(m.MEAN_ACT_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a326793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.52999567e+00 6.21592825e-02 6.21592825e-02]\n",
      "  [5.11718750e-01 0.00000000e+00 0.00000000e+00]\n",
      "  [5.52999567e+00 6.21592825e-02 6.21592825e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.52999721e+00 6.21610213e-02 6.21610213e-02]\n",
      "  [5.16859255e-01 1.64659128e-04 1.64659128e-04]\n",
      "  [5.52999569e+00 6.21608193e-02 6.21608193e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.53000184e+00 6.21662383e-02 6.21662383e-02]\n",
      "  [5.22047650e-01 3.29363052e-04 3.29363052e-04]\n",
      "  [5.52999579e+00 6.21654382e-02 6.21654382e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.54947285e+00 8.43415581e-02 8.43415581e-02]\n",
      "  [4.02336850e+00 6.28245040e-02 6.28245040e-02]\n",
      "  [5.54886637e+00 8.42355458e-02 8.42355458e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.55001776e+00 8.49692722e-02 8.49692722e-02]\n",
      "  [4.43479463e+00 6.92598701e-02 6.92598701e-02]\n",
      "  [5.54960153e+00 8.48960245e-02 8.48960245e-02]]\n",
      "\n",
      " [[5.55114842e+00 8.62730659e-02 8.62730659e-02]\n",
      "  [5.55057614e+00 8.56129378e-02 8.56129378e-02]\n",
      "  [4.93518290e+00 7.69628210e-02 7.69628210e-02]\n",
      "  [5.55036191e+00 8.55749777e-02 8.55749777e-02]]]\n"
     ]
    }
   ],
   "source": [
    "# load mean activations\n",
    "with open('outputs/mean_act_nengo_direct.pkl', 'rb') as f:\n",
    "    mean_C, mean_S, mean_CT, mean_CR, mean_LT, mean_LR, mean_ST, mean_SR = pickle.load(f)\n",
    "    \n",
    "print(mean_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635cd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
